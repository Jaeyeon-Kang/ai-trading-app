"""
ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìŠ¤ìºë„ˆ
Alpha Vantage News APIë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘

ê¸°íš ëª©í‘œ:
- íŒŒì›” ë°œì–¸, Fed ê´€ë ¨ ë‰´ìŠ¤ ì‹¤ì‹œê°„ í¬ì°©
- ê¸°ìˆ ì£¼ ì‹¤ì , ì‹œì¥ ì´ë²¤íŠ¸ ì¦‰ì‹œ ë°˜ì˜  
- EDGAR ê³µì‹œì˜ í•œê³„ë¥¼ ë‰´ìŠ¤ë¡œ ë³´ì™„
"""

import os
import time
import logging
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import httpx

logger = logging.getLogger(__name__)

class NewsScanner:
    """Alpha Vantage News API ê¸°ë°˜ ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìŠ¤ìºë„ˆ"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("ALPHA_VANTAGE_API_KEY", "demo")
        self.base_url = "https://www.alphavantage.co/query"
        
        # Fed ê´€ë ¨ í‚¤ì›Œë“œ (íŒŒì›” ë°œì–¸ ë“±)
        self.fed_keywords = [
            "powell", "jerome powell", "federal reserve", "fed chair", 
            "interest rate", "rate cut", "rate hike", "monetary policy",
            "fomc", "fed meeting", "inflation", "fed decision"
        ]
        
        # ê¸°ìˆ ì£¼ í‚¤ì›Œë“œ  
        self.tech_keywords = [
            "nvidia", "apple", "microsoft", "tesla", "amazon", 
            "google", "meta", "earnings", "ai", "semiconductor"
        ]
    
    def _get_headers(self) -> Dict[str, str]:
        """API í—¤ë”"""
        return {
            "User-Agent": "AI-Trading-Bot/1.0",
            "Accept": "application/json"
        }
    
    def scan_market_news(self, limit: int = 50) -> List[Dict]:
        """ì‹œì¥ ë‰´ìŠ¤ ìŠ¤ìº”"""
        try:
            # Alpha Vantage News API í˜¸ì¶œ
            params = {
                "function": "NEWS_SENTIMENT",
                "tickers": "AAPL,MSFT,NVDA,TSLA,AMZN,GOOGL,META",  # ì£¼ìš” ì¢…ëª©
                "topics": "technology,financial_markets,economy_macro",
                "time_from": (datetime.now() - timedelta(hours=6)).strftime("%Y%m%dT%H%M"),
                "limit": limit,
                "apikey": self.api_key
            }
            
            with httpx.Client(headers=self._get_headers(), timeout=15.0) as client:
                response = client.get(self.base_url, params=params)
                response.raise_for_status()
                data = response.json()
            
            return self._process_news_data(data)
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
            return []
    
    def scan_fed_news(self, limit: int = 20) -> List[Dict]:
        """Fed ê´€ë ¨ ë‰´ìŠ¤ ì „ìš© ìŠ¤ìº”"""
        try:
            params = {
                "function": "NEWS_SENTIMENT", 
                "topics": "economy_macro,financial_markets",
                "time_from": (datetime.now() - timedelta(hours=12)).strftime("%Y%m%dT%H%M"),
                "limit": limit,
                "apikey": self.api_key
            }
            
            with httpx.Client(headers=self._get_headers(), timeout=15.0) as client:
                response = client.get(self.base_url, params=params)
                response.raise_for_status()
                data = response.json()
            
            # Fed í‚¤ì›Œë“œ í•„í„°ë§
            news_items = self._process_news_data(data)
            fed_news = []
            
            for item in news_items:
                title = item.get("title", "").lower()
                summary = item.get("summary", "").lower()
                content = title + " " + summary
                
                if any(keyword in content for keyword in self.fed_keywords):
                    item["event_type"] = "fed_speech" if "powell" in content else "rate_decision" 
                    item["priority"] = "high"
                    fed_news.append(item)
            
            return fed_news
            
        except Exception as e:
            logger.error(f"Fed ë‰´ìŠ¤ ìŠ¤ìº” ì‹¤íŒ¨: {e}")
            return []
    
    def _process_news_data(self, data: Dict) -> List[Dict]:
        """ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬"""
        if not data or "feed" not in data:
            return []
        
        processed_news = []
        
        for item in data["feed"]:
            try:
                # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                news_item = {
                    "title": item.get("title", ""),
                    "summary": item.get("summary", "")[:500],  # 500ì ì œí•œ
                    "url": item.get("url", ""),
                    "published_at": item.get("time_published", ""),
                    "source": item.get("source", ""),
                    "sentiment_score": float(item.get("overall_sentiment_score", 0.0)),
                    "sentiment_label": item.get("overall_sentiment_label", "Neutral"),
                    "relevance_score": self._calculate_relevance(item),
                    "tickers": [ticker.get("ticker", "") for ticker in item.get("ticker_sentiment", [])],
                    "event_type": "market_news",  # ê¸°ë³¸ê°’
                    "priority": "medium"
                }
                
                # ê³ í’ˆì§ˆ ë‰´ìŠ¤ë§Œ ì„ íƒ
                if news_item["relevance_score"] > 0.3:
                    processed_news.append(news_item)
                    
            except Exception as e:
                logger.warning(f"ë‰´ìŠ¤ ì•„ì´í…œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        # ê´€ë ¨ì„± ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        processed_news.sort(key=lambda x: x["relevance_score"], reverse=True)
        return processed_news
    
    def _calculate_relevance(self, item: Dict) -> float:
        """ë‰´ìŠ¤ ê´€ë ¨ì„± ì ìˆ˜ ê³„ì‚°"""
        try:
            title = item.get("title", "").lower()
            summary = item.get("summary", "").lower()
            
            relevance = 0.0
            
            # Fed ê´€ë ¨ì„± (ìµœê³  ì ìˆ˜)
            if any(keyword in title + summary for keyword in self.fed_keywords):
                relevance += 0.8
            
            # ê¸°ìˆ ì£¼ ê´€ë ¨ì„±
            if any(keyword in title + summary for keyword in self.tech_keywords):
                relevance += 0.6
                
            # í‹°ì»¤ ê´€ë ¨ì„±  
            ticker_sentiment = item.get("ticker_sentiment", [])
            if ticker_sentiment:
                max_relevance = max(float(t.get("relevance_score", 0)) for t in ticker_sentiment)
                relevance += max_relevance * 0.5
            
            # ì „ì²´ ê°ì • ì ìˆ˜ ë°˜ì˜
            sentiment_score = abs(float(item.get("overall_sentiment_score", 0)))
            relevance += sentiment_score * 0.3
            
            return min(relevance, 1.0)  # 1.0 ìƒí•œ
            
        except Exception:
            return 0.0
    
    def run_full_scan(self) -> Dict[str, List[Dict]]:
        """ì „ì²´ ë‰´ìŠ¤ ìŠ¤ìº” ì‹¤í–‰"""
        logger.info("ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤ ìŠ¤ìº” ì‹œì‘")
        
        results = {
            "fed_news": self.scan_fed_news(),
            "market_news": self.scan_market_news(),
            "timestamp": datetime.now().isoformat()
        }
        
        total_news = len(results["fed_news"]) + len(results["market_news"])
        high_priority = len([n for n in results["fed_news"] if n.get("priority") == "high"])
        
        logger.info(f"ğŸ“° ë‰´ìŠ¤ ìŠ¤ìº” ì™„ë£Œ: ì´ {total_news}ê±´ (ê³ ìš°ì„ ìˆœìœ„ {high_priority}ê±´)")
        
        return results

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_news_scanner = None

def get_news_scanner() -> NewsScanner:
    """ë‰´ìŠ¤ ìŠ¤ìºë„ˆ ì‹±ê¸€í†¤"""
    global _news_scanner
    if _news_scanner is None:
        _news_scanner = NewsScanner()
    return _news_scanner