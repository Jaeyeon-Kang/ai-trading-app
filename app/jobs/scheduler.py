"""
Celery beat ìŠ¤ì¼€ì¤„ëŸ¬
15-30ì´ˆ ì£¼ê¸°ë¡œ ì‹œê·¸ë„ ìƒì„± ë° ê±°ë˜ ì‹¤í–‰
"""
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
import hashlib
import json
import logging
import os
import time
import math
# from decimal import Decimal  # ì‚¬ìš©ë˜ì§€ ì•ŠìŒ
from typing import Any, Dict, List, Optional, Tuple, Union
import urllib.parse as _urlparse

import psycopg2
import redis

from celery import Celery
from celery.schedules import crontab
from celery.signals import beat_init, task_prerun, worker_process_init, worker_ready

# ë¡œê¹… ì„¤ì • (ë‹¤ë¥¸ importë³´ë‹¤ ë¨¼ì €)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from app.config import settings, get_signal_cutoffs, sanitize_cutoffs_in_redis
from app.utils.rate_limiter import get_rate_limiter, TokenTier

# GPT-5 ë¦¬ìŠ¤í¬ ê´€ë¦¬ í†µí•©
try:
    from app.engine.risk_manager import get_risk_manager
    from app.adapters.trading_adapter import get_trading_adapter
    RISK_MANAGER_AVAILABLE = True
except ImportError:
    RISK_MANAGER_AVAILABLE = False
    logger.warning("âš ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì import ì‹¤íŒ¨ - ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘")

def check_signal_risk_feasibility(signal, session_label):
    """
    ì‹ í˜¸ ë°œí–‰ ì „ ë¦¬ìŠ¤í¬ ì²´í¬ (GPT-5 ê¶Œì¥)
    ë™ì‹œìœ„í—˜ í•œë„ë¥¼ ì´ˆê³¼í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì‹ í˜¸ëŠ” ì‚¬ì „ í•„í„°ë§
    
    Returns:
        Tuple[bool, str]: (í—ˆìš© ì—¬ë¶€, ì‚¬ìœ )
    """
    if not RISK_MANAGER_AVAILABLE:
        return True, "ë¦¬ìŠ¤í¬ ê´€ë¦¬ì ë¹„í™œì„±í™”"
    
    try:
        # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ í™•ì¸
        trading_adapter = get_trading_adapter()
        portfolio = trading_adapter.get_portfolio_summary()
        positions = trading_adapter.get_positions()
        
        # í˜„ì¬ ì´ ìœ„í—˜ ê³„ì‚°
        equity = portfolio.get('equity', 0)
        if equity <= 0:
            return False, "ê³„ì¢Œ ìì‚° í™•ì¸ ë¶ˆê°€"
        
        current_risk = 0
        for pos in positions:
            # ê° í¬ì§€ì…˜ ìœ„í—˜ (1.5% ì†ì ˆ ê°€ì •)
            stop_distance = pos.avg_price * 0.015
            pos_risk = abs(pos.quantity * stop_distance) / equity
            current_risk += pos_risk
        
        # ì‹ ê·œ ì‹ í˜¸ì˜ ì˜ˆìƒ ìœ„í—˜ (0.5% ê¸°ë³¸ê°’)
        risk_manager = get_risk_manager()
        expected_new_risk = risk_manager.config.risk_per_trade
        
        # ë™ì‹œìœ„í—˜ í•œë„ ì²´í¬ (2%)
        total_risk = current_risk + expected_new_risk
        max_risk = risk_manager.config.max_concurrent_risk
        
        if total_risk > max_risk:
            return False, f"ë™ì‹œìœ„í—˜ í•œë„ ì´ˆê³¼ ì˜ˆìƒ: {total_risk:.2%} > {max_risk:.2%}"
        
        # í¬ì§€ì…˜ ìˆ˜ ì²´í¬
        if len(positions) >= risk_manager.config.max_positions:
            return False, f"ìµœëŒ€ í¬ì§€ì…˜ ìˆ˜ ë„ë‹¬: {len(positions)}/{risk_manager.config.max_positions}"
        
        logger.info(f"âœ… {signal.ticker} ë¦¬ìŠ¤í¬ pre-check í†µê³¼: í˜„ì¬ {current_risk:.2%} + ì˜ˆìƒ {expected_new_risk:.2%} = {total_risk:.2%}")
        return True, f"ë¦¬ìŠ¤í¬ í—ˆìš©: {total_risk:.2%}/{max_risk:.2%}"
        
    except Exception as e:
        logger.error(f"âŒ ë¦¬ìŠ¤í¬ pre-check ì‹¤íŒ¨: {e}")
        # ì•ˆì „ì„ ìœ„í•´ ì²´í¬ ì‹¤íŒ¨ì‹œì—ë„ í—ˆìš© (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
        return True, "ë¦¬ìŠ¤í¬ ì²´í¬ ì˜¤ë¥˜ë¡œ ê¸°ë³¸ í—ˆìš©"

def check_signal_risk_feasibility_detailed(signal_data):
    """
    Redis ìŠ¤íŠ¸ë¦¼ ì‹ í˜¸ ë°ì´í„°ì— ëŒ€í•œ ë¦¬ìŠ¤í¬ ì²´í¬
    
    Args:
        signal_data: Redis ìŠ¤íŠ¸ë¦¼ì—ì„œ ê°€ì ¸ì˜¨ ì‹ í˜¸ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        Tuple[bool, str]: (í—ˆìš© ì—¬ë¶€, ì‚¬ìœ )
    """
    if not RISK_MANAGER_AVAILABLE:
        return True, "ë¦¬ìŠ¤í¬ ê´€ë¦¬ì ë¹„í™œì„±í™”"
    
    try:
        ticker = signal_data.get("ticker")
        entry_price = float(signal_data.get("entry_price", 0))
        stop_loss = float(signal_data.get("stop_loss", 0))
        
        if not ticker or entry_price <= 0 or stop_loss <= 0:
            return False, "ì‹ í˜¸ ë°ì´í„° ë¶€ì¡±"
        
        # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ í™•ì¸
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        
        # ê¸°ë³¸ ë¦¬ìŠ¤í¬ ì²´í¬
        risk_per_trade = abs(entry_price - stop_loss) / entry_price
        if risk_per_trade > 0.03:  # 3% ì´ˆê³¼ ì†ì‹¤ ìœ„í—˜
            return False, f"ë‹¨ì¼ ê±°ë˜ ìœ„í—˜ ê³¼ëŒ€: {risk_per_trade:.2%} > 3%"
        
        # í¬ì§€ì…˜ ìˆ˜ ì²´í¬ (ê°„ë‹¨ ë²„ì „)
        try:
            positions = trading_adapter.get_positions()
            if len(positions) >= 5:  # ìµœëŒ€ 5ê°œ í¬ì§€ì…˜
                return False, f"ìµœëŒ€ í¬ì§€ì…˜ ìˆ˜ ë„ë‹¬: {len(positions)}/5"
        except Exception:
            pass  # í¬ì§€ì…˜ ì²´í¬ ì‹¤íŒ¨í•´ë„ ì§„í–‰
        
        logger.info(f"âœ… {ticker} ìƒì„¸ ë¦¬ìŠ¤í¬ ì²´í¬ í†µê³¼: ì˜ˆìƒì†ì‹¤ {risk_per_trade:.2%}")
        return True, f"ë¦¬ìŠ¤í¬ í—ˆìš©: ì˜ˆìƒì†ì‹¤ {risk_per_trade:.2%}"
        
    except Exception as e:
        logger.error(f"âŒ ìƒì„¸ ë¦¬ìŠ¤í¬ ì²´í¬ ì‹¤íŒ¨: {e}")
        # ì•ˆì „ì„ ìœ„í•´ ì²´í¬ ì‹¤íŒ¨ì‹œì—ë„ í—ˆìš©
        return True, "ë¦¬ìŠ¤í¬ ì²´í¬ ì˜¤ë¥˜ë¡œ ê¸°ë³¸ í—ˆìš©"

# Celery ì•± ìƒì„±
celery_app = Celery(
    "trading_bot",
    broker=os.getenv("REDIS_URL", "redis://localhost:6379/0"),
    backend=os.getenv("REDIS_URL", "redis://localhost:6379/0")
)

# ì„¤ì •
celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Asia/Seoul",  # KST
    enable_utc=True,        # UTC ìœ ì§€ + íƒ€ì„ì¡´-aware ìŠ¤ì¼€ì¤„ OK
    task_track_started=True,
    task_time_limit=30 * 60,  # 30ë¶„
    task_soft_time_limit=25 * 60,  # 25ë¶„
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=1000,
    include=[
        "app.jobs.scheduler",
        "app.jobs.paper_trading_manager",
        "app.jobs.daily_briefing",
    ],
)

# ìŠ¤ì¼€ì¤„ ì„¤ì •
celery_app.conf.beat_schedule = {
    # 15ì´ˆë§ˆë‹¤ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (E2E)
    "pipeline-e2e": {
        "task": "app.jobs.scheduler.pipeline_e2e",
        "schedule": 15.0,  # 15ì´ˆ
    },
    # 15ì´ˆë§ˆë‹¤ ì‹œê·¸ë„ ìƒì„±
    "generate-signals": {
        "task": "app.jobs.scheduler.generate_signals",
        "schedule": 15.0,  # 15ì´ˆ
    },
    # 30ì´ˆë§ˆë‹¤ ì‹œì„¸ ì—…ë°ì´íŠ¸
    "update-quotes": {
        "task": "app.jobs.scheduler.update_quotes",
        "schedule": 30.0,  # 30ì´ˆ
    },
    # 1ë¶„ë§ˆë‹¤ EDGAR ìŠ¤ìº”
    "scan-edgar": {
        "task": "app.jobs.scheduler.scan_edgar",
        "schedule": 60.0,  # 1ë¶„
    },
    # 5ë¶„ë§ˆë‹¤ ë¦¬ìŠ¤í¬ ì²´í¬
    "check-risk": {
        "task": "app.jobs.scheduler.check_risk",
        "schedule": 300.0,  # 5ë¶„
    },
    # ë§¤ì¼ ìì •ì— ì¼ì¼ ë¦¬ì…‹
    "daily-reset": {
        "task": "app.jobs.scheduler.daily_reset",
        "schedule": crontab(hour=0, minute=0),  # ë§¤ì¼ 00:00
    },
    # ë§¤ì¼ 06:10 KSTì— ì¼ì¼ ë¦¬í¬íŠ¸ (KST = UTC+9, 06:10 KST = 21:10 UTC ì „ë‚ )
    "daily-report": {
        "task": "app.jobs.scheduler.daily_report",
        "schedule": crontab(hour=21, minute=10),  # ë§¤ì¼ 21:10 UTC = 06:10 KST
        "args": [False, True],  # force=False, post=True (ìŠ¬ë™ìœ¼ë¡œ ë³´ë‚´ê¸°)
    },
    # 5ì´ˆë§ˆë‹¤ EDGAR ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ â†’ DB ì ì¬ (dedupeëŠ” DB UNIQUEì™€ ON CONFLICTë¡œ ë³´ê°•)
    "ingest-edgar": {
        "task": "app.jobs.scheduler.ingest_edgar_stream",
        "schedule": 5.0,
    },
    # 15ë¶„ë§ˆë‹¤ ìœ ë‹ˆë²„ìŠ¤ ì¬ì ìš© (ê¶Œì¥ ë¶„ë¦¬)
    "refresh-universe": {
        "task": "app.jobs.scheduler.refresh_universe",
        "schedule": 900.0,
    },
    # ë§¤ì¼ 05:55 KST ì ì‘í˜• ì»·ì˜¤í”„ ê°±ì‹  (ë¦¬í¬íŠ¸ ì§ì „)
    "adaptive-cutoff": {
        "task": "app.jobs.scheduler.adaptive_cutoff",
        "schedule": crontab(hour=20, minute=55),  # 05:55 KST = 20:55 UTC ì „ë‚ 
    },
    
    # =============================================================================
    # Phase 1.5: ì¼ì¼ ë¸Œë¦¬í•‘ ì‹œìŠ¤í…œ (ë‹µë‹µí•¨ í•´ì†Œ!)
    # =============================================================================
    
    # ì•„ì¹¨ ë¸Œë¦¬í•‘ (09:00 KST = 00:00 UTC)
    "morning-briefing": {
        "task": "app.jobs.daily_briefing.send_scheduled_briefing",
        "schedule": crontab(hour=0, minute=0),  # 09:00 KST
        "args": ["morning"],
    },
    
    # ì ì‹¬ ë¸Œë¦¬í•‘ (12:30 KST = 03:30 UTC)  
    "midday-briefing": {
        "task": "app.jobs.daily_briefing.send_scheduled_briefing",
        "schedule": crontab(hour=3, minute=30),  # 12:30 KST
        "args": ["midday"],
    },
    
    # ì €ë… ë¸Œë¦¬í•‘ (18:00 KST = 09:00 UTC)
    "evening-briefing": {
        "task": "app.jobs.daily_briefing.send_scheduled_briefing",
        "schedule": crontab(hour=9, minute=0),  # 18:00 KST
        "args": ["evening"],
    },
    
    # ì¡°ìš©í•œ ì‹œì¥ ì²´í¬ (1ì‹œê°„ë§ˆë‹¤, 9-18ì‹œ KSTë§Œ)
    "quiet-market-check": {
        "task": "app.jobs.daily_briefing.check_and_send_quiet_message",
        "schedule": crontab(minute=0),  # ë§¤ ì •ì‹œë§ˆë‹¤
    },
    
    # =============================================================================
    # Phase 1.5: ìŠ¤ë§ˆíŠ¸ í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ
    # =============================================================================
    
    # ìŠ¤í†±ë¡œìŠ¤/ìµì ˆ ì£¼ë¬¸ ì²´í¬ (5ë¶„ë§ˆë‹¤)
    "check-stop-orders": {
        "task": "app.jobs.paper_trading_manager.check_stop_orders",
        "schedule": crontab(minute="*/5"),  # 5ë¶„ë§ˆë‹¤
    },
    
    # ì¼ì¼ ì„±ê³¼ ë¦¬í¬íŠ¸ (ì €ë… 19:00 KST = 10:00 UTC)
    "daily-paper-report": {
        "task": "app.jobs.paper_trading_manager.send_daily_report", 
        "schedule": crontab(hour=10, minute=0),  # 19:00 KST
    },
    # ë§ˆê° ì „ ì‚¬ì „ ì˜ˆì•½ ì²­ì‚° (ë¯¸ ë™ë¶€ì‹œê°„ 15:48)
    "queue-preclose-liquidation": {
        "task": "app.jobs.scheduler.queue_preclose_liquidation",
        "schedule": crontab(hour=15, minute=48, tz='America/New_York'),
    },
    # íƒ€ì„ ìŠ¤í†± ê°€ë“œë ˆì¼ (1ë¶„ë§ˆë‹¤)
    "enforce-time-stop": {
        "task": "app.jobs.scheduler.enforce_time_stop",
        "schedule": 60.0,
    },
    # íŠ¸ë ˆì¼ ìŠ¤í†± ê°€ë“œë ˆì¼ (1ë¶„ë§ˆë‹¤)
    "enforce-trail-stop": {
        "task": "app.jobs.scheduler.enforce_trail_stop",
        "schedule": 60.0,
    },
    # ì—­ETF ë ˆì§ í”Œë¦½ ê°€ë“œë ˆì¼ (1ë¶„ë§ˆë‹¤)
    "enforce-regime-flatten-inverse": {
        "task": "app.jobs.scheduler.enforce_regime_flatten_inverse",
        "schedule": 60.0,
    },
}

# ì „ì—­ ë³€ìˆ˜ (ì‹¤ì œë¡œëŠ” ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©)
trading_components = {
    "quotes_ingestor": None,
    "edgar_scanner": None,
    "regime_detector": None,
    "tech_score_engine": None,
    "llm_engine": None,
    "signal_mixer": None,
    "risk_engine": None,
    "paper_ledger": None,
    "redis_streams": None,
    "slack_bot": None,
    "stream_consumer": None,
    "db_connection": None,
}

def _parse_redis_url(url: str) -> tuple[str, int, int]:
    try:
        parsed = _urlparse.urlparse(url)
        host = parsed.hostname or "redis"
        port = int(parsed.port or 6379)
        db = int((parsed.path or "/0").lstrip("/") or 0)
        return host, port, db
    except Exception:
        return "redis", 6379, 0

def _autoinit_components_if_enabled() -> None:
    """Best-effort ì»´í¬ë„ŒíŠ¸ ìë™ ì´ˆê¸°í™” (ì›Œì»¤/ë¹„íŠ¸ í”„ë¡œì„¸ìŠ¤ ê¸°ë™ ì‹œ).
    í•„ìˆ˜ êµ¬ì„±ë§Œì´ë¼ë„ ì¤€ë¹„í•´ components_not_ready ìŠ¤í‚µì„ ì¤„ì¸ë‹¤.
    """
    if os.getenv("AUTO_INIT_COMPONENTS", "true").lower() not in ("1","true","yes","on"):  # opt-out
        return
    try:
        from app.io.quotes_delayed import DelayedQuotesIngestor
        from app.engine.regime import RegimeDetector
        from app.engine.techscore import TechScoreEngine
        from app.engine.mixer import SignalMixer
        from app.engine.risk import RiskEngine
        from app.adapters.paper_ledger import PaperLedger
        from app.io.streams import RedisStreams, StreamConsumer
        from app.engine.llm_insight import LLMInsightEngine
        from app.io.slack_bot import SlackBot
    except Exception as e:
        logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return

    components: Dict[str, object] = {}

    # Quotes ingestor
    try:
        components["quotes_ingestor"] = DelayedQuotesIngestor()
        # ì›Œë°ì—…ìœ¼ë¡œ ë¹ˆ ë²„í¼ ë°©ì§€
        components["quotes_ingestor"].warmup_backfill()  # type: ignore
        logger.info("ë”œë ˆì´ë“œ Quotes ì¸ì œìŠ¤í„° ì›Œë°ì—… ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"Quotes ì¸ì œìŠ¤í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Regime/Tech/Mixer
    try:
        components["regime_detector"] = RegimeDetector()
    except Exception as e:
        logger.warning(f"RegimeDetector ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        components["tech_score_engine"] = TechScoreEngine()
    except Exception as e:
        logger.warning(f"TechScoreEngine ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        thr = settings.MIXER_THRESHOLD
        components["signal_mixer"] = SignalMixer(buy_threshold=thr, sell_threshold=-thr)
    except Exception as e:
        logger.warning(f"SignalMixer ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Risk/Paper ledger
    try:
        init_cap = float(os.getenv("INITIAL_CAPITAL", "1000000"))
        components["risk_engine"] = RiskEngine(initial_capital=init_cap)
    except Exception as e:
        logger.warning(f"RiskEngine ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        components["paper_ledger"] = PaperLedger(initial_cash=float(os.getenv("INITIAL_CAPITAL", "1000000")))
    except Exception as e:
        logger.warning(f"PaperLedger ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Redis streams / consumer
    try:
        rurl = os.getenv("REDIS_URL", "redis://redis:6379/0")
        host, port, db = _parse_redis_url(rurl)
        rs = RedisStreams(host=host, port=port, db=db)
        components["redis_streams"] = rs
        components["stream_consumer"] = StreamConsumer(rs)
    except Exception as e:
        logger.warning(f"Redis Streams ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Slack bot (optional)
    try:
        token = os.getenv("SLACK_BOT_TOKEN")
        channel = os.getenv("SLACK_CHANNEL_ID") or os.getenv("SLACK_CHANNEL", "#trading-signals")
        logger.info(f"ğŸ” [DEBUG] SlackBot í™˜ê²½ë³€ìˆ˜: token={'***' if token else None}, channel_id={os.getenv('SLACK_CHANNEL_ID')}, channel_fallback={os.getenv('SLACK_CHANNEL')}")
        logger.info(f"ğŸ” [DEBUG] SlackBot ìµœì¢… ì±„ë„: {channel}")
        if token:
            components["slack_bot"] = SlackBot(token=token, channel=channel)
            logger.info(f"Slack ë´‡ ì¤€ë¹„: ì±„ë„ {channel}")
        else:
            logger.warning("Slack í† í° ì—†ìŒ - ìŠ¬ë™ ë¹„í™œì„±")
    except Exception as e:
        logger.warning(f"SlackBot ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # LLM (optional)
    try:
        llm = LLMInsightEngine()
        if components.get("slack_bot"):
            llm.set_slack_bot(components["slack_bot"])  # type: ignore
        components["llm_engine"] = llm
    except Exception as e:
        logger.warning(f"LLM ì—”ì§„ ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    if components:
        try:
            initialize_components(components)  # ê¸°ì¡´ í—¬í¼ë¡œ ì£¼ì…
        except Exception as e:
            logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì£¼ì… ì‹¤íŒ¨: {e}")

# Celery ì‹ í˜¸ì— ìë™ ì´ˆê¸°í™” ì—°ê²°
@worker_ready.connect
def _on_worker_ready(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        # ì»·ì˜¤í”„ ì •í•©ì„± ì²´í¬
        mixer_thr = settings.MIXER_THRESHOLD
        rth_cut = result['rth']
        if rth_cut > mixer_thr:
            logger.warning(f"âš ï¸ RTH cutoff({rth_cut}) > MIXER({mixer_thr}) : ì¬ê²€í†  í•„ìš”")
        logger.info(f"ì»·ì˜¤í”„ ì •í•©ì„±: mixer={mixer_thr}, rth={rth_cut}, delta={rth_cut - mixer_thr:.3f}")
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

@beat_init.connect
def _on_beat_init(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

# ê° ì›Œì»¤ í”„ë¡œì„¸ìŠ¤(prefork)ì—ì„œ í•œ ë²ˆì”© ì´ˆê¸°í™”
@worker_process_init.connect
def _on_worker_process_init(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

# íƒœìŠ¤í¬ ì§ì „ì—ë„ í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì‹œë„
@task_prerun.connect
def _ensure_components_before_task(task=None, **kwargs):
    try:
        required_keys = [
            "quotes_ingestor",
            "regime_detector",
            "tech_score_engine",
            "signal_mixer",
        ]
        missing = [k for k in required_keys if not trading_components.get(k)]
        if missing:
            logger.warning(f"í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„(prerun): {missing} â†’ ìë™ ì´ˆê¸°í™” ì‹œë„")
            _autoinit_components_if_enabled()
    except Exception as e:
        logger.warning(f"prerun ìë™ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# =============================================================================
# Tier System Functions (Universe Expansion)
# =============================================================================

def get_ticker_tier(ticker: str) -> Optional[TokenTier]:
    """
    ì¢…ëª©ì´ ì†í•œ Tier ë°˜í™˜
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        Optional[TokenTier]: Tier íƒ€ì… (Noneì´ë©´ ë²¤ì¹˜)
    """
    ticker = ticker.upper().strip()
    
    tier_a_tickers = [t.strip().upper() for t in settings.TIER_A_TICKERS]
    tier_b_tickers = [t.strip().upper() for t in settings.TIER_B_TICKERS]
    
    if ticker in tier_a_tickers:
        return TokenTier.TIER_A
    elif ticker in tier_b_tickers:
        return TokenTier.TIER_B
    else:
        return None  # ë²¤ì¹˜ (ì´ë²¤íŠ¸ ê¸°ë°˜)

def should_process_ticker_now(ticker: str, current_time: Optional[Union[datetime, int]] = None) -> Tuple[bool, str]:
    """
    í˜„ì¬ ì‹œê°„ì— í•´ë‹¹ ì¢…ëª©ì„ ë¶„ì„í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        current_time: í˜„ì¬ ì‹œê°„ (Noneì´ë©´ datetime.now())
        
    Returns:
        Tuple[bool, str]: (ì²˜ë¦¬ ì—¬ë¶€, ì‚¬ìœ )
    """
    if current_time is None:
        current_time = datetime.now()
    
    tier = get_ticker_tier(ticker)
    
    # ë²¤ì¹˜ ì¢…ëª©ì€ ì´ë²¤íŠ¸ ê¸°ë°˜ë§Œ ì²˜ë¦¬ (í˜„ì¬ëŠ” ìŠ¤í‚µ)
    if tier is None:
        return False, "bench_event_only"
    
    # í˜„ì¬ ë¶„ì˜ ì´ˆ (timestampì—ì„œ datetime ê°ì²´ë¡œ ë³€í™˜)
    if isinstance(current_time, int):
        from datetime import datetime
        current_time = datetime.fromtimestamp(current_time)
    current_second = current_time.second
    
    if tier == TokenTier.TIER_A:
        # Tier A: 30ì´ˆë§ˆë‹¤ (0ì´ˆ, 30ì´ˆ)
        return current_second % 30 == 0, "tier_a_schedule"
    elif tier == TokenTier.TIER_B:
        # Tier B: 60ì´ˆë§ˆë‹¤ (0ì´ˆë§Œ)
        return current_second == 0, "tier_b_schedule"
    
    return False, "unknown_tier"

def can_consume_api_token_for_ticker(ticker: str) -> Tuple[bool, str]:
    """
    í•´ë‹¹ ì¢…ëª© ë¶„ì„ì„ ìœ„í•œ API í† í° ì†Œë¹„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        Tuple[bool, str]: (ì†Œë¹„ ê°€ëŠ¥ ì—¬ë¶€, ì‚¬ìœ )
    """
    try:
        rate_limiter = get_rate_limiter()
        tier = get_ticker_tier(ticker)
        
        if tier is None:
            # ë²¤ì¹˜ ì¢…ëª©ì€ ì˜ˆì•½ í† í° ì‚¬ìš©
            tier = TokenTier.RESERVE
        
        can_consume = rate_limiter.can_consume_token(tier)
        if can_consume:
            return True, f"token_available_{tier.value}"
        else:
            return False, f"token_exhausted_{tier.value}"
            
    except Exception as e:
        logger.error(f"í† í° í™•ì¸ ì‹¤íŒ¨: {e}")
        return False, f"token_check_error: {e}"

def consume_api_token_for_ticker(ticker: str) -> Tuple[bool, str]:
    """
    í•´ë‹¹ ì¢…ëª© ë¶„ì„ì„ ìœ„í•œ API í† í° ì‹¤ì œ ì†Œë¹„
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        Tuple[bool, str]: (ì†Œë¹„ ì„±ê³µ ì—¬ë¶€, ì‚¬ìœ )
    """
    try:
        rate_limiter = get_rate_limiter()
        tier = get_ticker_tier(ticker)
        
        if tier is None:
            # ë²¤ì¹˜ ì¢…ëª©ì€ ì˜ˆì•½ í† í° ì‚¬ìš© (Fallbackë„ ì‹œë„)
            success, used_tier = rate_limiter.try_consume_with_fallback(
                TokenTier.RESERVE, 
                TokenTier.TIER_B  # Reserve ë¶€ì¡±ì‹œ Tier B ì‚¬ìš©
            )
            return success, f"consumed_{used_tier.value}_for_bench"
        else:
            # Tier A/BëŠ” í•´ë‹¹ í† í° ì‚¬ìš©.
            # í…ŒìŠ¤íŠ¸ í•œì •: ë¶„ ì´ˆ 0â€“10s êµ¬ê°„ì—ë§Œ Tier A â†’ Reserve í´ë°± í—ˆìš©(ê·¸ ì™¸ì—” í´ë°± ê¸ˆì§€)
            fallback_tier = None
            if tier == TokenTier.TIER_A:
                from datetime import datetime
                now = datetime.utcnow()
                if 0 <= now.second <= 10:
                    fallback_tier = TokenTier.RESERVE
            success, used_tier = rate_limiter.try_consume_with_fallback(tier, fallback_tier)
            return success, f"consumed_{used_tier.value}"
            
    except Exception as e:
        logger.error(f"í† í° ì†Œë¹„ ì‹¤íŒ¨: {e}")
        return False, f"token_consume_error: {e}"

def get_universe_with_tiers() -> Dict[str, List[str]]:
    """
    Tierë³„ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
    Returns:
        Dict[str, List[str]]: Tierë³„ ì¢…ëª© ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ë™ì  ìœ ë‹ˆë²„ìŠ¤ ì¡°íšŒ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
        dynamic_universe = None
        try:
            rurl = os.getenv("REDIS_URL")
            if rurl:
                r = redis.from_url(rurl)
                external = r.smembers("universe:external") or []
                watch = r.smembers("universe:watchlist") or []
                core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
                ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
                wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
                merged = []
                seen = set()
                max_n = int(os.getenv("UNIVERSE_MAX", "100"))
                for arr in [core, ext, wch]:
                    for s in arr:
                        if s and s not in seen:
                            merged.append(s)
                            seen.add(s)
                        if len(merged) >= max_n:
                            break
                    if len(merged) >= max_n:
                        break
                dynamic_universe = merged
        except Exception:
            dynamic_universe = None
        
        # Fallback: ì„¤ì •ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        all_tickers = dynamic_universe or []
        if not all_tickers:
            all_tickers = (
                settings.TIER_A_TICKERS + 
                settings.TIER_B_TICKERS + 
                settings.BENCH_TICKERS
            )
        
        # Tierë³„ ë¶„ë¥˜
        tier_a = [t for t in all_tickers if get_ticker_tier(t) == TokenTier.TIER_A]
        tier_b = [t for t in all_tickers if get_ticker_tier(t) == TokenTier.TIER_B] 
        bench = [t for t in all_tickers if get_ticker_tier(t) is None]
        
        return {
            "tier_a": tier_a,
            "tier_b": tier_b,
            "bench": bench
        }
        
    except Exception as e:
        logger.error(f"ìœ ë‹ˆë²„ìŠ¤ Tier ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return {
            "tier_a": settings.TIER_A_TICKERS,
            "tier_b": settings.TIER_B_TICKERS,
            "bench": settings.BENCH_TICKERS
        }

def should_call_llm_for_event(ticker: str, event_type: str, signal_score: float = None, 
                              edgar_filing: Dict = None) -> Tuple[bool, str]:
    """
    LLM í˜¸ì¶œ ê²Œì´íŒ… ì‹œìŠ¤í…œ - ì—„ê²©í•œ ì´ë²¤íŠ¸ ê¸°ë°˜ íŠ¸ë¦¬ê±°ë§
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        event_type: ì´ë²¤íŠ¸ íƒ€ì… ('edgar', 'vol_spike')
        signal_score: ì‹ í˜¸ ì ìˆ˜ (vol_spikeìš©)
        edgar_filing: EDGAR ê³µì‹œ ì •ë³´
        
    Returns:
        Tuple[bool, str]: (í˜¸ì¶œ í—ˆìš© ì—¬ë¶€, ì‚¬ìœ )
    """
    try:
        # í…ŒìŠ¤íŠ¸ìš© RTH ê°•ì œ í”Œë˜ê·¸
        TEST_FORCE_RTH = os.getenv("TEST_FORCE_RTH", "0").lower() in ("1", "true", "on")
        
        # LLM ê²Œì´íŒ… ë¹„í™œì„±í™”ì‹œ ë¬´ì¡°ê±´ í—ˆìš©
        if not settings.LLM_GATING_ENABLED:
            return True, "gating_disabled"
        
        # 1. ì¼ì¼ í˜¸ì¶œ í•œë„ ì²´í¬
        rurl = os.getenv("REDIS_URL")
        if rurl:
            r = redis.from_url(rurl)
            
            # ET ê¸°ì¤€ ë‚ ì§œ í‚¤
            et_tz = timezone(timedelta(hours=-5))
            now_et = datetime.now(et_tz)
            if 3 <= now_et.month <= 11:  # DST ê°„ì´ ì ìš©
                et_tz = timezone(timedelta(hours=-4))
                now_et = datetime.now(et_tz)
            
            daily_key = f"llm_calls:{now_et:%Y%m%d}"
            current_calls = int(r.get(daily_key) or 0)
            
            if current_calls >= settings.LLM_DAILY_CALL_LIMIT:
                return False, f"daily_limit_exceeded ({current_calls}/{settings.LLM_DAILY_CALL_LIMIT})"
        
        # 2. ì´ë²¤íŠ¸ë³„ ì¡°ê±´ ê²€ì¦
        if event_type == "edgar":
            # EDGAR ì´ë²¤íŠ¸ëŠ” í•­ìƒ í—ˆìš© (ì¤‘ìš”ë„ ë†’ìŒ)
            cache_key = f"llm_cache:edgar:{ticker}:{edgar_filing.get('form_type', 'unknown')}"
            
        elif event_type == "vol_spike":
            # vol_spikeëŠ” ì‹ í˜¸ ì ìˆ˜ ì¡°ê±´ í•„ìš”
            if signal_score is None or abs(signal_score) < settings.LLM_MIN_SIGNAL_SCORE:
                logger.info(f"ğŸ¤– LLM gate: block {ticker}/{event_type} "
                           f"score={signal_score:.3f} < min={settings.LLM_MIN_SIGNAL_SCORE}")
                return False, "signal_score_too_low"
            
            cache_key = f"llm_cache:vol_spike:{ticker}"
            
        else:
            return False, f"unknown_event_type: {event_type}"
        
        # 3. ì¤‘ë³µ ë°©ì§€ ìºì‹œ ì²´í¬ (30ë¶„)
        if rurl:
            cached = r.get(cache_key)
            if cached:
                return False, f"cached_within_{settings.LLM_CACHE_DURATION_MIN}min"
        
        return True, f"allowed_{event_type}"
        
    except Exception as e:
        logger.error(f"LLM ê²Œì´íŒ… ì²´í¬ ì‹¤íŒ¨: {e}")
        # ì•ˆì „ì„ ìœ„í•´ ì—ëŸ¬ì‹œ ì°¨ë‹¨
        return False, f"gating_error: {e}"

def consume_llm_call_quota(ticker: str, event_type: str, edgar_filing: Dict = None) -> bool:
    """
    LLM í˜¸ì¶œ ì¿¼í„° ì‹¤ì œ ì†Œë¹„ ë° ìºì‹œ ë§ˆí‚¹
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        event_type: ì´ë²¤íŠ¸ íƒ€ì…
        edgar_filing: EDGAR ê³µì‹œ ì •ë³´
        
    Returns:
        bool: ì†Œë¹„ ì„±ê³µ ì—¬ë¶€
    """
    try:
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return True
        
        r = redis.from_url(rurl)
        
        # ì¼ì¼ ì¹´ìš´í„° ì¦ê°€
        et_tz = timezone(timedelta(hours=-5))
        now_et = datetime.now(et_tz)
        if 3 <= now_et.month <= 11:
            et_tz = timezone(timedelta(hours=-4))
            now_et = datetime.now(et_tz)
        
        daily_key = f"llm_calls:{now_et:%Y%m%d}"
        r.incr(daily_key)
        r.expire(daily_key, 86400)  # 24ì‹œê°„ TTL
        
        # ìºì‹œ ë§ˆí‚¹
        if event_type == "edgar":
            cache_key = f"llm_cache:edgar:{ticker}:{edgar_filing.get('form_type', 'unknown')}"
        else:
            cache_key = f"llm_cache:vol_spike:{ticker}"
        
        r.setex(cache_key, settings.LLM_CACHE_DURATION_MIN * 60, 1)
        
        return True
        
    except Exception as e:
        logger.error(f"LLM ì¿¼í„° ì†Œë¹„ ì‹¤íŒ¨: {e}")
        return False

def get_llm_usage_stats() -> Dict[str, int]:
    """
    LLM ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ
    
    Returns:
        Dict: ì‚¬ìš©ëŸ‰ í†µê³„
    """
    try:
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return {"daily_used": 0, "daily_limit": settings.LLM_DAILY_CALL_LIMIT}
        
        r = redis.from_url(rurl)
        
        et_tz = timezone(timedelta(hours=-5))
        now_et = datetime.now(et_tz)
        if 3 <= now_et.month <= 11:
            et_tz = timezone(timedelta(hours=-4))
            now_et = datetime.now(et_tz)
        
        daily_key = f"llm_calls:{now_et:%Y%m%d}"
        daily_used = int(r.get(daily_key) or 0)
        
        return {
            "daily_used": daily_used,
            "daily_limit": settings.LLM_DAILY_CALL_LIMIT,
            "remaining": max(0, settings.LLM_DAILY_CALL_LIMIT - daily_used),
            "usage_pct": (daily_used / settings.LLM_DAILY_CALL_LIMIT) * 100 if settings.LLM_DAILY_CALL_LIMIT > 0 else 0
        }
        
    except Exception as e:
        logger.error(f"LLM ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"daily_used": 0, "daily_limit": settings.LLM_DAILY_CALL_LIMIT, "error": str(e)}

# ============================================================================
# í¬ì§€ì…˜ ê´€ë¦¬ ë° ë¦¬ìŠ¤í¬ ê³„ì‚° í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================================================

# ê±°ë˜ íŒŒë¼ë¯¸í„° (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
BUY_THRESHOLD = float(os.getenv("BUY_THRESHOLD", "0.15"))
SELL_THRESHOLD = float(os.getenv("SELL_THRESHOLD", "-0.15")) 
COOLDOWN_SECONDS = int(os.getenv("COOLDOWN_SECONDS", "120"))
DIRECTION_LOCK_SECONDS = int(os.getenv("DIRECTION_LOCK_SECONDS", "90"))
RISK_PER_TRADE = float(os.getenv("RISK_PER_TRADE", "0.005"))  # 0.5%
MAX_CONCURRENT_RISK = float(os.getenv("MAX_CONCURRENT_RISK", "0.02"))  # 2%
STOP_LOSS_PCT = float(os.getenv("STOP_LOSS_PCT", "0.015"))  # 1.5%
TAKE_PROFIT_RR = float(os.getenv("TAKE_PROFIT_RR", "1.5"))  # 1.5R
EOD_FLATTEN_MINUTES = int(os.getenv("EOD_FLATTEN_MINUTES", "10"))  # ê¸°ë³¸ 10ë¶„ ì „ìœ¼ë¡œ í™•ëŒ€
FRACTIONAL_ENABLED = os.getenv("FRACTIONAL_ENABLED", "0") == "1"

# ê°€ë“œë ˆì¼ í”Œë˜ê·¸/íŒŒë¼ë¯¸í„°
ENABLE_TIME_STOP = os.getenv("ENABLE_TIME_STOP", "1") in ("1", "true", "True")
TIME_STOP_MIN = int(os.getenv("TIME_STOP_MIN", "45"))
TIME_STOP_LATE_ENTRY_CUTOFF_MIN = int(os.getenv("TIME_STOP_LATE_ENTRY_CUTOFF_MIN", "10"))

ENABLE_TRAIL_STOP = os.getenv("ENABLE_TRAIL_STOP", "0") in ("1", "true", "True")
TRAIL_RET_PCT = float(os.getenv("TRAIL_RET_PCT", "0.005"))
TRAIL_MIN_HOLD_MIN = int(os.getenv("TRAIL_MIN_HOLD_MIN", "5"))

ENABLE_REGIME_FLATTEN_INVERSE = os.getenv("ENABLE_REGIME_FLATTEN_INVERSE", "1") in ("1", "true", "True")
INVERSE_TICKERS_ENV = os.getenv("INVERSE_TICKERS", "SOXS,SQQQ,SPXS,TZA,SDOW,TECS,DRV,SARK")
INVERSE_TICKERS_SET = set(t.strip().upper() for t in INVERSE_TICKERS_ENV.split(",") if t.strip())

# EOD ì¬ì‹œë„ íŒŒë¼ë¯¸í„°
EOD_MAX_RETRIES = int(os.getenv("EOD_MAX_RETRIES", "2"))
EOD_RETRY_DELAY_SEC = int(os.getenv("EOD_RETRY_DELAY_SEC", "30"))

# ìˆ ETF ì²­ì‚° ë¡œì§ íŒŒë¼ë¯¸í„°
MIN_HOLD_SEC = int(os.getenv("MIN_HOLD_SEC", "60"))  # ìµœì†Œ ë³´ìœ ì‹œê°„ 60ì´ˆ
TRAIL_R_RATIO = float(os.getenv("TRAIL_R_RATIO", "0.7"))  # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘ ë¹„ìœ¨ 0.7R
VOLUME_SPIKE_MULTIPLIER = float(os.getenv("VOLUME_SPIKE_MULTIPLIER", "1.5"))  # ë³¼ë¥¨ ìŠ¤íŒŒì´í¬ 1.5ë°°
CANDLE_BREAK_EPSILON = float(os.getenv("CANDLE_BREAK_EPSILON", "0.01"))  # ìº”ë“¤ ë¸Œë ˆì´í¬ ì„ê³„ê°’

# ì¸ë²„ìŠ¤ ETF ë©”íƒ€ë°ì´í„°
INSTRUMENT_META = {
    "AAPL": {"underlying": "AAPL", "exposure_sign": +1, "min_qty": 1},
    "NVDA": {"underlying": "NVDA", "exposure_sign": +1, "min_qty": 1},
    "TSLA": {"underlying": "TSLA", "exposure_sign": +1, "min_qty": 1},
    "MSFT": {"underlying": "MSFT", "exposure_sign": +1, "min_qty": 1},
    "SQQQ": {"underlying": "QQQ", "exposure_sign": -1, "min_qty": 1},
    "SOXS": {"underlying": "SOXX", "exposure_sign": -1, "min_qty": 1},
    "SPXS": {"underlying": "SPY", "exposure_sign": -1, "min_qty": 1},
    "TZA": {"underlying": "IWM", "exposure_sign": -1, "min_qty": 1},
    "SDOW": {"underlying": "DIA", "exposure_sign": -1, "min_qty": 1},
    "TECS": {"underlying": "XLK", "exposure_sign": -1, "min_qty": 1},
    "DRV": {"underlying": "XLE", "exposure_sign": -1, "min_qty": 1},
    "SARK": {"underlying": "ARKK", "exposure_sign": -1, "min_qty": 1},
}

# ë°”ìŠ¤ì¼“ ê¸°ë°˜ ë¼ìš°íŒ… ì‹œìŠ¤í…œ
BASKETS = {
    "MEGATECH": {
        "tickers": {"AAPL", "MSFT", "AMZN", "META", "GOOGL", "TSLA"},
        "etf": "SQQQ",  # NASDAQ-100 ì¸ë²„ìŠ¤
        "min_signals": 1,  # ìµœì†Œ 1ê°œ ì¢…ëª©ì—ì„œ ì‹ í˜¸ 
        "neg_fraction": 0.20,  # 20% ì´ìƒ ìŒìˆ˜ (ì ë‹¹íˆ ì™„í™”)
        "mean_threshold": -0.05  # í‰ê·  ìŠ¤ì½”ì–´ -0.05 ì´í•˜
    },
    "SEMIS": {
        "tickers": {"NVDA", "AMD", "AVGO"},
        "etf": "SOXS",  # ë°˜ë„ì²´ ì¸ë²„ìŠ¤
        "min_signals": 1,  # ì™„í™”
        "neg_fraction": 0.25,  # 25% ì´ìƒ ìŒìˆ˜
        "mean_threshold": -0.05  # í‰ê·  ìŠ¤ì½”ì–´ -0.05 ì´í•˜
    }
}

# ì¸ë²„ìŠ¤ ETF ëª©ë¡
INVERSE_ETFS = {"SQQQ", "SOXS", "SPXS", "TZA", "SDOW", "TECS", "DRV", "SARK"}

# ìƒì¶© í¬ì§€ì…˜ ë§µ
CONFLICT_MAP = {
    "SQQQ": {"QQQ"},      # NASDAQ ë¡±/ìˆ ë™ì‹œ ê¸ˆì§€
    "SOXS": {"SOXL", "SOXX"},  # ë°˜ë„ì²´ ë¡±/ìˆ ë™ì‹œ ê¸ˆì§€
    "SPXS": {"SPY"},      # S&P 500 ë¡±/ìˆ ë™ì‹œ ê¸ˆì§€
    "TZA": {"IWM"},       # Russell 2000 ë¡±/ìˆ ë™ì‹œ ê¸ˆì§€
    "SDOW": {"DIA"},      # Dow Jones ë¡±/ìˆ ë™ì‹œ ê¸ˆì§€
}

def get_basket_for_symbol(symbol: str) -> Optional[str]:
    """ì‹¬ë³¼ì´ ì†í•œ ë°”ìŠ¤ì¼“ ì°¾ê¸°"""
    for basket_name, basket_info in BASKETS.items():
        if symbol in basket_info["tickers"]:
            return basket_name
    return None

def get_basket_state(basket_name: str, window_seconds: int = None) -> Dict[str, Any]:
    """
    ë°”ìŠ¤ì¼“ ìƒíƒœ ì§‘ê³„ (signals:recent ë¦¬ìŠ¤íŠ¸ì—ì„œ ìµœê·¼ ì‹ í˜¸ë“¤ ë¶„ì„)
    
    Returns:
        {"neg_count": int, "total_count": int, "mean_score": float, 
         "neg_fraction": float, "two_tick": bool, "slope": float}
    """
    try:
        # íŒŒë¼ë¯¸í„° ëª…í™•í™”
        WINDOW_SEC = int(os.getenv("BASKET_WINDOW_SEC", "120"))
        SAMPLE_N = int(os.getenv("BASKET_SAMPLE_N", "200"))
        
        if window_seconds is None:
            window_seconds = WINDOW_SEC
            
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return {"neg_count": 0, "total_count": 0, "mean_score": 0, 
                   "neg_fraction": 0, "two_tick": False, "slope": 0}
        
        r = redis.from_url(rurl)
        basket_info = BASKETS.get(basket_name, {})
        tickers = basket_info.get("tickers", set())
        
        # signals:recent ë¦¬ìŠ¤íŠ¸ì—ì„œ ìµœê·¼ ì‹ í˜¸ë“¤ ìˆ˜ì§‘
        now = time.time()
        cutoff_time = now - window_seconds
        
        current_scores = []
        trend_scores = []  # slope ê³„ì‚°ìš©
        
        # signals:recent ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„¤ì •ëœ í‘œë³¸ ìˆ˜ë§Œí¼ ê°€ì ¸ì˜¤ê¸°
        recent_signals = r.lrange("signals:recent", 0, SAMPLE_N - 1)
        
        for signal_data in recent_signals:
            try:
                signal_info = json.loads(signal_data)
                ticker = signal_info.get("ticker")
                score = signal_info.get("score", 0)
                timestamp_str = signal_info.get("timestamp", "")
                
                # ë°”ìŠ¤ì¼“ì— ì†í•œ ì¢…ëª©ë§Œ ì²˜ë¦¬
                if ticker not in tickers:
                    continue
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± (ISO í˜•ì‹)
                if timestamp_str:
                    try:
                        from datetime import datetime
                        timestamp = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00')).timestamp()
                    except:
                        continue
                else:
                    continue
                
                # í˜„ì¬ ìœˆë„ìš° ë‚´ ì‹ í˜¸ë§Œ ì‚¬ìš©
                if timestamp >= cutoff_time:
                    current_scores.append(score)
                    trend_scores.append((timestamp, score))
            except Exception as e:
                logger.debug(f"ì‹ í˜¸ íŒŒì‹± ì‹¤íŒ¨: {e}")
                continue
        
        if not current_scores:
            return {"neg_count": 0, "total_count": 0, "mean_score": 0, 
                   "neg_fraction": 0, "two_tick": False, "slope": 0}
        
        neg_count = sum(1 for s in current_scores if s < -0.01)
        total_count = len(current_scores)
        mean_score = sum(current_scores) / len(current_scores) if current_scores else 0
        neg_fraction = neg_count / total_count if total_count > 0 else 0
        
        # 2í‹± í™•ì¸ (ì´ì „ ìœˆë„ìš°ì™€ ë¹„êµ)
        prev_key = f"basket_state:{basket_name}:prev"
        prev_data = r.get(prev_key)
        two_tick = False
        if prev_data:
            try:
                prev_state = json.loads(prev_data)
                if prev_state.get("neg_fraction", 0) >= 0.5 and neg_fraction >= 0.5:
                    two_tick = True
            except:
                pass
        
        # í˜„ì¬ ìƒíƒœ ì €ì¥ (ë‹¤ìŒ ë¹„êµìš©)
        r.setex(prev_key, 120, json.dumps({
            "neg_fraction": neg_fraction,
            "mean_score": mean_score,
            "timestamp": now
        }))
        
        # ì‹¤ì œ slope ê³„ì‚° (ê°„ë‹¨í•œ ì„ í˜• íšŒê·€)
        slope = 0
        if len(trend_scores) >= 3:
            # ì‹œê°„ìˆœ ì •ë ¬
            trend_scores.sort(key=lambda x: x[0])
            
            # ê°„ë‹¨í•œ ê¸°ìš¸ê¸° ê³„ì‚°: (ë§ˆì§€ë§‰ - ì²˜ìŒ) / ì‹œê°„ì°¨ì´
            if len(trend_scores) >= 2:
                first_score = trend_scores[0][1]
                last_score = trend_scores[-1][1]
                time_diff = trend_scores[-1][0] - trend_scores[0][0]
                if time_diff > 0:
                    slope = (last_score - first_score) / time_diff
        
        return {
            "neg_count": neg_count,
            "total_count": total_count,
            "mean_score": mean_score,
            "neg_fraction": neg_fraction,
            "two_tick": two_tick,
            "slope": slope
        }
        
    except Exception as e:
        logger.error(f"ë°”ìŠ¤ì¼“ ìƒíƒœ ì§‘ê³„ ì‹¤íŒ¨: {e}")
        return {"neg_count": 0, "total_count": 0, "mean_score": 0, 
               "neg_fraction": 0, "two_tick": False, "slope": 0}

def has_existing_position(symbol: str) -> bool:
    """ê¸°ì¡´ í¬ì§€ì…˜ ì¡´ì¬ ì—¬ë¶€ ì²´í¬ (GPT ìš”êµ¬: ì¶”ê°€ ë§¤ìˆ˜ ê¸ˆì§€)"""
    try:
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        positions = trading_adapter.get_positions()
        
        for pos in positions:
            if pos.ticker == symbol and pos.quantity > 0:
                return True
        return False
        
    except Exception as e:
        logger.warning(f"í¬ì§€ì…˜ ì²´í¬ ì‹¤íŒ¨: {e}")
        return False

def can_open_etf_position(etf_symbol: str) -> Tuple[bool, str]:
    """
    ETF í¬ì§€ì…˜ ì˜¤í”ˆ ê°€ëŠ¥ ì—¬ë¶€ ì²´í¬
    - ETF ë½ ì²´í¬
    - ê¸°ì¡´ í¬ì§€ì…˜ ì²´í¬
    - ìƒì¶© í¬ì§€ì…˜ ì²´í¬
    """
    try:
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return True, "redis_not_available"
        
        r = redis.from_url(rurl)
        
        # 1. ETF ë½ ì²´í¬ (90ì´ˆ TTL)
        lock_key = f"etf_lock:{etf_symbol}"
        if not r.setnx(lock_key, 1):
            return False, "etf_locked"
        r.expire(lock_key, 90)
        
        # 2. ìƒì¶© í¬ì§€ì…˜ ì²´í¬
        conflicts = CONFLICT_MAP.get(etf_symbol, set())
        for conflict_symbol in conflicts:
            if has_existing_position(conflict_symbol):
                r.delete(lock_key)  # ë½ í•´ì œ
                return False, f"conflict_with_{conflict_symbol}"
        
        return True, "ok"
        
    except Exception as e:
        logger.error(f"ETF í¬ì§€ì…˜ ì²´í¬ ì‹¤íŒ¨: {e}")
        return False, f"error_{e}"

def route_signal_symbol(original_symbol: str, base_score: float) -> Dict[str, str]:
    """
    ë°”ìŠ¤ì¼“ ê¸°ë°˜ ì‹ í˜¸ ë¼ìš°íŒ… (ê°œì„ ëœ ë²„ì „)
    
    Args:
        original_symbol: ì›ë˜ ì‹ í˜¸ ì‹¬ë³¼
        base_score: ì›ë˜ ì‹ í˜¸ ìŠ¤ì½”ì–´
        
    Returns:
        ë¼ìš°íŒ… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # ì¸ë²„ìŠ¤ ETFëŠ” ë¼ìš°íŒ…í•˜ì§€ ì•ŠìŒ (íŒ¨ìŠ¤ìŠ¤ë£¨)
    if original_symbol in INVERSE_ETFS:
        return {
            "exec_symbol": original_symbol,
            "intent": "direct",
            "route_reason": "inverse_etf_passthrough"
        }
    
    # ë¡± ì‹ í˜¸ëŠ” ì›ë˜ ì‹¬ë³¼ ê·¸ëŒ€ë¡œ
    if base_score >= 0:
        return {
            "exec_symbol": original_symbol,
            "intent": "enter_long",
            "route_reason": f"{original_symbol}->ìì²´(ë¡±)"
        }
    
    # ìˆ ì‹ í˜¸: ë°”ìŠ¤ì¼“ ì²´í¬
    basket_name = get_basket_for_symbol(original_symbol)
    if not basket_name:
        # ë°”ìŠ¤ì¼“ì— ì†í•˜ì§€ ì•ŠëŠ” ì¢…ëª©ì€ ìŠ¤í‚µ (SPXS fallback ì œê±°)
        return {
            "exec_symbol": None,
            "intent": "skip",
            "route_reason": "not_in_any_basket"
        }
    
    # ë°”ìŠ¤ì¼“ ìƒíƒœ í™•ì¸
    basket_state = get_basket_state(basket_name)
    basket_info = BASKETS[basket_name]
    
    # ë°”ìŠ¤ì¼“ ì¡°ê±´ ì²´í¬ (í…ŒìŠ¤íŠ¸ìš© ê·¹ë„ ì™„í™”)
    conditions_met = (
        basket_state["total_count"] >= basket_info.get("min_signals", 1) and
        basket_state["neg_fraction"] >= basket_info.get("neg_fraction", 0.0) and
        basket_state["mean_score"] <= basket_info.get("mean_threshold", 0.5)
        # 2í‹± ë° slope ì¡°ê±´ ì œê±° - ë„ˆë¬´ ê¹Œë‹¤ë¡œì›€
    )
    
    if not conditions_met:
        # ìƒì„¸ ë¡œê·¸ë¡œ ë°”ìŠ¤ì¼“ ìƒíƒœ ì¶œë ¥ (GPT ìš”êµ¬)
        state_detail = f"nf={basket_state['neg_fraction']:.2f},mean={basket_state['mean_score']:.3f},slope={basket_state['slope']:.4f},2tick={basket_state['two_tick']}"
        return {
            "exec_symbol": None,
            "intent": "suppress",
            "route_reason": f"basket_conditions_not_met_{basket_name}({state_detail})"
        }
    
    # ETF ê²°ì •
    target_etf = basket_info["etf"]
    
    # ê¸°ì¡´ í¬ì§€ì…˜ ì²´í¬ (GPT ìš”êµ¬: ì¶”ê°€ ë§¤ìˆ˜ ê¸ˆì§€) - ë¹„í™œì„±í™”ë¨
    # if has_existing_position(target_etf):
    #     return {
    #         "exec_symbol": None,
    #         "intent": "suppress",
    #         "route_reason": f"position_exists_{target_etf}"
    #     }
    
    # ETF í¬ì§€ì…˜ ì˜¤í”ˆ ê°€ëŠ¥ ì²´í¬ (ë½ ë° ìƒì¶©)
    can_open, reason = can_open_etf_position(target_etf)
    if not can_open:
        return {
            "exec_symbol": None,
            "intent": "block",
            "route_reason": f"etf_blocked_{reason}"
        }
    
    # ì„±ê³µì  ë¼ìš°íŒ… (ìƒì„¸ ë¡œê·¸ í¬í•¨)
    state_detail = f"nf={basket_state['neg_fraction']:.2f},mean={basket_state['mean_score']:.3f},slope={basket_state['slope']:.4f},2tick={basket_state['two_tick']}"
    return {
        "exec_symbol": target_etf,
        "intent": "enter_inverse",
        "route_reason": f"{basket_name}_cluster->{target_etf}({state_detail})"
    }

def is_actionable_signal(effective_score: float) -> bool:
    """ì‹ í˜¸ê°€ ì•¡ì…˜ ê°€ëŠ¥í•œì§€ í™•ì¸"""
    return effective_score >= BUY_THRESHOLD or effective_score <= SELL_THRESHOLD

def claim_idempotency(redis_client, event_id: str, ttl: int = 900) -> bool:
    """ì¤‘ë³µ ì´ë²¤íŠ¸ ì²˜ë¦¬ ë°©ì§€"""
    key = f"seen:{event_id}"
    if redis_client.setnx(key, 1):
        redis_client.expire(key, ttl)
        return True
    return False

def is_in_cooldown(redis_client, symbol: str) -> bool:
    """ì‹¬ë³¼ë³„ ì¿¨ë‹¤ìš´ í™•ì¸"""
    return redis_client.ttl(f"cooldown:{symbol}") > 0

def set_cooldown(redis_client, symbol: str, seconds: int) -> None:
    """ì‹¬ë³¼ë³„ ì¿¨ë‹¤ìš´ ì„¤ì •"""
    redis_client.setex(f"cooldown:{symbol}", seconds, 1)

def is_direction_locked(redis_client, symbol: str, wanted_direction: str) -> bool:
    """ë°©í–¥ë½ í™•ì¸ (ë°˜ëŒ€ ë°©í–¥ ì¬ì§„ì… ì°¨ë‹¨)"""
    current_lock = redis_client.get(f"dirlock:{symbol}")
    if not current_lock:
        return False
    
    current_direction = current_lock.decode()
    # long ì›í•˜ëŠ”ë° short ë½ì´ ê±¸ë ¤ìˆê±°ë‚˜, short ì›í•˜ëŠ”ë° long ë½ì´ ê±¸ë ¤ìˆìœ¼ë©´ ì°¨ë‹¨
    if wanted_direction == "long" and current_direction == "short":
        return True
    if wanted_direction == "short" and current_direction == "long":
        return True
    return False

def set_direction_lock(redis_client, symbol: str, direction: str, seconds: int) -> None:
    """ë°©í–¥ë½ ì„¤ì •"""
    redis_client.setex(f"dirlock:{symbol}", seconds, direction)

def clear_direction_lock(redis_client, symbol: str) -> None:
    """ë°©í–¥ë½ í•´ì œ"""
    redis_client.delete(f"dirlock:{symbol}")

def exceeds_daily_cap(redis_client, symbol: str) -> bool:
    """ì¼ì¼ ì‹ í˜¸ í•œë„ í™•ì¸"""
    cap = int(os.getenv("RTH_DAILY_CAP", "100"))
    key = get_daily_key("cap", symbol)
    current_count = int(redis_client.get(key) or 0)
    return current_count >= cap

def count_daily_cap(redis_client, symbol: str) -> bool:
    """ì¼ì¼ ì‹ í˜¸ ì¹´ìš´íŠ¸ ì¦ê°€ (idempotency ì ìš©)"""
    # GPT ê¶Œì¥: ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€ë¥¼ ìœ„í•œ idempotency í‚¤
    slot_id = int(time.time() // 90)  # 90ì´ˆ ìŠ¬ë¡¯
    date_str = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    idempotency_key = f"cap:{symbol}:{date_str}:{slot_id}"
    
    # ì´ë¯¸ ì¹´ìš´íŠ¸í–ˆìœ¼ë©´ ìŠ¤í‚µ
    if not redis_client.setnx(idempotency_key, 1):
        logger.debug(f"ì¼ì¼ ìº¡ ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€: {symbol}")
        return False
    
    redis_client.expire(idempotency_key, 90)  # 90ì´ˆ TTL
    
    # ì‹¤ì œ ì¹´ìš´íŠ¸ ì¦ê°€
    key = get_daily_key("cap", symbol)
    redis_client.incr(key)
    
    # TTLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ET ìì •ê¹Œì§€ ì„¤ì •
    if redis_client.ttl(key) < 0:
        next_reset = get_next_rth_reset_timestamp()
        redis_client.expireat(key, int(next_reset.timestamp()))
    return True

def get_daily_key(prefix: str, symbol: str) -> str:
    """ì¼ì¼ ê¸°ì¤€ Redis í‚¤ ìƒì„±"""
    date_str = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    return f"{prefix}:{symbol}:{date_str}"

def get_next_rth_reset_timestamp() -> datetime:
    """ë‹¤ìŒ RTH ë¦¬ì…‹ ì‹œê°„ (ë¯¸ ë™ë¶€ì‹œê°„ ìì • ê¸°ì¤€)"""
    import pytz
    
    # ë¯¸ ë™ë¶€ì‹œê°„ ìì •ìœ¼ë¡œ ì„¤ì •
    et = pytz.timezone("America/New_York")
    now_et = datetime.now(et)
    
    # ë‹¤ìŒ ìì • ê³„ì‚°
    next_midnight = (now_et + timedelta(days=1)).replace(
        hour=0, minute=0, second=0, microsecond=0
    )
    
    # UTCë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
    return next_midnight.astimezone(timezone.utc)

def get_open_position(trading_adapter, symbol: str) -> Optional[Dict]:
    """í˜„ì¬ ì˜¤í”ˆ í¬ì§€ì…˜ í™•ì¸"""
    try:
        positions = trading_adapter.get_positions()
        for pos in positions:
            if getattr(pos, 'ticker', None) == symbol and float(getattr(pos, 'quantity', 0)) != 0:
                qty = float(pos.quantity)
                return {
                    "symbol": symbol,
                    "qty": qty,
                    "avg_price": float(getattr(pos, 'avg_price', 0) or 0),
                    "side": "long" if qty > 0 else "short",
                    "unrealized_pl": float(getattr(pos, 'unrealized_pnl', 0) or 0),
                    "market_value": float(getattr(pos, 'market_value', 0) or 0),
                    "added_layers": getattr(pos, 'added_layers', 0)
                }
        return None
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ì¡°íšŒ ì‹¤íŒ¨ {symbol}: {e}")
        return None

def get_stop_distance(trading_adapter, symbol: str, fallback_pct: float = None) -> float:
    """ìŠ¤í†± ê±°ë¦¬ ê³„ì‚° (ATR ê¸°ë°˜ ë˜ëŠ” í¼ì„¼íŠ¸ í´ë°±)"""
    if fallback_pct is None:
        fallback_pct = STOP_LOSS_PCT
    
    try:
        # í˜„ì¬ ê°€ê²© ì¡°íšŒ
        current_price = trading_adapter.get_current_price(symbol)
        if not current_price or current_price <= 0:
            return 0
        
        # ATR ê¸°ë°˜ ìŠ¤í†± ê±°ë¦¬ ê³„ì‚° ì‹œë„
        atr = get_atr_from_db(symbol, periods=14)
        if atr and atr > 0:
            # GPT ê¶Œì¥: ATRì˜ 0.7ë°°, ìµœì†Œ 0.4% ë³´ì¥
            k = 0.7  # ë³´ìˆ˜ì  ë©€í‹°í”Œë¼ì´ì–´
            return max(atr * k, current_price * 0.004)
        
        # í´ë°±: ê³ ì • í¼ì„¼íŠ¸
        return current_price * fallback_pct
    except Exception as e:
        logger.error(f"ìŠ¤í†± ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨ {symbol}: {e}")
        return 0

def get_atr_from_db(symbol: str, periods: int = 14) -> Optional[float]:
    """DBì—ì„œ ATR(Average True Range) ê³„ì‚°"""
    try:
        # PostgreSQL ì—°ê²°
        conn_str = os.getenv("DATABASE_URL")
        if not conn_str:
            return None
        
        conn = psycopg2.connect(conn_str)
        cursor = conn.cursor()
        
        # ìµœê·¼ Nê°œ ìº”ë“¤ì—ì„œ TR ê³„ì‚° í›„ í‰ê· 
        query = """
        WITH candles AS (
            SELECT 
                h as high,
                l as low,
                c as close,
                LAG(c) OVER (ORDER BY ts) as prev_close
            FROM bars_30s
            WHERE ticker = %s
            ORDER BY ts DESC
            LIMIT %s
        ),
        true_range AS (
            SELECT 
                GREATEST(
                    high - low,
                    ABS(high - COALESCE(prev_close, close)),
                    ABS(low - COALESCE(prev_close, close))
                ) as tr
            FROM candles
            WHERE prev_close IS NOT NULL
        )
        SELECT AVG(tr) as atr
        FROM true_range
        """
        
        cursor.execute(query, (symbol, periods + 1))
        result = cursor.fetchone()
        
        cursor.close()
        conn.close()
        
        if result and result[0]:
            return float(result[0])
        return None
        
    except Exception as e:
        logger.warning(f"ATR ê³„ì‚° ì‹¤íŒ¨ {symbol}: {e}")
        return None

def calc_entry_quantity(trading_adapter, symbol: str, equity: float, stop_distance: float) -> int:
    """ì§„ì… ìˆ˜ëŸ‰ ê³„ì‚° (GPT ê¶Œì¥ ë¦¬ìŠ¤í¬ ê¸°ë°˜ ì‚¬ì´ì§•)"""
    try:
        current_price = trading_adapter.get_current_price(symbol)
        if not current_price or current_price <= 0 or stop_distance <= 0:
            return 0
        
        # === 1. ì‚¬ì´ì§• ìë³¸ ì˜¤ë²„ë¼ì´ë“œ (GPT ê¶Œì¥) ===
        sizing_mode = os.getenv("SIZING_EQUITY_MODE", "broker")
        if sizing_mode == "override":
            equity_krw = float(os.getenv("SIZING_EQUITY_KRW", "1000000"))
            usd_krw_rate = float(os.getenv("USD_KRW_RATE", "1350"))
            equity_usd = equity_krw / usd_krw_rate
        else:
            # ê¸°ì¡´ ë¸Œë¡œì»¤ ê³„ì¢Œ ê¸°ì¤€ (USD)
            equity_usd = equity
            equity_krw = equity * float(os.getenv("USD_KRW_RATE", "1350"))
        
        # === 2. ê³ ê°€ ì¢…ëª© í•˜ë“œ í•„í„° (GPT ê¶Œì¥) ===
        max_price_per_share = float(os.getenv("MAX_PRICE_PER_SHARE_USD", "120"))
        if current_price > max_price_per_share and not FRACTIONAL_ENABLED:
            logger.warning(f"ğŸš« ê³ ê°€ì¢…ëª© ìŠ¤í‚µ: {symbol} ${current_price:.2f} > ${max_price_per_share}")
            return 0  # suppress("price_cap_exceeded")
        
        # ë¦¬ìŠ¤í¬ ê¸ˆì•¡ = ê³„ì¢Œ ìì‚° * ê±°ë˜ë‹¹ ë¦¬ìŠ¤í¬ ë¹„ìœ¨
        risk_amount_usd = equity_usd * RISK_PER_TRADE
        
        # í¬ì§€ì…˜ ì‚¬ì´ì¦ˆ = ë¦¬ìŠ¤í¬ ê¸ˆì•¡ / ìŠ¤í†± ê±°ë¦¬
        raw_qty = risk_amount_usd / stop_distance
        
        # === 3. í”„ë™ì…”ë„ ìŠ¤ìœ„ì¹˜ ëª…í™•í™” (GPT ê¶Œì¥) ===
        min_notional_usd = float(os.getenv("MIN_ORDER_NOTIONAL_USD", "20"))
        if FRACTIONAL_ENABLED:
            qty = round(raw_qty, 2)  # ì†Œìˆ˜ì  2ìë¦¬
        else:
            qty = math.floor(raw_qty)
        
        # ìµœì†Œ ì£¼ë¬¸ ê¸ˆì•¡ ì²´í¬
        if qty * current_price < min_notional_usd:
            logger.warning(f"ğŸš« ìµœì†Œ ì£¼ë¬¸ê¸ˆì•¡ ë¯¸ë‹¬: {symbol} ${qty * current_price:.2f} < ${min_notional_usd}")
            return 0  # suppress("notional_too_small")
        
        # === 4. ë…¸ì¶œ ìƒí•œ (í•œí™” ê¸°ì¤€) ì„¸ì´í”„í‹°ë„· (GPT ê¶Œì¥) ===
        max_notional_krw = float(os.getenv("MAX_NOTIONAL_PER_TRADE_KRW", "600000"))
        notional_krw = qty * current_price * float(os.getenv("USD_KRW_RATE", "1350"))
        if notional_krw > max_notional_krw:
            # í•œí™” ê¸°ì¤€ ìƒí•œì— ë§ì¶° ìˆ˜ëŸ‰ ì¡°ì •
            adjusted_qty = int(max_notional_krw / (current_price * float(os.getenv("USD_KRW_RATE", "1350"))))
            logger.warning(f"âš ï¸ í•œí™” ë…¸ì¶œ ìƒí•œ ì¡°ì •: {symbol} {qty}ì£¼ â†’ {adjusted_qty}ì£¼ (â‚©{notional_krw:,.0f} â†’ â‚©{max_notional_krw:,.0f})")
            qty = adjusted_qty
        
        # ìµœì†Œ ìˆ˜ëŸ‰ ë³´ì¥
        meta = INSTRUMENT_META.get(symbol, {"min_qty": 1})
        min_qty = meta["min_qty"]
        final_qty = max(qty, min_qty) if qty > 0 else 0
        
        # === 5. ì‚¬ì´ì§• ë””ë²„ê·¸ ë¡œê·¸ (GPT ê¶Œì¥) ===
        logger.info(
            f"ğŸ“Š sizing: equity_krw={equity_krw:,.0f} equity_usd={equity_usd:.0f} "
            f"risk={RISK_PER_TRADE*100}% risk_usd={risk_amount_usd:.2f} "
            f"stop={stop_distance:.2f} last={current_price:.2f} qty={final_qty} "
            f"fractional={'ON' if FRACTIONAL_ENABLED else 'OFF'} "
            f"notional_krw={final_qty * current_price * float(os.getenv('USD_KRW_RATE', '1350')):,.0f} "
            f"decision={'enter' if final_qty > 0 else 'skip'}"
        )
        
        return final_qty
    except Exception as e:
        logger.error(f"ì§„ì… ìˆ˜ëŸ‰ ê³„ì‚° ì‹¤íŒ¨ {symbol}: {e}")
        return 0

def calc_add_quantity(trading_adapter, symbol: str, position: Dict, equity: float, stop_distance: float) -> int:
    """ì¶”ê°€ ë§¤ìˆ˜ ìˆ˜ëŸ‰ ê³„ì‚° (GPT ê¶Œì¥ í”¼ë¼ë¯¸ë”©)"""
    try:
        # ê¸°ë³¸ ìˆ˜ëŸ‰ì˜ 50% (GPT ê¶Œì¥: ë³´ìˆ˜ì  í”¼ë¼ë¯¸ë”©)
        base_qty = calc_entry_quantity(trading_adapter, symbol, equity, stop_distance)
        add_qty = base_qty * 0.5  # ì´ˆê¸° ìˆ˜ëŸ‰ì˜ 50%
        
        # í˜„ì¬ í¬ì§€ì…˜ í¬ê¸° ê³ ë ¤
        current_qty = abs(position.get("qty", 0))
        current_price = trading_adapter.get_current_price(symbol)
        
        # ì¶”ê°€ í›„ ì´ í¬ì§€ì…˜ì´ ê³„ì¢Œì˜ 40%ë¥¼ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡
        if current_price > 0:
            total_position_value = (current_qty + add_qty) * current_price
            max_allowed_value = equity * 0.4  # ë‹¨ì¼ í¬ì§€ì…˜ ìµœëŒ€ 40%
            
            if total_position_value > max_allowed_value:
                # ì¡°ì •ëœ ìˆ˜ëŸ‰ ê³„ì‚°
                max_add_value = max_allowed_value - (current_qty * current_price)
                add_qty = max_add_value / current_price
                logger.info(f"âš ï¸ í”¼ë¼ë¯¸ë”© ìˆ˜ëŸ‰ ì¡°ì •: {add_qty:.2f}ì£¼ (ìµœëŒ€ í¬ì§€ì…˜ 40% ì œí•œ)")
        
        if FRACTIONAL_ENABLED:
            final_qty = round(add_qty, 4)
        else:
            final_qty = max(int(math.floor(add_qty)), 0)
        
        logger.info(f"ğŸ“Š í”¼ë¼ë¯¸ë”© ìˆ˜ëŸ‰: {symbol} +{final_qty}ì£¼ (ê¸°ì¡´ {current_qty}ì£¼)")
        return final_qty
    except Exception as e:
        logger.error(f"ì¶”ê°€ ìˆ˜ëŸ‰ ê³„ì‚° ì‹¤íŒ¨ {symbol}: {e}")
        return 0

def can_pyramid(trading_adapter, position: Dict, equity: float, stop_distance: float) -> bool:
    """í”¼ë¼ë¯¸ë”© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (GPT ê¶Œì¥ ë¡œì§)"""
    try:
        # 1. ì•„ì§ ì¶”ê°€ë§¤ìˆ˜ ì•ˆí•¨ (1íšŒë§Œ í—ˆìš©)
        if position.get("added_layers", 0) >= 1:
            logger.debug(f"í”¼ë¼ë¯¸ë”© ë¶ˆê°€: ì´ë¯¸ {position.get('added_layers', 0)}íšŒ ì¶”ê°€ë§¤ìˆ˜")
            return False
        
        # 2. ë¯¸ì‹¤í˜„ ìˆ˜ìµ ì¤‘ (ìˆ˜ìµ ìƒíƒœì—ì„œë§Œ í”¼ë¼ë¯¸ë”©)
        unrealized_pl = position.get("unrealized_pl", 0)
        if unrealized_pl <= 0:
            logger.debug(f"í”¼ë¼ë¯¸ë”© ë¶ˆê°€: ì†ì‹¤ ì¤‘ (PL: {unrealized_pl})")
            return False
        
        # 3. ìˆ˜ìµë¥ ì´ ìµœì†Œ ìŠ¤í†± ê±°ë¦¬ì˜ 50% ì´ìƒì¼ ë•Œë§Œ (ì¶”ê°€ ì¡°ê±´)
        avg_price = position.get("avg_price", 0)
        if avg_price > 0:
            profit_pct = unrealized_pl / (avg_price * abs(position.get("qty", 1)))
            min_profit_threshold = STOP_LOSS_PCT * 0.5  # ìŠ¤í†±ì˜ 50%
            if profit_pct < min_profit_threshold:
                logger.debug(f"í”¼ë¼ë¯¸ë”© ë¶ˆê°€: ìˆ˜ìµë¥  ë¶€ì¡± ({profit_pct:.2%} < {min_profit_threshold:.2%})")
                return False
        
        # 4. ì´ ë¦¬ìŠ¤í¬ í•œë„ í™•ì¸
        current_risk = get_current_total_risk(trading_adapter, equity)
        additional_risk = equity * RISK_PER_TRADE
        max_allowed_risk = equity * MAX_CONCURRENT_RISK
        
        if (current_risk + additional_risk) > max_allowed_risk:
            logger.debug(f"í”¼ë¼ë¯¸ë”© ë¶ˆê°€: ë¦¬ìŠ¤í¬ í•œë„ ì´ˆê³¼ ({current_risk + additional_risk:.2f} > {max_allowed_risk:.2f})")
            return False
        
        logger.info(f"âœ… í”¼ë¼ë¯¸ë”© ê°€ëŠ¥: ìˆ˜ìµ ${unrealized_pl:.2f}, ë¦¬ìŠ¤í¬ ì—¬ìœ  ${max_allowed_risk - current_risk:.2f}")
        return True
    except Exception as e:
        logger.error(f"í”¼ë¼ë¯¸ë”© ê°€ëŠ¥ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

def get_current_total_risk(trading_adapter, equity: float) -> float:
    """í˜„ì¬ ì´ ë¦¬ìŠ¤í¬ ê³„ì‚°"""
    try:
        total_risk = 0.0
        positions = trading_adapter.get_positions()
        
        for pos in positions:
            if float(getattr(pos, 'quantity', 0)) == 0:
                continue
            
            # ê° í¬ì§€ì…˜ì˜ ë¦¬ìŠ¤í¬ = (í˜„ì¬ê°€ - ìŠ¤í†±ê°€) * ìˆ˜ëŸ‰
            sym = getattr(pos, 'ticker', None)
            if not sym:
                continue
            current_price = trading_adapter.get_current_price(sym)
            stop_distance = get_stop_distance(trading_adapter, sym)
            
            if current_price and stop_distance:
                position_risk = stop_distance * abs(float(getattr(pos, 'quantity', 0)))
                total_risk += position_risk
        
        return total_risk
    except Exception as e:
        logger.error(f"ì´ ë¦¬ìŠ¤í¬ ê³„ì‚° ì‹¤íŒ¨: {e}")
        return equity * MAX_CONCURRENT_RISK  # ë³´ìˆ˜ì ìœ¼ë¡œ ìµœëŒ€ì¹˜ ë°˜í™˜

def is_eod_window(market_calendar = None) -> bool:
    """ì¥ ë§ˆê° ì „ ìœˆë„ìš° í™•ì¸ (America/New_York ê¸°ì¤€)"""
    try:
        now_ny = datetime.now(timezone.utc).astimezone(ZoneInfo("America/New_York"))
        eod_minutes_before = EOD_FLATTEN_MINUTES
        close_dt = now_ny.replace(hour=16, minute=0, second=0, microsecond=0)
        start_dt = close_dt - timedelta(minutes=eod_minutes_before)
        in_window = start_dt <= now_ny <= close_dt
        if in_window:
            logger.info(f"ğŸŒ… EOD ìœˆë„ìš° í™œì„±: ë§ˆê° {eod_minutes_before}ë¶„ ì „")
        return in_window
    except Exception as e:
        logger.error(f"EOD ìœˆë„ìš° í™•ì¸ ì‹¤íŒ¨: {e}")
        return False

def place_bracket_order(trading_adapter, symbol: str, side: str, quantity: int, stop_distance: float) -> Optional[Dict]:
    """ë¸Œë˜í‚· ì£¼ë¬¸ (ì‹œì¥ê°€ + OCO) - GPT ê¶Œì¥ êµ¬í˜„"""
    try:
        current_price = trading_adapter.get_current_price(symbol)
        if not current_price:
            raise ValueError(f"ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨: {symbol}")
        
        # ìŠ¤í†±ë¡œìŠ¤/ìµì ˆ ê°€ê²© ê³„ì‚° (GPT ê¶Œì¥: RR ë¹„ìœ¨ ì ìš©)
        if side == "buy":
            stop_price = current_price - stop_distance
            take_profit_price = current_price + (stop_distance * TAKE_PROFIT_RR)
        else:
            stop_price = current_price + stop_distance
            take_profit_price = current_price - (stop_distance * TAKE_PROFIT_RR)
        
        # ìŠ¤í†±/ìµì ˆ ê°€ê²© ê²€ì¦
        if stop_price <= 0 or take_profit_price <= 0:
            logger.error(f"âŒ ì˜ëª»ëœ OCO ê°€ê²©: SL=${stop_price:.2f}, TP=${take_profit_price:.2f}")
            raise ValueError("Invalid OCO prices")
        
        # ë¸Œë˜í‚· ì£¼ë¬¸ (ì§„ì… + ìŠ¤í†±ë¡œìŠ¤ + ìµì ˆ) ì›ìƒ· ì œì¶œ
        try:
            if hasattr(trading_adapter, 'submit_bracket_order'):
                # ì•ŒíŒŒì¹´ ë¸Œë˜í‚· ì£¼ë¬¸ ì‚¬ìš© (GPT ê¶Œì¥: ì›ìƒ· ì œì¶œ)
                main_order, stop_order_id, profit_order_id = trading_adapter.submit_bracket_order(
                    ticker=symbol,
                    side=side,
                    quantity=quantity,
                    stop_loss_price=stop_price,
                    take_profit_price=take_profit_price,
                    signal_id=f"bracket_{symbol}_{int(time.time())}"
                )
                logger.info(f"ğŸ¯ ë¸Œë˜í‚· ì£¼ë¬¸ ì™„ë£Œ: {symbol} SL=${stop_price:.2f}, TP=${take_profit_price:.2f}, stop_id={stop_order_id}, profit_id={profit_order_id}")
            else:
                # í´ë°±: ê¸°ì¡´ ë°©ì‹ (ì‹œì¥ê°€ + Redis OCO)
                main_order = trading_adapter.submit_market_order(
                    ticker=symbol,
                    side=side,
                    quantity=quantity,
                    signal_id=f"bracket_{symbol}_{int(time.time())}"
                )
                
                # Redis OCO ë“±ë¡
                redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))
                oco_data = {
                    "symbol": symbol,
                    "quantity": quantity,
                    "stop_loss": stop_price,
                    "take_profit": take_profit_price,
                    "parent_order_id": getattr(main_order, 'id', 'unknown'),
                    "created_at": datetime.now(timezone.utc).isoformat()
                }
                redis_client.hset(
                    f"oco_pending:{symbol}",
                    getattr(main_order, 'id', f"temp_{int(time.time())}"),
                    json.dumps(oco_data)
                )
                redis_client.expire(f"oco_pending:{symbol}", 86400)
                logger.info(f"ğŸ¯ í´ë°± OCO ë“±ë¡: {symbol} SL=${stop_price:.2f}, TP=${take_profit_price:.2f}")
        except Exception as bracket_e:
            logger.warning(f"ë¸Œë˜í‚· ì£¼ë¬¸ ì‹¤íŒ¨, í´ë°± ì‹œë„: {bracket_e}")
            # ë¸Œë˜í‚· ì‹¤íŒ¨ ì‹œ ìµœì†Œí•œ ì‹œì¥ê°€ ì£¼ë¬¸ë§Œì´ë¼ë„ ì‹¤í–‰
            main_order = trading_adapter.submit_market_order(
                ticker=symbol,
                side=side,
                quantity=quantity,
                signal_id=f"fallback_{symbol}_{int(time.time())}"
            )
        
        logger.info(
            f"âœ… ë¸Œë˜í‚· ì£¼ë¬¸ ì‹¤í–‰: {symbol} {side} {quantity}ì£¼ @ ${float(current_price):.2f}\n"
            f"   â”œâ”€ ìŠ¤í†±ë¡œìŠ¤: ${float(stop_price):.2f} (-{(stop_distance/current_price)*100:.1f}%)\n"
            f"   â””â”€ ìµì ˆëª©í‘œ: ${float(take_profit_price):.2f} (+{(stop_distance*TAKE_PROFIT_RR/current_price)*100:.1f}%)"
        )
        return main_order
        
    except Exception as e:
        logger.error(f"ë¸Œë˜í‚· ì£¼ë¬¸ ì‹¤íŒ¨ {symbol}: {e}")
        raise

def _log_exit_decision(symbol: str, side: str, qty: int, policy: str, reason: str,
                       tif: str = "day", attempt: int = 1, market_state: str = "unknown",
                       order_id: str | None = None, price: float | None = None) -> None:
    parts = [
        f"EXIT_DECISION symbol={symbol}",
        f"side={side}",
        f"qty={qty}",
        f"policy={policy}",
        f"reason={reason}",
        f"tif={tif}",
        f"attempt={attempt}",
        f"market_state={market_state}"
    ]
    if order_id:
        parts.append(f"order_id={order_id}")
    if price is not None:
        try:
            parts.append(f"price={float(price):.2f}")
        except Exception:
            pass
    logger.info(" ".join(parts))

def flatten_all_positions(trading_adapter, reason: str = "eod_flatten") -> int:
    """ëª¨ë“  í¬ì§€ì…˜ ê°•ì œ ì²­ì‚°: í¬ì§€ì…˜ ë‹¨ìœ„ ì˜ˆì™¸/ì¬ì‹œë„ + êµ¬ì¡° ë¡œê·¸"""
    flattened_count = 0
    positions = []
    try:
        positions = trading_adapter.get_positions() or []
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return 0

    failed = []
    for pos in positions:
        try:
            qty_raw = float(getattr(pos, 'quantity', 0))
            if qty_raw == 0:
                continue
            symbol = getattr(pos, 'ticker', '')
            side = "sell" if qty_raw > 0 else "buy"
            quantity = abs(qty_raw if FRACTIONAL_ENABLED else int(qty_raw))

            # ì¬ì‹œë„ ë£¨í”„
            last_err = None
            for attempt in range(1, EOD_MAX_RETRIES + 2):  # ìµœì´ˆ 1íšŒ + ì¬ì‹œë„ NíšŒ
                tif_used = "cls"  # ê¸°ë³¸ ì˜ë„ëŠ” CLS (submit_eod_exitê°€ ì‹¤ì œ tifë¥¼ ê²°ì •)
                try:
                    # ì–´ëŒ‘í„°ê°€ EOD ì „ìš© ì¶œêµ¬ë¥¼ ì§€ì›í•˜ë©´ ìš°ì„  ì‚¬ìš©
                    if hasattr(trading_adapter, "submit_eod_exit"):
                        trade = trading_adapter.submit_eod_exit(symbol, quantity, side)
                    else:
                        tif_used = "day"
                        trade = trading_adapter.submit_market_order(
                            ticker=symbol,
                            side=side,
                            quantity=quantity,
                            signal_id=f"{reason}_{symbol}_{int(time.time())}"
                        )

                    # ê¸°ë¡ ë° ë¡œê¹…
                    if trade:
                        # tif ë³´ì • (ì˜ˆì•½ ì£¼ë¬¸ì€ meta.tif ë³´ìœ )
                        try:
                            tif_used = (getattr(trade, 'meta', {}) or {}).get('tif', tif_used)
                        except Exception:
                            pass
                        eod_signal_data = {
                            "symbol": symbol,
                            "score": 0.0,
                            "confidence": 1.0,
                            "regime": "eod",
                            "meta": {"reason": reason, "position_qty": qty_raw, "tif": tif_used, "side": side}
                        }
                        signal_db_id = save_signal_to_db(eod_signal_data, "eod_flatten", f"reason={reason},qty={quantity}")
                        # ì˜ˆì•½ ì£¼ë¬¸(CLS/OPG)ì€ ì•„ì§ ë¯¸ì²´ê²° â†’ íŠ¸ë ˆì´ë“œ ê¸°ë¡ì€ ë³´ë¥˜
                        if tif_used not in ("cls", "opg"):
                            save_trade_to_db(trade, eod_signal_data, symbol, signal_db_id)

                        order_id = getattr(trade, 'trade_id', None)
                        price = getattr(trade, 'price', None)
                        _log_exit_decision(symbol, side, quantity, policy="EOD", reason=reason, tif=tif_used,
                                           attempt=attempt, market_state="unknown", order_id=order_id, price=price)
                        logger.info(f"EOD ì²­ì‚°: {symbol} {side} {quantity}ì£¼ (ì‚¬ìœ : {reason})")
                        flattened_count += 1
                        break
                except Exception as e:
                    last_err = e
                    _log_exit_decision(symbol, side, quantity, policy="EOD", reason=f"error:{e}", tif=tif_used,
                                       attempt=attempt, market_state="closed")
                    if attempt <= EOD_MAX_RETRIES:
                        try:
                            time.sleep(EOD_RETRY_DELAY_SEC)
                        except Exception:
                            pass
                        continue
                    else:
                        raise
        except Exception as e:
            logger.error(f"í¬ì§€ì…˜ ì²­ì‚° ì‹¤íŒ¨: {getattr(pos, 'ticker', '')} - {e}")
            failed.append((getattr(pos, 'ticker', ''), str(e)))
            continue

    # ì”ì¡´ í¬ì§€ì…˜ ê²½ê³ 
    if failed:
        try:
            slack_bot = trading_components.get("slack_bot")
            if slack_bot:
                msg_lines = ["âš ï¸ EOD ì²­ì‚° ì‹¤íŒ¨ ìš”ì•½"] + [f"â€¢ {sym}: {err}" for sym, err in failed]
                slack_bot.send_message("\n".join(msg_lines))
        except Exception:
            pass

    return flattened_count

def _minutes_to_close(now_utc: datetime | None = None) -> int:
    ny = (now_utc or datetime.now(timezone.utc)).astimezone(ZoneInfo("America/New_York"))
    close_dt = ny.replace(hour=16, minute=0, second=0, microsecond=0)
    delta = (close_dt - ny).total_seconds() / 60.0
    return int(delta)

def _is_rth_now(now_utc: datetime | None = None) -> bool:
    ny = (now_utc or datetime.now(timezone.utc)).astimezone(ZoneInfo("America/New_York"))
    open_dt = ny.replace(hour=9, minute=30, second=0, microsecond=0)
    close_dt = ny.replace(hour=16, minute=0, second=0, microsecond=0)
    return open_dt <= ny <= close_dt

@celery_app.task(bind=True, name="app.jobs.scheduler.queue_preclose_liquidation")
def queue_preclose_liquidation(self):
    """ë§ˆê° ì „(ET 15:48) ì‚¬ì „ ì˜ˆì•½ ì²­ì‚°: CLS/OPG ì˜ˆì•½ ì œì¶œ"""
    try:
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        positions = trading_adapter.get_positions() or []
        scheduled = 0
        for p in positions:
            qty_raw = float(getattr(p, 'quantity', 0))
            quantity = abs(qty_raw if FRACTIONAL_ENABLED else int(qty_raw))
            if quantity <= 0:
                continue
            sym = getattr(p, 'ticker', '')
            try:
                side = "sell" if qty_raw > 0 else "buy"
                if hasattr(trading_adapter, "submit_eod_exit"):
                    trade = trading_adapter.submit_eod_exit(sym, quantity, side)
                else:
                    trade = trading_adapter.submit_market_order(
                        ticker=sym,
                        side=side,
                        quantity=quantity,
                        signal_id=f"preclose_{sym}"
                    )
                scheduled += 1
                tif_used = (getattr(trade, 'meta', {}) or {}).get('tif', 'cls')
                _log_exit_decision(sym, side, quantity, policy="EOD", reason="preclose_queue", tif=tif_used, attempt=1, market_state="RTH",
                                   order_id=getattr(trade, 'trade_id', None), price=getattr(trade, 'price', None))
            except Exception as e:
                logger.warning(f"ì‚¬ì „ ì²­ì‚° ì˜ˆì•½ ì‹¤íŒ¨: {sym} - {e}")
        return {"scheduled": scheduled}
    except Exception as e:
        logger.error(f"ì‚¬ì „ ì²­ì‚° íƒœìŠ¤í¬ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

@celery_app.task(bind=True, name="app.jobs.scheduler.enforce_time_stop")
def enforce_time_stop(self):
    """ì„¸ì…˜ ê¸°ì¤€ ê²°ì •ë¡ ì  íƒ€ì„ ìŠ¤í†± (ê¸°ë³¸ ON)"""
    if not ENABLE_TIME_STOP:
        return {"status": "disabled"}
    if not _is_rth_now():
        return {"status": "off_session"}
    try:
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))
        positions = trading_adapter.get_positions() or []
        exited = 0
        for p in positions:
            qty_raw = float(getattr(p, 'quantity', 0))
            quantity = abs(qty_raw if FRACTIONAL_ENABLED else int(qty_raw))
            if quantity <= 0:
                continue
            sym = getattr(p, 'ticker', '')
            side = "sell" if qty_raw > 0 else "buy"
            entry_key = f"position_entry_time:{sym}"
            try:
                entry_ts = float(redis_client.get(entry_key) or 0)
            except Exception:
                entry_ts = 0
            if entry_ts <= 0:
                continue
            age_min = int((time.time() - entry_ts) / 60)
            if age_min >= TIME_STOP_MIN:
                # ì„ë°• ì‹œ OPG ì˜ˆì•½
                minutes_left = _minutes_to_close()
                tif_used = "day"
                try:
                    if minutes_left <= TIME_STOP_LATE_ENTRY_CUTOFF_MIN and hasattr(trading_adapter, "submit_eod_exit"):
                        trade = trading_adapter.submit_eod_exit(sym, quantity, side)
                        try:
                            tif_used = (getattr(trade, 'meta', {}) or {}).get('tif', tif_used)
                        except Exception:
                            pass
                    else:
                        trade = trading_adapter.submit_market_order(ticker=sym, side=side, quantity=quantity, signal_id=f"time_stop_{sym}")
                    exited += 1
                    # DB ê¸°ë¡: ì˜ˆì•½ ì£¼ë¬¸ì€ trade ê¸°ë¡ ë³´ë¥˜
                    ts_signal = {"symbol": sym, "score": 0.0, "confidence": 1.0, "regime": "time_stop",
                                 "meta": {"reason": "time_stop", "tif": tif_used}}
                    sig_id = save_signal_to_db(ts_signal, "time_stop", f"age_min={age_min}")
                    if tif_used not in ("cls", "opg"):
                        save_trade_to_db(trade, ts_signal, sym, sig_id)
                    _log_exit_decision(sym, side, quantity, policy="TIME_STOP", reason="time_stop", tif=tif_used, attempt=1, market_state="RTH",
                                       order_id=getattr(trade, 'trade_id', None), price=getattr(trade, 'price', None))
                except Exception as e:
                    logger.warning(f"TIME_STOP ì²­ì‚° ì‹¤íŒ¨: {sym} - {e}")
        return {"exited": exited}
    except Exception as e:
        logger.error(f"TIME_STOP íƒœìŠ¤í¬ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

@celery_app.task(bind=True, name="app.jobs.scheduler.enforce_trail_stop")
def enforce_trail_stop(self):
    """ê²°ì •ë¡ ì  íŠ¸ë ˆì¼ ìŠ¤í†± (ê¸°ë³¸ OFF)"""
    if not ENABLE_TRAIL_STOP:
        return {"status": "disabled"}
    try:
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))
        positions = trading_adapter.get_positions() or []
        exited = 0
        failed = []
        for p in positions:
            try:
                qty_raw = float(getattr(p, 'quantity', 0))
                quantity = abs(qty_raw if FRACTIONAL_ENABLED else int(qty_raw))
                if quantity <= 0:
                    continue
                sym = getattr(p, 'ticker', '')
                entry_key = f"position_entry_time:{sym}"
                try:
                    entry_ts = float(redis_client.get(entry_key) or 0)
                except Exception:
                    entry_ts = 0
                if entry_ts <= 0:
                    continue
                age_min = int((time.time() - entry_ts) / 60)
                if age_min < TRAIL_MIN_HOLD_MIN:
                    continue
                price = trading_adapter.get_current_price(sym) or 0.0
                if price <= 0:
                    continue
                peak_key = f"trail:{sym}:peak"
                try:
                    prev_peak = float(redis_client.get(peak_key) or 0)
                except Exception:
                    prev_peak = 0.0
                # ë¡± ê¸°ì¤€ (ìˆì€ ì¶”í›„ í™•ì¥)
                peak = max(prev_peak, price)
                redis_client.setex(peak_key, 86400, str(peak))
                if peak > 0 and price <= peak * (1 - TRAIL_RET_PCT):
                    side = "sell" if qty_raw > 0 else "buy"
                    tif_used = "day"
                    try:
                        if (not _is_rth_now()) or _minutes_to_close() <= TIME_STOP_LATE_ENTRY_CUTOFF_MIN:
                            if hasattr(trading_adapter, "submit_eod_exit"):
                                trade = trading_adapter.submit_eod_exit(sym, quantity, side)
                                try:
                                    tif_used = (getattr(trade, 'meta', {}) or {}).get('tif', tif_used)
                                except Exception:
                                    pass
                            else:
                                trade = trading_adapter.submit_market_order(ticker=sym, side=side, quantity=quantity, signal_id=f"trail_stop_{sym}")
                        else:
                            trade = trading_adapter.submit_market_order(ticker=sym, side=side, quantity=quantity, signal_id=f"trail_stop_{sym}")
                        exited += 1
                        # ê¸°ë¡
                        tr_signal = {"symbol": sym, "score": 0.0, "confidence": 1.0, "regime": "trail_stop",
                                     "meta": {"reason": "trail_retreat", "tif": tif_used}}
                        sig_id = save_signal_to_db(tr_signal, "trail_stop", f"peak_ret={TRAIL_RET_PCT}")
                        if tif_used not in ("cls", "opg"):
                            save_trade_to_db(trade, tr_signal, sym, sig_id)
                        _log_exit_decision(sym, side, quantity, policy="TRAIL_STOP", reason="trail_retreat", tif=tif_used, attempt=1, market_state=("RTH" if _is_rth_now() else "CLOSED"),
                                           order_id=getattr(trade, 'trade_id', None), price=getattr(trade, 'price', None))
                    except Exception as e:
                        logger.warning(f"TRAIL_STOP ì²­ì‚° ì‹¤íŒ¨: {sym} - {e}")
                        failed.append((sym, str(e)))
                        continue
            except Exception as e:
                logger.warning(f"TRAIL_STOP ì²˜ë¦¬ ì‹¤íŒ¨(ì‹¬ë³¼ ë‹¨ìœ„): {getattr(p, 'ticker', '')} - {e}")
                failed.append((getattr(p, 'ticker', ''), str(e)))
                continue
        # ìš”ì•½ ê²½ê³  (ì„ íƒ)
        if failed:
            try:
                slack_bot = trading_components.get("slack_bot")
                if slack_bot:
                    msg_lines = ["âš ï¸ TRAIL_STOP ì²­ì‚° ì‹¤íŒ¨ ìš”ì•½"] + [f"â€¢ {sym}: {err}" for sym, err in failed]
                    slack_bot.send_message("\n".join(msg_lines))
            except Exception:
                pass
        return {"exited": exited}
    except Exception as e:
        logger.error(f"TRAIL_STOP íƒœìŠ¤í¬ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

@celery_app.task(bind=True, name="app.jobs.scheduler.enforce_regime_flatten_inverse")
def enforce_regime_flatten_inverse(self):
    """ì—­ETF ë ˆì§ í”Œë¦½ í‰íƒ„í™” (ì˜µì…˜)"""
    if not ENABLE_REGIME_FLATTEN_INVERSE:
        return {"status": "disabled"}
    try:
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))
        positions = trading_adapter.get_positions() or []
        flattened = 0
        for p in positions:
            sym = getattr(p, 'ticker', '').upper()
            qty_raw = float(getattr(p, 'quantity', 0))
            quantity = abs(qty_raw if FRACTIONAL_ENABLED else int(qty_raw))
            if quantity <= 0 or sym not in INVERSE_TICKERS_SET:
                continue
            # underlying ë§¤í•‘ (ì—†ìœ¼ë©´ ì‹¬ë³¼ ìì²´ ê¸°ì¤€)
            underlying = INSTRUMENT_META.get(sym, {}).get("underlying", sym)
            # ìµœì‹  ì ìˆ˜(ì–‘ìˆ˜=ë¦¬ìŠ¤í¬ ì˜¨ ê°€ì •)
            try:
                latest_score = float(redis_client.get(f"latest_score:{underlying}") or 0.0)
            except Exception:
                latest_score = 0.0
            if latest_score >= BUY_THRESHOLD:
                try:
                    side = "sell" if qty_raw > 0 else "buy"
                    trade = trading_adapter.submit_market_order(ticker=sym, side=side, quantity=quantity, signal_id=f"regime_flatten_{sym}")
                    flattened += 1
                    # ê¸°ë¡
                    rg_signal = {"symbol": sym, "score": 0.0, "confidence": 1.0, "regime": "regime_flat",
                                 "meta": {"reason": "regime_flip_inverse_flatten"}}
                    sig_id = save_signal_to_db(rg_signal, "regime_flatten", "inverse_flip")
                    save_trade_to_db(trade, rg_signal, sym, sig_id)
                    _log_exit_decision(sym, side, quantity, policy="REGIME_FLAT", reason="regime_flip_inverse_flatten", tif="day",
                                       attempt=1, market_state="RTH", order_id=getattr(trade, 'trade_id', None), price=getattr(trade, 'price', None))
                except Exception as e:
                    logger.warning(f"ë ˆì§ í”Œë¦½ í‰íƒ„í™” ì‹¤íŒ¨: {sym} - {e}")
        return {"flattened": flattened}
    except Exception as e:
        logger.error(f"ë ˆì§ í”Œë¦½ ê°€ë“œë ˆì¼ íƒœìŠ¤í¬ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}

def check_volume_spike(symbol: str, current_volume: float) -> bool:
    """ë³¼ë¥¨ ìŠ¤íŒŒì´í¬ í™•ì¸: í˜„ì¬ ë³¼ë¥¨ > 20ì¼ í‰ê·  * 1.5ë°°"""
    try:
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¸”ë¡œí‚¹ ë°©ì§€
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬ (ìµœê·¼ 5ì¼ë§Œ ì²´í¬)
            query = """
            SELECT AVG(v) as avg_volume
            FROM bars_30s 
            WHERE ticker = %s 
            AND ts >= NOW() - INTERVAL '5 days'
            LIMIT 100
            """
            cursor.execute(query, (symbol,))
            result = cursor.fetchone()
            
            if result and result[0] and current_volume > 0:
                avg_volume = float(result[0])
                volume_threshold = avg_volume * VOLUME_SPIKE_MULTIPLIER
                is_spike = current_volume > volume_threshold
                
                logger.debug(f"ë³¼ë¥¨ ìŠ¤íŒŒì´í¬ ì²´í¬ {symbol}: í˜„ì¬={current_volume:,.0f}, í‰ê· ={avg_volume:,.0f}, ìŠ¤íŒŒì´í¬={is_spike}")
                return is_spike
            else:
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ í†µê³¼
                return True
                
    except Exception as e:
        logger.error(f"ë³¼ë¥¨ ìŠ¤íŒŒì´í¬ í™•ì¸ ì‹¤íŒ¨ {symbol}: {e}")
        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ í†µê³¼
        return True

def check_candle_break(symbol: str, current_close: float) -> bool:
    """ìº”ë“¤ ë¸Œë ˆì´í¬ í™•ì¸: í˜„ì¬ ì¢…ê°€ > ì§ì „ ê³ ì  + epsilon"""
    try:
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ë¸”ë¡œí‚¹ ë°©ì§€
        with get_db_connection() as conn:
            cursor = conn.cursor()
            
            # ë‹¨ìˆœí™”ëœ ì¿¼ë¦¬ (ìµœê·¼ 5ê°œ ìº”ë“¤ë§Œ)
            query = """
            SELECT h as high
            FROM bars_30s 
            WHERE ticker = %s 
            AND ts < NOW() - INTERVAL '30 seconds'
            ORDER BY ts DESC 
            LIMIT 5
            """
            cursor.execute(query, (symbol,))
            result = cursor.fetchone()
            
            if result and result[0] and current_close > 0:
                prev_high = float(result[0])
                break_threshold = prev_high * (1 + CANDLE_BREAK_EPSILON)
                is_break = current_close > break_threshold
                
                logger.debug(f"ìº”ë“¤ ë¸Œë ˆì´í¬ ì²´í¬ {symbol}: í˜„ì¬ì¢…ê°€={current_close:.2f}, ì§ì „ê³ ì ={prev_high:.2f}, ë¸Œë ˆì´í¬={is_break}")
                return is_break
            else:
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ í†µê³¼
                return True
                
    except Exception as e:
        logger.error(f"ìº”ë“¤ ë¸Œë ˆì´í¬ í™•ì¸ ì‹¤íŒ¨ {symbol}: {e}")
        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ê°’ìœ¼ë¡œ í†µê³¼
        return True

def get_position_entry_time(symbol: str) -> Optional[float]:
    """í¬ì§€ì…˜ ì§„ì… ì‹œê°„ ì¡°íšŒ (UNIX timestamp)"""
    try:
        # Redis ì—°ê²° íƒ€ì„ì•„ì›ƒ ì„¤ì •
        r = redis.from_url(os.getenv("REDIS_URL"), socket_timeout=2.0, socket_connect_timeout=2.0)
        entry_key = f"position_entry_time:{symbol}"
        
        # ì§§ì€ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¡°íšŒ
        entry_time_str = r.get(entry_key)
        
        if entry_time_str:
            return float(entry_time_str)
        else:
            # í¬ì§€ì…˜ ì§„ì… ì‹œê°„ì´ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ë°˜í™˜ (Redis ì„¤ì • ìƒëµ)
            return time.time()
            
    except Exception as e:
        logger.error(f"í¬ì§€ì…˜ ì§„ì… ì‹œê°„ ì¡°íšŒ ì‹¤íŒ¨ {symbol}: {e}")
        # ì—ëŸ¬ ì‹œ í˜„ì¬ ì‹œê°„ ë°˜í™˜
        return time.time()

def close_partial_position(trading_adapter, symbol: str, partial_qty: int, reason: str) -> bool:
    """ë¶€ë¶„ í¬ì§€ì…˜ ì²­ì‚°"""
    try:
        # í˜„ì¬ í¬ì§€ì…˜ í™•ì¸
        positions = trading_adapter.get_positions()
        current_pos = None
        
        for pos in positions:
            if pos.ticker == symbol:
                current_pos = pos
                break
        
        if not current_pos or current_pos.quantity <= 0:
            logger.warning(f"ì²­ì‚°í•  í¬ì§€ì…˜ì´ ì—†ìŒ: {symbol}")
            return False
        
        # ë¶€ë¶„ ì²­ì‚°ëŸ‰ ì¡°ì • (ë³´ìœ ëŸ‰ì„ ì´ˆê³¼í•˜ì§€ ì•Šë„ë¡)
        actual_qty = min(partial_qty, abs(int(current_pos.quantity)))
        
        if actual_qty <= 0:
            logger.warning(f"ì²­ì‚°í•  ìˆ˜ëŸ‰ì´ ì—†ìŒ: {symbol}")
            return False
        
        # ì‹œì¥ê°€ ë§¤ë„ ì£¼ë¬¸
        side = "sell" if current_pos.quantity > 0 else "buy"
        trade = trading_adapter.submit_market_order(
            ticker=symbol,
            side=side,
            quantity=actual_qty,
            signal_id=f"{reason}_{symbol}_{int(time.time())}"
        )
        
        # GPT ì œì•ˆ: ë¶€ë¶„ ì²­ì‚° DB ê¸°ë¡
        if trade:
            partial_signal_data = {
                "symbol": symbol,
                "score": 0.0,  # ë¶€ë¶„ ì²­ì‚°ì€ ê°•ì œ ì²˜ë¦¬
                "confidence": 1.0,
                "regime": "partial_liquidation",
                "meta": {"reason": reason, "partial_qty": actual_qty, "original_qty": current_pos.quantity}
            }
            # ë¶€ë¶„ ì²­ì‚°: ì‹ í˜¸ ì €ì¥ í›„ ê±°ë˜ ê¸°ë¡
            signal_db_id = save_signal_to_db(partial_signal_data, "partial_liquidate", f"reason={reason},qty={actual_qty}")
            save_trade_to_db(trade, partial_signal_data, symbol, signal_db_id)
        
        logger.info(f"ğŸ”„ ë¶€ë¶„ ì²­ì‚°: {symbol} {side} {actual_qty}ì£¼ (ì‚¬ìœ : {reason})")
        return True
        
    except Exception as e:
        logger.error(f"ë¶€ë¶„ í¬ì§€ì…˜ ì²­ì‚° ì‹¤íŒ¨ {symbol}: {e}")
        return False

def check_short_etf_exit_conditions(symbol: str, current_score: float, current_price: float, current_volume: float) -> Optional[str]:
    """ìˆ ETF ì²­ì‚° ì¡°ê±´ ì²´í¬"""
    try:
        # ìˆ ETFì¸ì§€ í™•ì¸
        inverse_etfs = os.getenv("INVERSE_ETFS", "").split(",")
        if symbol not in inverse_etfs:
            return None
        
        # í¬ì§€ì…˜ ì§„ì… ì‹œê°„ í™•ì¸
        entry_time = get_position_entry_time(symbol)
        if not entry_time:
            return None
        
        hold_time = time.time() - entry_time
        
        # ìµœì†Œ ë³´ìœ  ì‹œê°„ ì²´í¬
        if hold_time < MIN_HOLD_SEC:
            logger.debug(f"ìµœì†Œ ë³´ìœ ì‹œê°„ ë¯¸ë‹¬: {symbol} {hold_time:.0f}s < {MIN_HOLD_SEC}s")
            return None
        
        # ë°˜ëŒ€ ì‹ í˜¸ ì²´í¬ (ë¡± ì‹ í˜¸ = ìˆ ETF ì²­ì‚° ì‹ í˜¸)
        buy_threshold = float(os.getenv("BUY_THRESHOLD", "0.15"))
        if current_score >= buy_threshold:
            # ë³¼ë¥¨ ìŠ¤íŒŒì´í¬ í™•ì¸
            if not check_volume_spike(symbol, current_volume):
                return "flip_noise_volume"
            
            # ìº”ë“¤ ë¸Œë ˆì´í¬ í™•ì¸
            if not check_candle_break(symbol, current_price):
                return "flip_noise_candle"
            
            return "opposite_signal_confirmed"
        
        return None
        
    except Exception as e:
        logger.error(f"ìˆ ETF ì²­ì‚° ì¡°ê±´ ì²´í¬ ì‹¤íŒ¨ {symbol}: {e}")
        return None

def log_signal_decision(signal_data: Dict, symbol: str, decision: str, reason: str = None) -> None:
    """ì‹ í˜¸ ì²˜ë¦¬ ê²°ì • ë¡œê¹…"""
    score = signal_data.get("score", 0)
    # scoreê°€ ë¬¸ìì—´ë¡œ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ floatë¡œ ë³€í™˜
    try:
        score = float(score) if score else 0
    except (ValueError, TypeError):
        score = 0
    signal_type = signal_data.get("signal_type", "unknown")
    
    if decision == "suppress":
        logger.info(f"ğŸš« ì‹ í˜¸ ì–µì œ: {symbol} {signal_type} (score: {score:.3f}) - {reason}")
    elif decision in ["entry", "add", "exit"]:
        logger.info(f"âœ… ì‹ í˜¸ ì‹¤í–‰: {symbol} {signal_type} (score: {score:.3f}) - {decision}")
    else:
        logger.info(f"ğŸ“ ì‹ í˜¸ ì²˜ë¦¬: {symbol} {signal_type} (score: {score:.3f}) - {decision}")

# --- DB ì €ì¥ í—¬í¼ í•¨ìˆ˜ (GPT ì œì•ˆ: ì‹¤ì œ ê±°ë˜ í›„ ë¡œì»¬ DB ê¸°ë¡) ---

def save_trade_to_db(trade_result, signal_data: Dict, exec_symbol: str, signal_db_id: str = None) -> Optional[str]:
    """ê±°ë˜ ê²°ê³¼ë¥¼ ë¡œì»¬ DBì— ì €ì¥ - signal_id ì—°ê³„ ê°œì„ """
    if not trade_result:
        return None
        
    dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
    if not dsn:
        logger.warning("DB DSNì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ê±°ë˜ ê¸°ë¡ì„ ê±´ë„ˆëœ€")
        return None
        
    try:
        with psycopg2.connect(dsn) as conn:
            with conn.cursor() as cur:
                # trade_resultê°€ ê°ì²´ì¸ ê²½ìš°ì™€ dictì¸ ê²½ìš° ëª¨ë‘ ì²˜ë¦¬
                if hasattr(trade_result, 'side'):
                    # ê°ì²´ í˜•íƒœ (ì•ŒíŒŒì¹´ Trade ê°ì²´)
                    side = getattr(trade_result, 'side', 'buy')
                    quantity = int(getattr(trade_result, 'quantity', 0))
                    price = float(getattr(trade_result, 'price', 0))
                    trade_id_str = getattr(trade_result, 'trade_id', f"trade_{int(time.time())}")
                else:
                    # dict í˜•íƒœ
                    side = trade_result.get("side", "buy")
                    quantity = int(trade_result.get("quantity", 0))
                    price = float(trade_result.get("price", 0))
                    trade_id_str = trade_result.get("trade_id", f"trade_{int(time.time())}")
                
                # signal_id ê²°ì •: ìƒˆë¡œ ìƒì„±ëœ signal_db_id ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ì¡´ signal_dataì—ì„œ
                # signals.idëŠ” INTEGERì´ë¯€ë¡œ ë³€í™˜ í•„ìš”
                final_signal_id = None
                if signal_db_id:
                    try:
                        final_signal_id = int(signal_db_id)
                    except (ValueError, TypeError):
                        final_signal_id = None
                elif signal_data.get("signal_id"):
                    try:
                        final_signal_id = int(signal_data.get("signal_id"))
                    except (ValueError, TypeError):
                        final_signal_id = None
                
                # trades í…Œì´ë¸”ì— ê¸°ë¡ - ì‹¤ì œ ìŠ¤í‚¤ë§ˆ ì‚¬ìš©
                cur.execute("""
                    INSERT INTO trades (
                        trade_id, ticker, side, quantity, price, signal_id, created_at, status
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    RETURNING id
                """, (
                    trade_id_str,
                    exec_symbol,
                    side,
                    quantity,
                    price,
                    final_signal_id,  # ìœ íš¨í•œ signal_id ì‚¬ìš© ë˜ëŠ” NULL
                    datetime.now(),
                    'filled'
                ))
                db_trade_id = cur.fetchone()[0]
                logger.info(f"ğŸ’¾ ê±°ë˜ ê¸°ë¡ ì €ì¥: ID={db_trade_id}, {exec_symbol} {side} {quantity}ì£¼ @ ${price:.2f}, signal_id={final_signal_id}")
                return str(db_trade_id)
                
    except Exception as e:
        logger.error(f"ê±°ë˜ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def save_signal_to_db(signal_data: Dict, action: str, decision_reason: str) -> Optional[str]:
    """ì‹ í˜¸ë¥¼ ë¡œì»¬ DBì— ì €ì¥"""
    dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
    if not dsn:
        return None
        
    try:
        with psycopg2.connect(dsn) as conn:
            with conn.cursor() as cur:
                # signals í…Œì´ë¸”ì— ê¸°ë¡
                cur.execute("""
                    INSERT INTO signals (
                        ticker, signal_type, score, confidence, 
                        regime, trigger_reason, created_at, 
                        action_taken, meta
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                    RETURNING id
                """, (
                    signal_data.get("symbol", "UNKNOWN"),
                    "long" if signal_data.get("score", 0) > 0 else "short",
                    float(signal_data.get("score", 0)),
                    float(signal_data.get("confidence", 0.7)),
                    signal_data.get("regime", "trend"),
                    decision_reason,
                    datetime.now(),
                    action,  # "entry", "exit", "suppress"
                    json.dumps(signal_data.get("meta", {}))
                ))
                signal_id = cur.fetchone()[0]
                logger.debug(f"ğŸ’¾ ì‹ í˜¸ ê¸°ë¡ ì €ì¥: ID={signal_id}, {signal_data.get('symbol')} {action}")
                return str(signal_id)
                
    except Exception as e:
        logger.error(f"ì‹ í˜¸ DB ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

@celery_app.task(bind=True, name="app.jobs.scheduler.pipeline_e2e")
def pipeline_e2e(self):
    """í¬ì§€ì…˜ ê´€ë¦¬ ê¸°ë°˜ E2E íŒŒì´í”„ë¼ì¸: ì‹ í˜¸ ì†Œë¹„ â†’ í¬ì§€ì…˜ ìƒíƒœ ê¸°ë°˜ ê±°ë˜ ì‹¤í–‰"""
    try:
        start_time = time.time()
        logger.info("ğŸš€ í¬ì§€ì…˜ ê´€ë¦¬ E2E íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        _autoinit_components_if_enabled()
        stream_consumer = trading_components["stream_consumer"]
        slack_bot = trading_components["slack_bot"]
        
        signals_processed = 0
        orders_executed = 0
        signals_suppressed = {"cooldown": 0, "direction_lock": 0, "daily_cap": 0, "below_cutoff": 0, "dup_event": 0, "risk_budget": 0}
        
        # AUTO_MODE ì²´í¬
        auto_mode = os.getenv("AUTO_MODE", "0").lower() in ("1", "true", "yes", "on")
        if not auto_mode:
            logger.info("ğŸ”„ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ - ì‹¤ì œ ê±°ë˜ ê±´ë„ˆëœ€")
            return {"status": "skipped", "reason": "simulation_mode"}
        
        # ê±°ë˜ ì–´ëŒ‘í„° ì´ˆê¸°í™”
        from app.adapters.trading_adapter import get_trading_adapter
        trading_adapter = get_trading_adapter()
        redis_client = redis.Redis.from_url(os.getenv("REDIS_URL", "redis://localhost:6379"))
        
        # ê³„ì¢Œ ì •ë³´ ì¡°íšŒ
        account_info = trading_adapter.get_portfolio_summary()
        equity = float(account_info.get('equity', 100000))
        logger.info(f"ğŸ’° í˜„ì¬ ê³„ì¢Œ ìì‚°: ${equity:,.2f}")
        
        # EOD ìœˆë„ìš° ì²´í¬ - ê°•ì œ ì²­ì‚°
        if is_eod_window():
            flattened = flatten_all_positions(trading_adapter, "eod_flatten")
            logger.info(f"ğŸŒ… EOD ìœˆë„ìš°: {flattened}ê°œ í¬ì§€ì…˜ ê°•ì œ ì²­ì‚°")
            return {
                "status": "eod_flatten",
                "positions_flattened": flattened,
                "execution_time": time.time() - start_time
            }
        
        # ğŸ¯ ìˆ ETF ì²­ì‚° ì¡°ê±´ ì²´í¬ - ë¹„í™œì„±í™” (2025-08-20)
        # ì •ê·œì¥ ì§ì „ ì „ëŸ‰ ì²­ì‚°ë§Œ ìœ ì§€í•˜ê¸°ë¡œ ê²°ì •
        # liquidation_count = 0
        # try:
        #     # í˜„ì¬ í¬ì§€ì…˜ì„ í•œ ë²ˆë§Œ ì¡°íšŒí•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
        #     positions = trading_adapter.get_positions() if trading_adapter else []
        #     inverse_etfs = set(os.getenv("INVERSE_ETFS", "SOXS,SQQQ,SPXS,TZA,SDOW,TECS").split(","))
        #     
        #     for pos in positions:
        #         if (hasattr(pos, 'ticker') and pos.ticker in inverse_etfs and 
        #             hasattr(pos, 'quantity') and float(pos.quantity) > 0):
        #             
        #             # í¬ì§€ì…˜ ê¸°ë³¸ ì •ë³´
        #             symbol = pos.ticker
        #             qty = float(pos.quantity)
        #             
        #             try:
        #                 # ìµœì‹  ê°€ê²© ë° ì ìˆ˜ í™•ì¸ (ìºì‹œëœ ê°’ í™œìš©)
        #                 current_price = trading_adapter.get_current_price(symbol)
        #                 if current_price <= 0:
        #                     continue
        #                 
        #                 # ê°„ë‹¨í•œ ì²­ì‚° ì¡°ê±´: BUY_THRESHOLD ì´ìƒì˜ ì ìˆ˜ (ë¡± ì „í™˜)
        #                 # ë³µì¡í•œ ë³¼ë¥¨/ìº”ë“¤ ì²´í¬ëŠ” ì„±ëŠ¥ìƒ ìƒëµ
        #                 latest_signal = redis_client.get(f"latest_score:{symbol}")
        #                 if latest_signal:
        #                     try:
        #                         current_score = float(latest_signal)
        #                         if current_score >= BUY_THRESHOLD:
        #                             # ë¶€ë¶„ ì²­ì‚° (50%)
        #                             partial_qty = max(1, int(qty * 0.5))
        #                             
        #                             # ì²­ì‚° ì£¼ë¬¸ ì‹¤í–‰
        #                             trade = trading_adapter.submit_market_order(
        #                                 ticker=symbol,
        #                                 side="sell",
        #                                 quantity=partial_qty,
        #                                 signal_id=f"liquidation_{symbol}_{int(time.time())}"
        #                             )
        #                             
        #                             if trade:
        #                                 liquidation_count += 1
        #                                 logger.info(f"ğŸ”„ ìˆ ETF ë¶€ë¶„ ì²­ì‚°: {symbol} {partial_qty}ì£¼ @ ${current_price:.2f} (ìŠ¤ì½”ì–´: {current_score:.3f})")
        #                                 
        #                                 # Slack ì•Œë¦¼
        #                                 if slack_bot:
        #                                     slack_message = f"ğŸ”„ *ë¡± ì „í™˜ ì²­ì‚°*\nâ€¢ {symbol} {partial_qty}ì£¼ ë§¤ë„ @ ${current_price:.2f}\nâ€¢ ì „í™˜ ìŠ¤ì½”ì–´: {current_score:.3f}"
        #                                     slack_bot.send_message(slack_message)
        #                     except ValueError:
        #                         continue
        #             except Exception as e:
        #                 logger.debug(f"ìˆ ETF ì²­ì‚° ì²´í¬ ì‹¤íŒ¨ {symbol}: {e}")
        #                 continue
        #     
        #     if liquidation_count > 0:
        #         logger.info(f"âœ… ìˆ ETF ì²­ì‚° ì™„ë£Œ: {liquidation_count}ê°œ í¬ì§€ì…˜ ì²˜ë¦¬")
        # 
        # except Exception as e:
        #     logger.error(f"ìˆ ETF ì²­ì‚° ë¡œì§ ì˜¤ë¥˜: {e}")
        #     # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ì „ì²´ íŒŒì´í”„ë¼ì¸ì€ ê³„ì† ì§„í–‰
        
        # Redis ìŠ¤íŠ¸ë¦¼ì—ì„œ ì‹ í˜¸ ì†Œë¹„
        redis_streams = stream_consumer.redis_streams
        raw_signals = redis_streams.consume_stream("signals.raw", count=50, block_ms=0, last_id="0")
        logger.info(f"ğŸ“Š Redisì—ì„œ {len(raw_signals)}ê°œ ì‹ í˜¸ ìˆ˜ì‹ ")
        
        # ë¦¬ìŠ¤í¬ ì˜ˆì‚° ê³„ì‚°
        current_total_risk = get_current_total_risk(trading_adapter, equity)
        risk_budget_left = (equity * MAX_CONCURRENT_RISK) - current_total_risk
        logger.info(f"ğŸ›¡ï¸ ì´ ë¦¬ìŠ¤í¬: ${current_total_risk:.2f}, ì”ì—¬ ì˜ˆì‚°: ${risk_budget_left:.2f}")
        
        for signal_event in raw_signals:
            try:
                signal_data = signal_event.data
                event_id = signal_event.message_id
                
                # ì‹ í˜¸ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                symbol = signal_data.get("ticker")
                def parse_numeric_value(value):
                    """numpy ë° ê¸°íƒ€ íƒ€ì…ì„ floatë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
                    try:
                        if hasattr(value, 'item'):  # numpy scalar
                            return float(value.item())
                        
                        value_str = str(value)
                        # numpy float64(...) í˜•íƒœ ì²˜ë¦¬
                        if value_str.startswith('np.float64(') and value_str.endswith(')'):
                            value_str = value_str[11:-1]
                        elif value_str.startswith('np.float32(') and value_str.endswith(')'):
                            value_str = value_str[11:-1]
                        
                        return float(value_str)
                    except Exception:
                        return 0.0
                
                base_score = parse_numeric_value(signal_data.get("score", 0))
                signal_type = signal_data.get("signal_type", "unknown")
                
                if not symbol or symbol not in INSTRUMENT_META:
                    log_signal_decision(signal_data, symbol or "unknown", "suppress", "unknown_symbol")
                    continue
                
                # ğŸ”„ ì‹¬ë³¼ ë¼ìš°íŒ… (ë°”ìŠ¤ì¼“ ê¸°ë°˜)
                route_result = route_signal_symbol(symbol, base_score)
                exec_symbol = route_result["exec_symbol"]
                route_reason = route_result["route_reason"]
                route_intent = route_result.get("intent", "")
                
                # ë¼ìš°íŒ… ê²°ê³¼ì— ë”°ë¥¸ ì²˜ë¦¬
                if exec_symbol is None:
                    # skip, suppress, block ë“±ì˜ ê²½ìš°
                    log_signal_decision(signal_data, symbol, route_intent, route_reason)
                    if "basket_conditions_not_met" in route_reason:
                        signals_suppressed["below_cutoff"] += 1
                    elif "etf_locked" in route_reason:
                        signals_suppressed["cooldown"] += 1
                    elif "conflict" in route_reason:
                        signals_suppressed["direction_lock"] += 1
                    continue
                
                # ì‹¤í–‰ ì‹¬ë³¼ì˜ ë©”íƒ€ë°ì´í„° í™•ì¸
                if exec_symbol not in INSTRUMENT_META:
                    log_signal_decision(signal_data, symbol, "suppress", f"routed_symbol_unknown:{exec_symbol}")
                    continue
                
                # ë¼ìš°íŒ…ëœ ì‹¬ë³¼ë¡œ effective_score ê³„ì‚°
                exec_meta = INSTRUMENT_META[exec_symbol]
                effective_score = exec_meta["exposure_sign"] * base_score
                
                # ì•¡ì…˜ ê°€ëŠ¥ì„± í™•ì¸
                if not is_actionable_signal(effective_score):
                    log_signal_decision(signal_data, symbol, "suppress", f"below_cutoff:routed_to_{exec_symbol}")
                    signals_suppressed["below_cutoff"] += 1
                    continue
                
                logger.info(f"ğŸ”„ ë¼ìš°íŒ…: {route_reason}, ìŠ¤ì½”ì–´: {base_score:.3f} â†’ {effective_score:.3f}")
                
                # ì¤‘ë³µ ì´ë²¤íŠ¸ ì°¨ë‹¨
                if not claim_idempotency(redis_client, event_id, ttl=900):
                    log_signal_decision(signal_data, symbol, "suppress", "dup_event")
                    signals_suppressed["dup_event"] += 1
                    continue
                
                # ì¿¨ë‹¤ìš´ í™•ì¸ (ì‹¤í–‰ ì‹¬ë³¼ ê¸°ì¤€)
                if is_in_cooldown(redis_client, exec_symbol):
                    log_signal_decision(signal_data, symbol, "suppress", f"cooldown:{exec_symbol}")
                    signals_suppressed["cooldown"] += 1
                    continue
                
                # ì¼ì¼ ì‹ í˜¸ í•œë„ í™•ì¸ (ì‹¤í–‰ ì‹¬ë³¼ ê¸°ì¤€)
                if exceeds_daily_cap(redis_client, exec_symbol):
                    log_signal_decision(signal_data, symbol, "suppress", f"daily_cap:{exec_symbol}")
                    signals_suppressed["daily_cap"] += 1
                    continue
                
                # í˜„ì¬ í¬ì§€ì…˜ í™•ì¸ (ì‹¤í–‰ ì‹¬ë³¼ ê¸°ì¤€)
                current_position = get_open_position(trading_adapter, exec_symbol)
                
                # ê±°ë˜ ë°©í–¥ ê²°ì •
                if effective_score >= BUY_THRESHOLD:
                    wanted_direction = "long"
                    action = "buy"
                elif effective_score <= SELL_THRESHOLD:
                    wanted_direction = "exit"
                    action = "sell"
                else:
                    log_signal_decision(signal_data, symbol, "suppress", "neutral_zone")
                    continue
                
                # ë°©í–¥ë½ í™•ì¸ (ì‹¤í–‰ ì‹¬ë³¼ ê¸°ì¤€)
                if is_direction_locked(redis_client, exec_symbol, wanted_direction):
                    log_signal_decision(signal_data, symbol, "suppress", f"direction_lock:{exec_symbol}")
                    signals_suppressed["direction_lock"] += 1
                    continue
                
                # ìŠ¤í†± ê±°ë¦¬ ê³„ì‚° (ì‹¤í–‰ ì‹¬ë³¼ ê¸°ì¤€)
                stop_distance = get_stop_distance(trading_adapter, exec_symbol)
                if stop_distance <= 0:
                    log_signal_decision(signal_data, symbol, "suppress", f"invalid_stop_distance:{exec_symbol}")
                    continue
                
                # ê±°ë˜ ì‹¤í–‰ ë¡œì§
                if action == "buy":
                    if current_position:
                        # ì¶”ê°€ ë§¤ìˆ˜ (í”¼ë¼ë¯¸ë”©) ê²€í† 
                        if can_pyramid(trading_adapter, current_position, equity, stop_distance):
                            quantity = calc_add_quantity(trading_adapter, exec_symbol, current_position, equity, stop_distance)
                            if quantity > 0:
                                trade = place_bracket_order(trading_adapter, exec_symbol, "buy", quantity, stop_distance)
                                set_cooldown(redis_client, exec_symbol, COOLDOWN_SECONDS)
                                set_direction_lock(redis_client, exec_symbol, "long", DIRECTION_LOCK_SECONDS)
                                count_daily_cap(redis_client, exec_symbol)
                                orders_executed += 1
                                log_signal_decision(signal_data, symbol, "add", f"exec_symbol={exec_symbol},qty={quantity}")
                                
                                # GPT ì œì•ˆ: DB ì €ì¥ ë¡œì§ ì¶”ê°€ - ì‹ í˜¸ ë¨¼ì € ì €ì¥ í›„ ê±°ë˜ì— ì—°ê²°
                                if trade:
                                    signal_db_id = save_signal_to_db(signal_data, "add", f"exec_symbol={exec_symbol},qty={quantity}")
                                    save_trade_to_db(trade, signal_data, exec_symbol, signal_db_id)
                                
                                # Slack ì•Œë¦¼
                                if slack_bot:
                                    slack_message = f"ğŸ“ˆ *ì¶”ê°€ ë§¤ìˆ˜*\nâ€¢ {exec_symbol} +{quantity}ì£¼ @ ${float(getattr(trade, 'price', 0)):.2f}\nâ€¢ ì›ì‹ í˜¸: {symbol}({base_score:.3f})\nâ€¢ ë¼ìš°íŒ…: {route_reason}\nâ€¢ ê¸°ì¡´í¬ì§€ì…˜: {current_position['qty']}ì£¼"
                                    slack_bot.send_message(slack_message)
                            else:
                                log_signal_decision(signal_data, symbol, "suppress", f"qty_zero_add:{exec_symbol}")
                        else:
                            log_signal_decision(signal_data, symbol, "suppress", f"already_long_no_pyramid:{exec_symbol}")
                    else:
                        # ì‹ ê·œ ì§„ì…
                        if risk_budget_left <= 0:
                            log_signal_decision(signal_data, symbol, "suppress", "risk_budget_exhausted")
                            signals_suppressed["risk_budget"] += 1
                            continue
                        
                        quantity = calc_entry_quantity(trading_adapter, exec_symbol, equity, stop_distance)
                        if quantity > 0:
                            trade = place_bracket_order(trading_adapter, exec_symbol, "buy", quantity, stop_distance)
                            set_cooldown(redis_client, exec_symbol, COOLDOWN_SECONDS)
                            set_direction_lock(redis_client, exec_symbol, "long", DIRECTION_LOCK_SECONDS)
                            count_daily_cap(redis_client, exec_symbol)
                            risk_budget_left -= (equity * RISK_PER_TRADE)
                            
                            # í¬ì§€ì…˜ ì§„ì… ì‹œê°„ ê¸°ë¡ (ìˆ ETF ì²­ì‚° ë¡œì§ìš©)
                            entry_key = f"position_entry_time:{exec_symbol}"
                            redis_client.set(entry_key, time.time(), ex=86400)  # 24ì‹œê°„ TTL
                            
                            orders_executed += 1
                            log_signal_decision(signal_data, symbol, "entry", f"exec_symbol={exec_symbol},qty={quantity}")
                            
                            # GPT ì œì•ˆ: DB ì €ì¥ ë¡œì§ ì¶”ê°€ - ì‹ í˜¸ ë¨¼ì € ì €ì¥ í›„ ê±°ë˜ì— ì—°ê²°
                            if trade:
                                signal_db_id = save_signal_to_db(signal_data, "entry", f"exec_symbol={exec_symbol},qty={quantity}")
                                save_trade_to_db(trade, signal_data, exec_symbol, signal_db_id)
                            
                            # Slack ì•Œë¦¼
                            if slack_bot:
                                slack_message = f"ğŸš€ *ì‹ ê·œ ì§„ì…*\nâ€¢ {exec_symbol} {quantity}ì£¼ @ ${float(getattr(trade, 'price', 0)):.2f}\nâ€¢ ì›ì‹ í˜¸: {symbol}({base_score:.3f})\nâ€¢ ë¼ìš°íŒ…: {route_reason}\nâ€¢ ìŠ¤í†±ê±°ë¦¬: ${float(stop_distance):.2f}"
                                slack_bot.send_message(slack_message)
                        else:
                            log_signal_decision(signal_data, symbol, "suppress", f"qty_zero_entry:{exec_symbol}")
                
                elif action == "sell":
                    if current_position:
                        # í¬ì§€ì…˜ ì²­ì‚° (ì‹¤í–‰ ì‹¬ë³¼ ê¸°ì¤€)
                        quantity = abs(current_position["qty"])
                        trade = trading_adapter.submit_market_order(
                            ticker=exec_symbol,
                            side="sell",
                            quantity=quantity,
                            signal_id=f"exit_{exec_symbol}_{int(time.time())}"
                        )
                        clear_direction_lock(redis_client, exec_symbol)
                        set_cooldown(redis_client, exec_symbol, COOLDOWN_SECONDS // 2)  # ì²­ì‚° í›„ ì§§ì€ ì¿¨ë‹¤ìš´
                        count_daily_cap(redis_client, exec_symbol)
                        orders_executed += 1
                        log_signal_decision(signal_data, symbol, "exit", f"exec_symbol={exec_symbol},qty={quantity}")
                        
                        # GPT ì œì•ˆ: DB ì €ì¥ ë¡œì§ ì¶”ê°€ - ì‹ í˜¸ ë¨¼ì € ì €ì¥ í›„ ê±°ë˜ì— ì—°ê²°
                        if trade:
                            signal_db_id = save_signal_to_db(signal_data, "exit", f"exec_symbol={exec_symbol},qty={quantity}")
                            save_trade_to_db(trade, signal_data, exec_symbol, signal_db_id)
                        
                        # Slack ì•Œë¦¼
                        if slack_bot:
                            pnl = current_position["unrealized_pl"]
                            pnl_emoji = "ğŸ“ˆ" if pnl >= 0 else "ğŸ“‰"
                            slack_message = f"{pnl_emoji} *í¬ì§€ì…˜ ì²­ì‚°*\nâ€¢ {exec_symbol} -{quantity}ì£¼ @ ${float(getattr(trade, 'price', 0)):.2f}\nâ€¢ ì›ì‹ í˜¸: {symbol}({base_score:.3f})\nâ€¢ ë¼ìš°íŒ…: {route_reason}\nâ€¢ ì†ìµ: ${float(pnl):.2f}"
                            slack_bot.send_message(slack_message)
                    else:
                        log_signal_decision(signal_data, symbol, "suppress", f"no_position_to_exit:{exec_symbol}")
                
                # ë©”ì‹œì§€ ACK
                stream_consumer.acknowledge("signals.raw", signal_event.message_id)
                signals_processed += 1
                
            except Exception as sig_e:
                logger.error(f"ì‹ í˜¸ ì²˜ë¦¬ ì‹¤íŒ¨ {signal_event.message_id}: {sig_e}")
                import traceback
                traceback.print_exc()
                continue
        
        execution_time = time.time() - start_time
        
        # ì„±ëŠ¥ í†µê³„ ë¡œê¹…
        total_signals = signals_processed + sum(signals_suppressed.values())
        logger.info(f"ğŸ¯ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {execution_time:.2f}ì´ˆ")
        logger.info(f"ğŸ“Š ì‹ í˜¸ í†µê³„: ì´ {total_signals}ê°œ, ì²˜ë¦¬ {signals_processed}ê°œ, ì£¼ë¬¸ {orders_executed}ê°œ")
        logger.info(f"ğŸš« ì–µì œ í†µê³„: {signals_suppressed}")
        
        return {
            "status": "success",
            "signals_processed": signals_processed,
            "orders_executed": orders_executed,
            "signals_suppressed": signals_suppressed,
            "risk_budget_used": current_total_risk,
            "risk_budget_left": risk_budget_left,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"E2E íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def get_mock_candles(ticker: str) -> List:
    """ëª¨ì˜ ìº”ë“¤ ë°ì´í„°"""
    # ì‹¤ì œë¡œëŠ” quotes_ingestorì—ì„œ ê°€ì ¸ì˜´
    return []

def get_mock_indicators(ticker: str) -> Dict:
    """ëª¨ì˜ ê¸°ìˆ ì  ì§€í‘œ"""
    # ì‹¤ì œë¡œëŠ” quotes_ingestorì—ì„œ ê°€ì ¸ì˜´
    return {
        "adx": 25.0,
        "ema_20": 150.0,
        "ema_50": 148.0,
        "rsi": 65.0,
        "volume_spike": 0.3,
        "price_change_5m": 0.02,
        "realized_volatility": 0.03,
        "current_price": 150.0,
        "vwap": 149.5,
        "vwap_deviation": 0.003,
        "macd": 0.5,
        "macd_signal": 0.3,
        "bb_position": 0.6
    }

def get_mock_tech_score(ticker: str):
    """ëª¨ì˜ ê¸°ìˆ ì  ì ìˆ˜"""
    # ì‹¤ì œë¡œëŠ” tech_score_engineì—ì„œ ê³„ì‚°
    from app.engine.techscore import TechScoreResult
    return TechScoreResult(
        score=0.7,
        components={
            "ema": 0.8,
            "macd": 0.7,
            "rsi": 0.6,
            "vwap": 0.7,
        },
        timestamp=datetime.now()
    )

def format_slack_message(signal) -> Dict:
    """ìŠ¬ë™ ë©”ì‹œì§€ í¬ë§· (ê°€ê²©/ë²„íŠ¼/ìƒíƒœì •ë³´ í¬í•¨)"""
    import os
    import json
    
    # ê¸°ë³¸ ë©”ì‹œì§€ í…ìŠ¤íŠ¸
    regime_display = signal.regime.upper().replace("_", "")
    score_sign = "+" if signal.score >= 0 else ""
    action = "long" if signal.signal_type.value == "long" else "short"
    action_ko = "ë¡±" if action == "long" else "ìˆ"
    
    # ë©”ì¸ ë©”ì‹œì§€
    main_text = (
        f"{signal.ticker} | ë ˆì§ {regime_display}({signal.confidence:.2f}) | "
        f"ì ìˆ˜ {score_sign}{signal.score:.2f} {action_ko}"
    )
    
    # ë””í…Œì¼ ë¼ì¸
    detail_text = (
        f"ì œì•ˆ: ì§„ì… {signal.entry_price:.2f} / "
        f"ì†ì ˆ {signal.stop_loss:.2f} / ìµì ˆ {signal.take_profit:.2f}\n"
        f"ì´ìœ : {signal.trigger} (<= {signal.horizon_minutes}m)"
    )
    
    # ë²„íŠ¼ ìƒì„± ì—¬ë¶€ í™•ì¸ (ë°˜ìë™ ëª¨ë“œë§Œ)
    show_buttons = os.getenv("SEMI_AUTO_BUTTONS", "0").lower() in ("1", "true", "yes", "on")
    
    # ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": f"*{main_text}*"}
        },
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": detail_text}
        }
    ]
    
    # ë²„íŠ¼ ì¶”ê°€ (ë°˜ìë™ ëª¨ë“œì¼ ë•Œ)
    if show_buttons:
        button_text = "ë§¤ìˆ˜" if action == "long" else "ë§¤ë„"
        order_payload = json.dumps({
            "ticker": signal.ticker,
            "side": "buy" if action == "long" else "sell",
            "entry": signal.entry_price,
            "sl": signal.stop_loss,
            "tp": signal.take_profit,
            "qty": int(os.getenv("DEFAULT_QTY", "1"))
        })
        
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": f"âœ… {button_text}", "emoji": True},
                    "style": "primary",
                    "value": order_payload,
                    "action_id": "approve_trade"
                },
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": "âŒ íŒ¨ìŠ¤", "emoji": True},
                    "style": "danger",
                    "value": f"reject_{signal.ticker}_{signal.signal_type.value}_{signal.timestamp.timestamp()}",
                    "action_id": "reject_trade"
                }
            ]
        })
    
    # ì²« ë²ˆì§¸ ì±„ë„ ìš°ì„ , ë‘ ë²ˆì§¸ëŠ” í´ë°± (channel_not_found ì˜¤ë¥˜ í•´ê²°)
    channel = os.getenv("SLACK_CHANNEL_ID") or "C099CQP8CJ3"
    
    return {
        "channel": channel,
        "text": main_text,
        "blocks": blocks
    }

def format_enhanced_slack_message(signal, llm_insight) -> Dict:
    """LLM ë¶„ì„ì´ í¬í•¨ëœ í–¥ìƒëœ ìŠ¬ë™ ë©”ì‹œì§€ í¬ë§· (Phase 1.5)"""
    import os
    import json
    
    # ê¸°ë³¸ ì •ë³´
    signal.regime.upper().replace("_", "")
    action_ko = "ë¡±" if signal.signal_type.value == "long" else "ìˆ"
    
    # ì‹ ë¢°ë„ ì´ëª¨ì§€
    confidence_emoji = {5: "ğŸ¯", 4: "ğŸ‘", 3: "ğŸ¤”", 2: "âš ï¸", 1: "ğŸ˜…"}
    confidence_level = min(5, max(1, round(signal.confidence * 5)))
    
    # LLM í–¥ìƒëœ ë©”ì¸ ë©”ì‹œì§€
    main_text = f"""
ğŸ’­ **{signal.ticker} ìƒˆë¡œìš´ ê¸°íšŒ ë°œê²¬!**

{confidence_emoji[confidence_level]} **AI íŒë‹¨**: {action_ko} ì¶”ì²œ ({signal.score:+.2f}ì )
ğŸ¯ **AI ë¶„ì„**: {llm_insight.summary}"""

    # ìƒì„¸ ì •ë³´ (ë” ì¹œê·¼í•˜ê²Œ)
    detail_text = f"""
ğŸ’¡ **íŠ¸ë ˆì´ë”© ì œì•ˆ**:
â€¢ ì§„ì…ê°€: ${signal.entry_price:.2f}
â€¢ ì†ì ˆì„ : ${signal.stop_loss:.2f} (ë¦¬ìŠ¤í¬ ê´€ë¦¬)
â€¢ ëª©í‘œê°€: ${signal.take_profit:.2f} (ìˆ˜ìµ ê¸°ëŒ€)

ğŸ§  **AIê°€ ë³¸ ì´ìœ **: {llm_insight.trigger}
â° **ì˜ˆìƒ ì§€ì†ì‹œê°„**: {signal.horizon_minutes}ë¶„

ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”?"""

    # ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "section", 
            "text": {"type": "mrkdwn", "text": main_text}
        },
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": detail_text}
        }
    ]
    
    # ë²„íŠ¼ ì¶”ê°€ (ë°˜ìë™ ëª¨ë“œë§Œ)
    show_buttons = os.getenv("SEMI_AUTO_BUTTONS", "0").lower() in ("1", "true", "yes", "on")
    
    if show_buttons:
        button_text = "ë§¤ìˆ˜" if signal.signal_type.value == "long" else "ë§¤ë„"
        order_payload = json.dumps({
            "ticker": signal.ticker,
            "action": signal.signal_type.value,
            "entry_price": signal.entry_price,
            "stop_loss": signal.stop_loss,
            "take_profit": signal.take_profit,
            "signal_score": signal.score,
            "llm_analysis": {
                "sentiment": llm_insight.sentiment,
                "trigger": llm_insight.trigger,
                "summary": llm_insight.summary
            }
        })
        
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": f"âœ… {button_text}"},
                    "style": "primary",
                    "value": order_payload,
                    "action_id": "execute_trade"
                },
                {
                    "type": "button", 
                    "text": {"type": "plain_text", "text": "âŒ ê±´ë„ˆë›°ê¸°"},
                    "value": "skip",
                    "action_id": "skip_trade"
                }
            ]
        })
    
    # ì±„ë„ ì„¤ì •
    channel = os.getenv("SLACK_CHANNEL_ID", "#trading-signals")
    
    return {
        "channel": channel,
        "text": f"ğŸ¤– AI ì¶”ì²œ: {signal.ticker} {action_ko} {signal.score:+.2f}ì ",
        "blocks": blocks
    }

@celery_app.task(bind=True, name="app.jobs.scheduler.generate_signals")
def generate_signals(self):
    """ì‹œê·¸ë„ ìƒì„± ì‘ì—…"""
    try:
        start_time = time.time()
        logger.info("ì‹œê·¸ë„ ìƒì„± ì‹œì‘")
        
        # í•„ìˆ˜ ìµœì†Œ ì»´í¬ë„ŒíŠ¸ í™•ì¸: ìŠ¤ìº˜í”„ ê²½ë¡œë§Œì´ë¼ë„ ëŒë¦´ ìˆ˜ ìˆê²Œ ìµœì†Œ depsë§Œ ê°•ì œ
        # 1) quotes_ingestor í•„ìˆ˜. ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ìƒì„± ì‹œë„
        if not trading_components.get("quotes_ingestor"):
            logger.warning("í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„: ['quotes_ingestor'] â†’ ë¡œì»¬ ìƒì„± ì‹œë„")
            try:
                from app.io.quotes_delayed import DelayedQuotesIngestor
                trading_components["quotes_ingestor"] = DelayedQuotesIngestor()
                try:
                    trading_components["quotes_ingestor"].warmup_backfill()  # type: ignore
                except Exception:
                    pass
            except Exception as e:
                logger.warning(f"quotes_ingestor ìƒì„± ì‹¤íŒ¨: {e}")
        if not trading_components.get("quotes_ingestor"):
            return {"status": "skipped", "reason": "quotes_ingestor_not_ready"}
        # 2) signal_mixer ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„± (ìŠ¤ìº˜í”„ ê²½ë¡œìš©)
        if not trading_components.get("signal_mixer"):
            try:
                from app.engine.mixer import SignalMixer
                thr = settings.MIXER_THRESHOLD
                trading_components["signal_mixer"] = SignalMixer(buy_threshold=thr, sell_threshold=-thr)
                logger.warning("signal_mixer ë¡œì»¬ ìƒì„±")
            except Exception as e:
                logger.warning(f"signal_mixer ìƒì„± ì‹¤íŒ¨: {e}")
        # 3) redis_streams ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ìƒì„± (ë°œí–‰ìš©)
        if not trading_components.get("redis_streams"):
            try:
                from app.io.streams import RedisStreams
                rurl = os.getenv("REDIS_URL", "redis://redis:6379/0")
                host, port, db = _parse_redis_url(rurl)
                trading_components["redis_streams"] = RedisStreams(host=host, port=port, db=db)
            except Exception as e:
                logger.warning(f"redis_streams ìƒì„± ì‹¤íŒ¨: {e}")
        
        quotes_ingestor = trading_components["quotes_ingestor"]
        trading_components["edgar_scanner"]
        regime_detector = trading_components["regime_detector"]
        tech_score_engine = trading_components["tech_score_engine"]
        llm_engine = trading_components["llm_engine"]
        signal_mixer = trading_components["signal_mixer"]
        redis_streams = trading_components["redis_streams"]
        slack_bot = trading_components.get("slack_bot")
        
        # ğŸ” DEBUG: Slack bot ìƒíƒœ í™•ì¸
        logger.info(f"ğŸ” [DEBUG] slack_bot ì¡´ì¬ ì—¬ë¶€: {slack_bot is not None}")
        if slack_bot:
            logger.info(f"ğŸ” [DEBUG] slack_bot íƒ€ì…: {type(slack_bot)}")
            logger.info(f"ğŸ” [DEBUG] slack_bot ì±„ë„: {getattr(slack_bot, 'default_channel', 'N/A')}")
        else:
            logger.warning(f"ğŸ” [DEBUG] slack_botì´ Noneì„! trading_components í‚¤: {list(trading_components.keys())}")
        
        signals_generated = 0
        
        # ê° ì¢…ëª©ë³„ë¡œ ì‹œê·¸ë„ ìƒì„±
        # ìœ ë‹ˆë²„ìŠ¤ ë™ì  ì ìš© (Redis union: core + external + watchlist)
        dynamic_universe = None
        try:
            rurl = os.getenv("REDIS_URL")
            if rurl:
                r = redis.from_url(rurl)
                external = r.smembers("universe:external") or []
                watch = r.smembers("universe:watchlist") or []
                core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
                ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
                wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
                merged = []
                seen = set()
                max_n = int(os.getenv("UNIVERSE_MAX", "100"))
                for arr in [core, ext, wch]:
                    for s in arr:
                        if s and s not in seen:
                            merged.append(s)
                            seen.add(s)
                        if len(merged) >= max_n:
                            break
                    if len(merged) >= max_n:
                        break
                dynamic_universe = merged
                # ì¸ì œìŠ¤í„°ì— ë°˜ì˜ ë° ì›Œë°ì—…
                try:
                    if hasattr(quotes_ingestor, "update_universe_tickers"):
                        quotes_ingestor.update_universe_tickers(dynamic_universe)
                except Exception:
                    pass
        except Exception:
            dynamic_universe = None

        # Tier ê¸°ë°˜ ì¢…ëª© ì²˜ë¦¬ (Universe Expansion)
        universe_tiers = get_universe_with_tiers()
        logger.info(f"ğŸ¯ Tier ìœ ë‹ˆë²„ìŠ¤: A={len(universe_tiers['tier_a'])}, B={len(universe_tiers['tier_b'])}, ë²¤ì¹˜={len(universe_tiers['bench'])}")
        
        # Tierë³„ ìŠ¤ì¼€ì¤„ë§ ì ìš©
        current_time = datetime.now()
        processing_tickers = []
        
        # Tier A ì¢…ëª© ì²´í¬ (30ì´ˆë§ˆë‹¤)
        for ticker in universe_tiers['tier_a']:
            should_process, reason = should_process_ticker_now(ticker, current_time)
            if should_process:
                processing_tickers.append((ticker, TokenTier.TIER_A, reason))
        
        # Tier B ì¢…ëª© ì²´í¬ (60ì´ˆë§ˆë‹¤) 
        for ticker in universe_tiers['tier_b']:
            should_process, reason = should_process_ticker_now(ticker, current_time)
            if should_process:
                processing_tickers.append((ticker, TokenTier.TIER_B, reason))
        
        # ë²¤ì¹˜ ì¢…ëª©ì€ í˜„ì¬ ì´ë²¤íŠ¸ ê¸°ë°˜ë§Œ (ì¶”í›„ í™•ì¥)
        
        logger.info(f"ğŸ¯ ì²˜ë¦¬ ëŒ€ìƒ: {len(processing_tickers)}ê°œ ì¢…ëª© {[f'{t}({tier.value})' for t, tier, _ in processing_tickers]}")
        
        # Fallback: Tier ì‹œìŠ¤í…œ ë¹„í™œì„±í™”ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if not processing_tickers:
            logger.info("ğŸ¯ Tier ì²˜ë¦¬ ëŒ€ìƒ ì—†ìŒ, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ Fallback")
            tickers_iter = dynamic_universe or list(quotes_ingestor.tickers)
            processing_tickers = [(ticker, None, "fallback") for ticker in tickers_iter]
        
        for ticker, tier, schedule_reason in processing_tickers:
            try:
                # API í† í° ì²´í¬ ë° ì†Œë¹„ (Tier ì‹œìŠ¤í…œ)
                if tier is not None:  # Tier ì‹œìŠ¤í…œ í™œì„±í™”ëœ ê²½ìš°
                    can_consume, token_reason = can_consume_api_token_for_ticker(ticker)
                    if not can_consume:
                        logger.info(f"ğŸš« í† í° ë¶€ì¡±ìœ¼ë¡œ ìŠ¤í‚µ: {ticker} ({tier.value}) - {token_reason}")
                        continue
                    
                    # í† í° ì‹¤ì œ ì†Œë¹„
                    consumed, consume_reason = consume_api_token_for_ticker(ticker)
                    if not consumed:
                        logger.warning(f"ğŸš« í† í° ì†Œë¹„ ì‹¤íŒ¨: {ticker} ({tier.value}) - {consume_reason}")
                        continue
                    
                    logger.debug(f"âœ… í† í° ì†Œë¹„: {ticker} ({tier.value}) - {consume_reason}")
                
                # 1. ì‹œì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                candles = quotes_ingestor.get_latest_candles(ticker, 50)
                if len(candles) < 20:
                    continue
                
                # 2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                indicators = quotes_ingestor.get_technical_indicators(ticker)
                if not indicators:
                    continue
                
                # 2.5 ìŠ¤ìº˜í”„ ëª¨ë“œ: ë§ˆì§€ë§‰ í•œ í‹±ì´ í¬ê²Œ íŠ€ë©´ ì¦‰ì‹œ ì‹ í˜¸ ìƒì„± (í…ŒìŠ¤íŠ¸/ì•Œë¦¼ìš©)
                try:
                    scalp_enabled = (os.getenv("SCALP_TICK_SPIKE", "false").lower() in ("1", "true", "yes", "on"))
                    if scalp_enabled and len(candles) >= 2:
                        # 30s/15s ë¶„í•  ì‹œ ë§ˆì§€ë§‰ ë‘ ë°”ê°€ ê°™ì€ 1ë¶„ì— ì†í•¨ â†’ ë¶„ë‹¹ ê°„ê²©ìœ¼ë¡œ ë¹„êµ
                        try:
                            bars_per_min = max(1, 60 // max(getattr(quotes_ingestor, "bar_sec", 60), 1))
                        except Exception:
                            bars_per_min = 1
                        last = candles[-1]
                        prev_idx = -1 - bars_per_min if len(candles) > bars_per_min else -2
                        prev = candles[prev_idx]
                        last_abs_ret = abs((last.c - prev.c) / max(prev.c, 1e-9))
                        spike_thr = float(os.getenv("SCALP_MIN_RET", "0.003"))  # ê¸°ë³¸ 0.3%
                        # ì•¼í›„ 1ë¶„ë´‰ ë¶„í•  ì‹œ ë§ˆì§€ë§‰ ë‘ ë°”ê°€ ë™ì¼ ê°’ì¸ ê²½ìš°ê°€ ë§ì•„ ê³ ì €í­ ê¸°ì¤€ë„ í—ˆìš©
                        last_range = (last.h - last.l) / max(last.c, 1e-9)
                        range_thr = float(os.getenv("SCALP_MIN_RANGE", "0.003"))  # ê¸°ë³¸ 0.3%
                        trig_reason = None
                        if last_abs_ret >= spike_thr:
                            trig_reason = f"ret>={spike_thr:.3%}"
                        elif last_range >= range_thr:
                            trig_reason = f"range>={range_thr:.3%}"
                        if trig_reason:
                            from app.engine.regime import RegimeType, RegimeResult
                            from app.engine.techscore import TechScoreResult
                            direction = 1.0 if (last.c - prev.c) >= 0 else -1.0
                            fake_regime = RegimeResult(
                                regime=RegimeType.VOL_SPIKE,
                                confidence=min(1.0, last_abs_ret * 20.0),
                                features={"last_abs_ret": last_abs_ret},
                                timestamp=datetime.now()
                            )
                            fake_tech = TechScoreResult(
                                score=direction,  # -1 ~ +1ë¡œ ì§ì ‘ ìŠ¤ì¼€ì¼
                                components={"ema": 0.8 if direction > 0 else 0.2,
                                            "macd": 0.8 if direction > 0 else 0.2,
                                            "rsi": 0.8 if direction > 0 else 0.2,
                                            "vwap": 0.8 if direction > 0 else 0.2},
                                timestamp=datetime.now()
                            )
                            quick_signal = signal_mixer.mix_signals(
                                ticker=ticker,
                                regime_result=fake_regime,
                                tech_score=fake_tech,
                                llm_insight=None,
                                edgar_filing=None,
                                current_price=last.c
                            )
                            if quick_signal:
                                quick_signal.trigger = "tick_spike"
                                quick_signal.summary = f"{trig_reason}; abs_ret={last_abs_ret:.3%}; range={last_range:.3%}"
                                # ì»·/ì„¸ì…˜ ì–µì œ ë™ì¼ ì ìš© (ë¡œì»¬ ê³„ì‚°)
                                sess_now = _session_label()
                                cutoff_rth, cutoff_ext = get_signal_cutoffs()
                                cut_r = cutoff_rth
                                cut_e = cutoff_ext
                                cut = cut_r if sess_now == "RTH" else cut_e
                                if abs(quick_signal.score) < cut:
                                    logger.info(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ ì‹ í˜¸ ì–µì œ: {ticker} score={quick_signal.score:.3f} < cut={cut:.3f}")
                                    _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="below_cutoff")
                                else:
                                    # GPT-5 ë¦¬ìŠ¤í¬ pre-check ì¶”ê°€
                                    risk_ok, risk_reason = check_signal_risk_feasibility(quick_signal, sess_now)
                                    if not risk_ok:
                                        logger.warning(f"ğŸ›¡ï¸ [RISK] ìŠ¤ìº˜í”„ ì‹ í˜¸ ë¦¬ìŠ¤í¬ ì°¨ë‹¨: {ticker} - {risk_reason}")
                                        _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed=f"risk_check: {risk_reason}")
                                    else:
                                        logger.info(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ ì‹ í˜¸ ë°œí–‰: {ticker} {quick_signal.signal_type.value} score={quick_signal.score:.3f} | ë¦¬ìŠ¤í¬: {risk_reason}")
                                        try:
                                            redis_streams.publish_signal({
                                            "ticker": quick_signal.ticker,
                                            "signal_type": quick_signal.signal_type.value,
                                            "score": quick_signal.score,
                                            "confidence": quick_signal.confidence,
                                            "regime": quick_signal.regime,
                                            "tech_score": quick_signal.tech_score,
                                            "sentiment_score": quick_signal.sentiment_score,
                                            "edgar_bonus": quick_signal.edgar_bonus,
                                            "trigger": quick_signal.trigger,
                                            "summary": quick_signal.summary,
                                            "entry_price": quick_signal.entry_price,
                                            "stop_loss": quick_signal.stop_loss,
                                            "take_profit": quick_signal.take_profit,
                                            "horizon_minutes": quick_signal.horizon_minutes,
                                            "timestamp": quick_signal.timestamp.isoformat()
                                        })
                                            logger.info(f"ğŸ”¥ [SCALP DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                                            signals_generated += 1
                                            _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators)
                                            logger.info(f"ìŠ¤ìº˜í”„ ì‹ í˜¸: {ticker} {quick_signal.signal_type.value} ({trig_reason}, abs_ret {last_abs_ret:.2%}, range {last_range:.2%})")
                                        except Exception as e:
                                            logger.error(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ Redis ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                except Exception:
                    pass

                # 2.6 ìŠ¤ìº˜í”„ ëª¨ë“œ(ëŒ€ì•ˆ): 3ë¶„ë´‰ 3ê°œ ì—°ì† ì–‘ë´‰ì´ë©´ ë¡± ì‹ í˜¸
                try:
                    if os.getenv("SCALP_3MIN3UP", "false").lower() in ("1", "true", "yes", "on"):
                        bar_sec = int(os.getenv("BAR_SEC", "30") or 30)
                        window = max(1, int(180 / max(bar_sec, 1)))  # 3ë¶„ ì°½ì˜ ë°” ê°œìˆ˜
                        need = window * 3
                        if len(candles) >= need:
                            w1 = candles[-window:]
                            w2 = candles[-2*window:-window]
                            w3 = candles[-3*window:-2*window]
                            def _is_green(ws):
                                try:
                                    return (ws[-1].c if ws else 0.0) > (ws[0].o if ws else 0.0)
                                except Exception:
                                    return False
                            if _is_green(w1) and _is_green(w2) and _is_green(w3):
                                from app.engine.regime import RegimeType, RegimeResult
                                from app.engine.techscore import TechScoreResult
                                fake_regime = RegimeResult(
                                    regime=RegimeType.TREND,
                                    confidence=0.8,
                                    features={"3min3up": True},
                                    timestamp=datetime.now()
                                )
                                fake_tech = TechScoreResult(
                                    score=1.0,
                                    components={"ema": 0.9, "macd": 0.9, "rsi": 0.8, "vwap": 0.8},
                                    timestamp=datetime.now()
                                )
                                last_px = candles[-1].c
                                quick_signal = signal_mixer.mix_signals(
                                    ticker=ticker,
                                    regime_result=fake_regime,
                                    tech_score=fake_tech,
                                    llm_insight=None,
                                    edgar_filing=None,
                                    current_price=last_px
                                )
                                if quick_signal:
                                    quick_signal.trigger = "3min_3up"
                                    quick_signal.summary = "3min green x3"
                                    sess_now = _session_label()
                                    cutoff_rth, cutoff_ext = get_signal_cutoffs()
                                    cut_r = cutoff_rth
                                    cut_e = cutoff_ext
                                    cut = cut_r if sess_now == "RTH" else cut_e
                                    if abs(quick_signal.score) < cut:
                                        logger.info(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ì–µì œ: {ticker} score={quick_signal.score:.3f} < cut={cut:.3f}")
                                        _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="below_cutoff")
                                    else:
                                        # ë¦¬ìŠ¤í¬ ì‚¬ì „ ì²´í¬ (GPT-5 ê¶Œì¥ì‚¬í•­)
                                        risk_ok, risk_reason = check_signal_risk_feasibility(quick_signal, sess_now)
                                        if not risk_ok:
                                            logger.warning(f"ğŸ›¡ï¸ {ticker} 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ë¦¬ìŠ¤í¬ ì°¨ë‹¨: {risk_reason}")
                                            _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="risk_limit")
                                        else:
                                            logger.info(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ë°œí–‰: {ticker} long score={quick_signal.score:.3f}")
                                            try:
                                                redis_streams.publish_signal({
                                                "ticker": quick_signal.ticker,
                                                "signal_type": quick_signal.signal_type.value,
                                                "score": quick_signal.score,
                                                "confidence": quick_signal.confidence,
                                                "regime": quick_signal.regime,
                                                "tech_score": quick_signal.tech_score,
                                                "sentiment_score": quick_signal.sentiment_score,
                                                "edgar_bonus": quick_signal.edgar_bonus,
                                                "trigger": quick_signal.trigger,
                                                "summary": quick_signal.summary,
                                                "entry_price": quick_signal.entry_price,
                                                "stop_loss": quick_signal.stop_loss,
                                                "take_profit": quick_signal.take_profit,
                                                "horizon_minutes": quick_signal.horizon_minutes,
                                                "timestamp": quick_signal.timestamp.isoformat()
                                            })
                                                logger.info(f"ğŸ”¥ [3MIN DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                                                signals_generated += 1
                                                _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators)
                                                logger.info(f"ìŠ¤ìº˜í”„ ì‹ í˜¸: {ticker} long (3min_3up)")
                                            except Exception as e:
                                                logger.error(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ Redis ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                                            continue
                except Exception:
                    pass

                # 3. ë ˆì§ ê°ì§€
                regime_result = regime_detector.detect_regime(candles)
                
                # 4. ê¸°ìˆ ì  ì ìˆ˜ ê³„ì‚°
                tech_score = tech_score_engine.calculate_tech_score(candles)
                
                # 5. EDGAR ê³µì‹œ í™•ì¸
                edgar_filing = None
                llm_insight = None
                
                # ìµœê·¼ EDGAR ê³µì‹œê°€ ìˆëŠ”ì§€ í™•ì¸
                recent_edgar = get_recent_edgar_filing(ticker)
                if recent_edgar:
                    edgar_filing = recent_edgar
                    # LLM ê²Œì´íŒ… ì ìš© (EDGAR ì´ë²¤íŠ¸)
                    should_call, call_reason = should_call_llm_for_event(
                        ticker, "edgar", edgar_filing=edgar_filing
                    )
                    if should_call:
                        # ì¿¼í„° ì†Œë¹„ ë° LLM ë¶„ì„
                        if consume_llm_call_quota(ticker, "edgar", edgar_filing):
                            llm_insight = llm_engine.analyze_edgar_filing(edgar_filing)
                            logger.info(f"ğŸ¤– LLM EDGAR ë¶„ì„: {ticker} - {call_reason}")
                        else:
                            logger.warning(f"ğŸ¤– LLM ì¿¼í„° ì†Œë¹„ ì‹¤íŒ¨: {ticker} (EDGAR)")
                    else:
                        logger.info(f"ğŸš« LLM EDGAR ì°¨ë‹¨: {ticker} - {call_reason}")
                
                # 6. ë ˆì§ì´ vol_spikeì¸ ê²½ìš° ì¶”ê°€ LLM ë¶„ì„ (ì‹ í˜¸ ì ìˆ˜ ì¡°ê±´ë¶€)
                if regime_result.regime.value == 'vol_spike' and llm_engine and not llm_insight:
                    # tech_scoreë¥¼ ì´ìš©í•´ ì‹ í˜¸ ì ìˆ˜ ì²´í¬ (vol_spike ê²Œì´íŒ…)
                    should_call, call_reason = should_call_llm_for_event(
                        ticker, "vol_spike", signal_score=tech_score.score
                    )
                    if should_call:
                        # ì¿¼í„° ì†Œë¹„ ë° LLM ë¶„ì„
                        if consume_llm_call_quota(ticker, "vol_spike"):
                            text = f"Volatility spike detected for {ticker} in {regime_result.regime.value} regime"
                            llm_insight = llm_engine.analyze_text(text, f"vol_spike_{ticker}", regime='vol_spike')
                            logger.info(f"ğŸ¤– LLM vol_spike ë¶„ì„: {ticker} - {call_reason}")
                        else:
                            logger.warning(f"ğŸ¤– LLM ì¿¼í„° ì†Œë¹„ ì‹¤íŒ¨: {ticker} (vol_spike)")
                    else:
                        logger.info(f"ğŸš« LLM vol_spike ì°¨ë‹¨: {ticker} - {call_reason}")
                
                # 6. ì„¸ì…˜ë³„ pre-filter (RTH: ì¼ì¼ìƒí•œ, EXT: ìœ ë™ì„±/ìŠ¤í”„ë ˆë“œ/ì¿¨ë‹¤ìš´/ì¼ì¼ìƒí•œ)
                ext_enabled = (os.getenv("EXTENDED_PRICE_SIGNALS", "false").lower() in ("1","true","yes","on"))
                session_label = _session_label()
                cutoff_rth, cutoff_ext = get_signal_cutoffs()
                dvol5m = float(indicators.get("dollar_vol_5m", 0.0))
                spread_bp = float(indicators.get("spread_bp", 0.0))
                suppress_reason = None
                
                # RTH ì¼ì¼ ìƒí•œ: 'ì˜ë¯¸ìˆëŠ” ì‹ í˜¸'ì— ëŒ€í•´ì„œë§Œ ì¹´ìš´íŠ¸í•˜ê¸° ìœ„í•´
                # ì»·ì˜¤í”„/ë¦¬ìŠ¤í¬ ì²´í¬ë¥¼ í†µê³¼í•œ ì´í›„ë¡œ INCRë¥¼ ì´ë™
                rth_day_key = None
                rth_daily_cap = None
                r_conn = None
                # ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€ìš© idempotency í‚¤ êµ¬ì„± ìš”ì†Œ
                idemp_key = None
                if session_label == "RTH":
                    try:
                        if rurl:
                            r_conn = redis.from_url(rurl)
                            rth_daily_cap = int(os.getenv("RTH_DAILY_CAP", "5"))
                            # ET ê¸°ì¤€ ë‚ ì§œ í‚¤ (UTC-5, DST ê°„ì´ ì ìš©)
                            et_tz = timezone(timedelta(hours=-5))
                            now_et = datetime.now(et_tz)
                            # DST ê°„ì´ ì ìš© (3ì›”-11ì›”)
                            if 3 <= now_et.month <= 11:
                                et_tz = timezone(timedelta(hours=-4))
                                now_et = datetime.now(et_tz)
                            rth_day_key = f"dailycap:{now_et:%Y%m%d}:RTH:{ticker}"
                            # 90ì´ˆ idempotency ìŠ¬ë¡¯í‚¤ (ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€)
                            slot = int(now_et.timestamp() // 90)
                            idemp_key = f"cap:idemp:{now_et:%Y%m%d}:{ticker}:{slot}"
                    except Exception as e:
                        logger.warning(f"RTH ì¼ì¼ìƒí•œ í‚¤ ì¤€ë¹„ ì‹¤íŒ¨: {e}")
                        r_conn = None
                elif session_label in ["EXT", "CLOSED"]:  # CLOSEDë„ EXT ë¡œì§ ì ìš©
                    # EXT ì„¸ì…˜ íŒë³„ ë° ì–µì œ ì´ìœ  ë¡œê·¸ ìˆ˜ì§‘
                    logger.info(f"EXT ì„¸ì…˜ ì²´í¬: {ticker} ext_enabled={ext_enabled} dvol5m={dvol5m:.0f} spread_bp={spread_bp:.1f}")
                    
                    if not ext_enabled:
                        suppress_reason = "ext_disabled"
                        logger.info(f"suppressed=ext_disabled ticker={ticker} session=EXT")
                    elif dvol5m < float(os.getenv("EXT_MIN_DOLLAR_VOL_5M", "50000")):
                        suppress_reason = "low_dvol"
                        logger.info(f"suppressed=low_dvol ticker={ticker} session=EXT dvol5m={dvol5m:.0f} min={os.getenv('EXT_MIN_DOLLAR_VOL_5M', '50000')}")
                    elif spread_bp > float(os.getenv("EXT_MAX_SPREAD_BP", "300")):
                        suppress_reason = "wide_spread"
                        logger.info(f"suppressed=wide_spread ticker={ticker} session=EXT spread_bp={spread_bp:.1f} max={os.getenv('EXT_MAX_SPREAD_BP', '300')}")
                    # ì¿¨ë‹¤ìš´/ì¼ì¼ ìƒí•œ ì²´í¬: Redis í‚¤ ì‚¬ìš© (ì›ìì  ì²˜ë¦¬)
                    try:
                        if rurl and not suppress_reason:  # ì´ë¯¸ ì–µì œ ì‚¬ìœ ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
                            r = redis.from_url(rurl)
                            cool_min = int(os.getenv("EXT_COOLDOWN_MIN", "7"))
                            daily_cap = int(os.getenv("EXT_DAILY_CAP", "3"))
                            now_ts = int(time.time())
                            cd_key = f"cooldown:{ticker}"
                            
                            # ì¿¨ë‹¤ìš´ ì²´í¬
                            last_ts = int(r.get(cd_key) or 0)
                            if now_ts - last_ts < cool_min * 60:
                                suppress_reason = "cooldown"
                                logger.info(f"EXT ì¿¨ë‹¤ìš´: {ticker} ({now_ts - last_ts}s < {cool_min*60}s)")
                            else:
                                # ET ê¸°ì¤€ ë‚ ì§œ í‚¤
                                et_tz = timezone(timedelta(hours=-5))
                                now_et = datetime.now(et_tz)
                                if 3 <= now_et.month <= 11:
                                    et_tz = timezone(timedelta(hours=-4))
                                    now_et = datetime.now(et_tz)
                                day_key = f"dailycap:{now_et:%Y%m%d}:EXT:{ticker}"
                                
                                # ì›ìì  ì²´í¬-ì¦ê°€
                                current_count = r.incr(day_key)
                                r.expire(day_key, 86400)
                                if current_count > daily_cap:
                                    r.decr(day_key)  # ë¡¤ë°±
                                    suppress_reason = "ext_daily_cap"
                                    logger.info(f"EXT ì¼ì¼ìƒí•œ ì´ˆê³¼: {ticker} ({current_count-1}/{daily_cap})")
                                else:
                                    # í†µê³¼ ì‹œ ì¿¨ë‹¤ìš´ ë§ˆí‚¹
                                    r.setex(cd_key, cool_min*60, now_ts)
                    except Exception as e:
                        logger.warning(f"EXT ì¿¨ë‹¤ìš´/ìƒí•œ ì²´í¬ ì‹¤íŒ¨: {e}")
                        pass

                # VaR95 ê²½ëŸ‰ ê°€ë“œ: ìµœê·¼ ë¦¬í„´ ìƒ˜í”Œ ê¸°ë°˜(ì˜µì…˜)
                try:
                    from app.engine.risk import rolling_var95
                    # ìƒ˜í”Œì€ ë³„ë„ ê³³ì—ì„œ ì±„ì›Œì§„ë‹¤ê³  ê°€ì •; ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    rurl = os.getenv("REDIS_URL")
                    if rurl:
                        r = redis.from_url(rurl)
                        key = f"risk:rets:{ticker}:{regime_result.regime.value}"
                        samples = [float(x) for x in (r.lrange(key, 0, 9999) or [])]
                        if samples:
                            rolling_var95(samples)
                            # ê°„ì´ ê¸°ì¤€: ì˜ˆìƒ ì†ì‹¤R>VaRì´ë©´ ì–µì œ
                            # ì—¬ê¸°ì„œëŠ” ì‹ í˜¸ ìƒì„± í›„ ì»·ì˜¤í”„ ë‹¨ê³„ì—ì„œ suppress
                            pass
                except Exception:
                    pass

                # 7. ì‹œê·¸ë„ ë¯¹ì‹±
                current_price = candles[-1].c if candles else 0
                signal = signal_mixer.mix_signals(
                    ticker=ticker,
                    regime_result=regime_result,
                    tech_score=tech_score,
                    llm_insight=llm_insight,
                    edgar_filing=edgar_filing,
                    current_price=current_price
                )
                
                if signal:
                    # ì»·ì˜¤í”„ ì ìš© (ì„¸ì…˜ë³„)
                    cut = cutoff_rth if session_label == "RTH" else cutoff_ext
                    if abs(signal.score) < cut or suppress_reason:
                        # ì–µì œ ì‚¬ìœ  í†µì¼ í˜•ì‹ ë¡œê·¸
                        actual_reason = suppress_reason or "below_cutoff"
                        logger.info(f"suppressed={actual_reason} ticker={ticker} session={session_label} "
                                   f"score={signal.score:.3f} cut={cut:.3f} dvol5m={dvol5m:.0f} spread_bp={spread_bp:.1f}")
                        
                        # ì–µì œ ë©”íŠ¸ë¦­ ëˆ„ì 
                        try:
                            if rurl:
                                r = redis.from_url(rurl)
                                hkey = f"metrics:suppressed:{datetime.utcnow():%Y%m%d}"
                                r.hincrby(hkey, actual_reason, 1)
                        except Exception:
                            pass
                        # ìµœê·¼ ì‹ í˜¸ ë¦¬ìŠ¤íŠ¸ì— suppressedë¡œ ê¸°ë¡
                        _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed=suppress_reason or "below_cutoff")
                        continue

                    # RTH ì¼ì¼ ìƒí•œ ì²´í¬: ì»·ì˜¤í”„/ë¦¬ìŠ¤í¬ í†µê³¼ í›„ì— í•œ ë²ˆë§Œ ì ìš©
                    if session_label == "RTH" and r_conn and rth_day_key and rth_daily_cap is not None:
                        try:
                            # idempotency: ë™ì¼ ìŠ¬ë¡¯ ë‚´ ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€
                            if idemp_key:
                                if not r_conn.setnx(idemp_key, 1):
                                    # ì´ë¯¸ ì¹´ìš´íŠ¸ ì²˜ë¦¬ë¨ â†’ ê·¸ëŒ€ë¡œ ì–µì œ ê¸°ë¡ë§Œ í›„ì†ë¡œ ë‚¨ê¸°ê³  ê±´ë„ˆëœ€
                                    r_conn.expire(idemp_key, 90)
                                else:
                                    r_conn.expire(idemp_key, 90)
                            current_count = r_conn.incr(rth_day_key)
                            r_conn.expire(rth_day_key, 86400)
                            if current_count > rth_daily_cap:
                                # ìƒí•œ ì´ˆê³¼ë©´ ë¡¤ë°±í•˜ê³  ì–µì œ ì²˜ë¦¬ë¡œ ì „í™˜
                                r_conn.decr(rth_day_key)
                                logger.info(f"suppressed=rth_daily_cap ticker={ticker} session={session_label} "
                                            f"score={signal.score:.3f} cut={cut:.3f} dvol5m={dvol5m:.0f} spread_bp={spread_bp:.1f}")
                                _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed="rth_daily_cap")
                                continue
                        except Exception as e:
                            logger.warning(f"RTH ì¼ì¼ìƒí•œ ì²´í¬ ì‹¤íŒ¨(ì‚¬í›„): {e}")

                    # ê¸€ë¡œë²Œ ìº¡(ì„ íƒ): í•˜ë£¨ ì´ ì•¡ì…˜ ê°€ëŠ¥ ì‹ í˜¸ ìƒí•œ
                    try:
                        global_cap = int(os.getenv("GLOBAL_RTH_DAILY_CAP", "0"))
                    except Exception:
                        global_cap = 0
                    if session_label == "RTH" and r_conn and global_cap > 0:
                        try:
                            gkey = f"dailycap:{now_et:%Y%m%d}:RTH:GLOBAL"
                            gcur = r_conn.incr(gkey)
                            r_conn.expire(gkey, 86400)
                            if gcur > global_cap:
                                r_conn.decr(gkey)
                                logger.info(f"suppressed=global_rth_daily_cap ticker={ticker} session={session_label}")
                                _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed="global_rth_daily_cap")
                                continue
                        except Exception as e:
                            logger.warning(f"ê¸€ë¡œë²Œ RTH ì¼ì¼ìƒí•œ ì²´í¬ ì‹¤íŒ¨: {e}")

                    # ë°©í–¥ ë½: ìµœê·¼ ë°˜ëŒ€ë°©í–¥ ì¬ì§„ì… ê¸ˆì§€(í…ŒìŠ¤íŠ¸ í•œì •)
                    try:
                        lock_sec = int(os.getenv("DIRECTION_LOCK_SEC", "0"))
                    except Exception:
                        lock_sec = 0
                    if lock_sec > 0 and r_conn:
                        try:
                            lkey = f"lock:dir:{ticker}"
                            last = r_conn.get(lkey)
                            if last:
                                last_dir, last_ts = last.decode().split(":")
                                from time import time as _now
                                if last_dir != signal.signal_type.value and (int(_now()) - int(last_ts)) < lock_sec:
                                    logger.info(f"suppressed=direction_lock ticker={ticker} lock={lock_sec}s last={last_dir}")
                                    _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed="direction_lock")
                                    continue
                            # í†µê³¼ ì‹œ í˜„ì¬ ë°©í–¥ ê¸°ë¡
                            from time import time as _now
                            r_conn.setex(lkey, lock_sec, f"{signal.signal_type.value}:{int(_now())}")
                        except Exception as e:
                            logger.warning(f"direction_lock ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                    # 7. Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
                    signal_data = {
                        "ticker": signal.ticker,
                        "signal_type": signal.signal_type.value,
                        "score": signal.score,
                        "confidence": signal.confidence,
                        "regime": signal.regime,
                        "tech_score": signal.tech_score,
                        "sentiment_score": signal.sentiment_score,
                        "edgar_bonus": signal.edgar_bonus,
                        "trigger": signal.trigger,
                        "summary": signal.summary,
                        "entry_price": signal.entry_price,
                        "stop_loss": signal.stop_loss,
                        "take_profit": signal.take_profit,
                        "horizon_minutes": signal.horizon_minutes,
                        "timestamp": signal.timestamp.isoformat()
                    }
                    
                    logger.info(f"ğŸ”¥ [DEBUG] ì‹œê·¸ë„ ìƒì„±ë¨! ticker={ticker}, type={signal.signal_type.value}, score={signal.score:.3f}, cut={cut:.3f}")
                    
                    # GPT-5 ë¦¬ìŠ¤í¬ pre-check ì¶”ê°€
                    risk_ok, risk_reason = check_signal_risk_feasibility(signal, session_label)
                    if not risk_ok:
                        logger.warning(f"ğŸ›¡ï¸ [RISK] ì‹ í˜¸ ë¦¬ìŠ¤í¬ ì°¨ë‹¨: {ticker} - {risk_reason}")
                        _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed=f"risk_check: {risk_reason}")
                        continue  # ì´ ì‹ í˜¸ëŠ” ê±´ë„ˆë›°ê³  ë‹¤ìŒìœ¼ë¡œ
                    
                    logger.info(f"ğŸ”¥ [DEBUG] ë¦¬ìŠ¤í¬ ì²´í¬ í†µê³¼ - Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹œë„: {ticker} | {risk_reason}")
                    
                    try:
                        redis_streams.publish_signal(signal_data)
                        logger.info(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                        
                        # ë°”ìŠ¤ì¼“ ë¶„ì„ì„ ìœ„í•œ ì‹ í˜¸ ìŠ¤ì½”ì–´ ì €ì¥ ë° íˆìŠ¤í† ë¦¬ ì¶”ê°€
                        try:
                            rurl = os.getenv("REDIS_URL")
                            if rurl:
                                r = redis.from_url(rurl)
                                now = time.time()
                                
                                # í˜„ì¬ ìŠ¤ì½”ì–´ ì €ì¥
                                score_key = f"signal_score:{ticker}"
                                score_data = {
                                    "score": signal.score,
                                    "timestamp": now,
                                    "signal_type": signal.signal_type.value
                                }
                                r.setex(score_key, 300, json.dumps(score_data))  # 5ë¶„ TTL
                                
                                # íˆìŠ¤í† ë¦¬ ì €ì¥ (slope ê³„ì‚°ìš©)
                                history_key = f"score_history:{ticker}"
                                r.lpush(history_key, json.dumps(score_data))
                                r.ltrim(history_key, 0, 19)  # ìµœê·¼ 20ê°œë§Œ ìœ ì§€
                                r.expire(history_key, 1800)  # 30ë¶„ TTL
                        except Exception as e:
                            logger.warning(f"ì‹ í˜¸ ìŠ¤ì½”ì–´ ì €ì¥ ì‹¤íŒ¨: {e}")
                        
                        # Slack ì „ì†¡: ê°•ì‹ í˜¸ë§Œ (ì›ë˜ ê¸°íš - ì†Œìˆ˜Â·êµµì§í•œ ì•Œë¦¼)
                        if slack_bot:
                            # ê°•ì‹ í˜¸ ê¸°ì¤€: abs(score) >= cut + 0.20 (ë” ê¹Œë‹¤ë¡­ê²Œ)
                            strong_signal_threshold = cut + 0.20
                            is_strong_signal = abs(signal.score) >= strong_signal_threshold
                            
                            if is_strong_signal:
                                logger.info(f"ğŸ“¢ ê°•ì‹ í˜¸ ê°ì§€: {ticker} score={signal.score:.3f} >= {strong_signal_threshold:.3f}")
                                
                                # Phase 1.5: ê°•ì‹ í˜¸ ì‹œ LLM ë¶„ì„ ì¶”ê°€!
                                enhanced_llm_insight = None
                                if llm_engine:
                                    try:
                                        # ê°•ì‹ í˜¸ë¥¼ ìœ„í•œ LLM ë¶„ì„ í”„ë¡¬í”„íŠ¸
                                        strong_signal_text = f"""
ê°•ì‹ í˜¸ ê°ì§€: {ticker}
ì ìˆ˜: {signal.score:.3f} ({signal.signal_type.value})
ë ˆì§: {signal.regime}
ê¸°ìˆ ì ìˆ˜: {signal.tech_score:.3f}
íŠ¸ë¦¬ê±°: {signal.trigger}

ì´ ê°•ì‹ í˜¸ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ê³¼ ì¹œê·¼í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.
                                        """
                                        
                                        enhanced_llm_insight = llm_engine.analyze_text(
                                            text=strong_signal_text,
                                            source=f"strong_signal_{ticker}",
                                            edgar_event=False,
                                            regime=signal.regime,
                                            signal_strength=abs(signal.score)  # ê°•ì‹ í˜¸ strength ì „ë‹¬!
                                        )
                                        
                                        if enhanced_llm_insight:
                                            logger.info(f"ğŸ¤– ê°•ì‹ í˜¸ LLM ë¶„ì„ ì™„ë£Œ: {ticker}")
                                            logger.info(f"  - ê°ì„±: {enhanced_llm_insight.sentiment:.2f}")
                                            logger.info(f"  - íŠ¸ë¦¬ê±°: {enhanced_llm_insight.trigger}")
                                            logger.info(f"  - ìš”ì•½: {enhanced_llm_insight.summary}")
                                        
                                    except Exception as llm_e:
                                        logger.warning(f"ê°•ì‹ í˜¸ LLM ë¶„ì„ ì‹¤íŒ¨: {ticker} - {llm_e}")
                                
                                try:
                                    # ê¸°ì¡´ ë©”ì‹œì§€ë‚˜ LLM í–¥ìƒëœ ë©”ì‹œì§€ ì‚¬ìš©
                                    if enhanced_llm_insight:
                                        # LLM ë¶„ì„ì´ ìˆìœ¼ë©´ ë” ì¹œê·¼í•œ ë©”ì‹œì§€ë¡œ í¬ë§·
                                        # Phase 1.5: ì‹ í˜¸ ê²€ì¦ ì‹œìŠ¤í…œ ì ìš©!
                                        validated_signal = signal
                                        try:
                                            from app.jobs.signal_validation import SignalValidationEngine
                                            validation_engine = SignalValidationEngine()
                                            validation_result = validation_engine.validate_signal(signal)
                                            
                                            if validation_result:
                                                validated_signal = validation_engine.apply_validation_result(signal, validation_result)
                                                logger.info(f"ğŸ” ì‹ í˜¸ ê²€ì¦ ì™„ë£Œ: {ticker} - {'âœ…í†µê³¼' if validation_result.should_proceed else 'ğŸ›‘ê±°ë¶€'}")
                                                
                                                # ê²€ì¦ ê±°ë¶€ëœ ì‹ í˜¸ëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŒ
                                                if not validation_result.should_proceed:
                                                    logger.info(f"suppressed=validation_rejected ticker={ticker} reason={validation_result.validation_reason}")
                                                    continue
                                        except Exception as val_e:
                                            logger.warning(f"ì‹ í˜¸ ê²€ì¦ ì‹¤íŒ¨: {ticker} - {val_e}")
                                        
                                        slack_message = format_enhanced_slack_message(validated_signal, enhanced_llm_insight)
                                    else:
                                        # ê¸°ì¡´ ë©”ì‹œì§€ ì‚¬ìš©
                                        slack_message = format_slack_message(signal)
                                    result = slack_bot.send_message(slack_message)
                                    if result:
                                        logger.info(f"âœ… Slack ì „ì†¡ ì„±ê³µ: {ticker} (ì¹´ìš´í„°ëŠ” ì´ë¯¸ ì „ì¹˜ ì²´í¬ì—ì„œ ì¦ê°€ë¨)")
                                        
                                        # Phase 1.5: í˜ì´í¼ íŠ¸ë ˆì´ë”© ìë™ ì‹¤í–‰!
                                        try:
                                            from app.jobs.paper_trading_manager import get_paper_trading_manager
                                            paper_manager = get_paper_trading_manager()
                                            
                                            execution_result = paper_manager.execute_signal(validated_signal)
                                            if execution_result:
                                                logger.info(f"ğŸ“Š í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹¤í–‰: {ticker}")
                                            else:
                                                logger.info(f"ğŸ“Š í˜ì´í¼ íŠ¸ë ˆì´ë”© ìŠ¤í‚µ: {ticker}")
                                        except Exception as paper_e:
                                            logger.warning(f"í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹¤í–‰ ì‹¤íŒ¨: {ticker} - {paper_e}")
                                    else:
                                        # Slack ì „ì†¡ ì‹¤íŒ¨ ì‹œ ì¹´ìš´í„° ë¡¤ë°± (ì „ì¹˜ ì²´í¬ì—ì„œ ì´ë¯¸ ì¦ê°€í–ˆìœ¼ë¯€ë¡œ)
                                        try:
                                            if rurl:
                                                r = redis.from_url(rurl)
                                                if session_label == "RTH":
                                                    et_tz = timezone(timedelta(hours=-5))
                                                    now_et = datetime.now(et_tz)
                                                    if 3 <= now_et.month <= 11:
                                                        et_tz = timezone(timedelta(hours=-4))
                                                        now_et = datetime.now(et_tz)
                                                    day_key = f"dailycap:{now_et:%Y%m%d}:RTH:{ticker}"
                                                    r.decr(day_key)
                                                elif session_label == "EXT":
                                                    et_tz = timezone(timedelta(hours=-5))
                                                    now_et = datetime.now(et_tz)
                                                    if 3 <= now_et.month <= 11:
                                                        et_tz = timezone(timedelta(hours=-4))
                                                        now_et = datetime.now(et_tz)
                                                    day_key = f"dailycap:{now_et:%Y%m%d}:EXT:{ticker}"
                                                    r.decr(day_key)
                                                logger.info(f"Slack ì „ì†¡ ì‹¤íŒ¨ë¡œ ì¹´ìš´í„° ë¡¤ë°±: {ticker}")
                                        except Exception as e:
                                            logger.warning(f"ì¹´ìš´í„° ë¡¤ë°± ì‹¤íŒ¨: {e}")
                                        logger.error(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {ticker}")
                                except Exception as e:
                                    # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ì¹´ìš´í„° ë¡¤ë°±
                                    try:
                                        if rurl:
                                            r = redis.from_url(rurl)
                                            if session_label == "RTH":
                                                et_tz = timezone(timedelta(hours=-5))
                                                now_et = datetime.now(et_tz)
                                                if 3 <= now_et.month <= 11:
                                                    et_tz = timezone(timedelta(hours=-4))
                                                    now_et = datetime.now(et_tz)
                                                day_key = f"dailycap:{now_et:%Y%m%d}:RTH:{ticker}"
                                                r.decr(day_key)
                                            elif session_label == "EXT":
                                                et_tz = timezone(timedelta(hours=-5))
                                                now_et = datetime.now(et_tz)
                                                if 3 <= now_et.month <= 11:
                                                    et_tz = timezone(timedelta(hours=-4))
                                                    now_et = datetime.now(et_tz)
                                                day_key = f"dailycap:{now_et:%Y%m%d}:EXT:{ticker}"
                                                r.decr(day_key)
                                            logger.info(f"Slack ì „ì†¡ ì˜ˆì™¸ë¡œ ì¹´ìš´í„° ë¡¤ë°±: {ticker}")
                                    except Exception as rollback_e:
                                        logger.warning(f"ì¹´ìš´í„° ë¡¤ë°± ì‹¤íŒ¨: {rollback_e}")
                                    logger.error(f"âŒ Slack ì „ì†¡ ì˜ˆì™¸: {ticker} - {e}")
                            else:
                                logger.info(f"ğŸ”‡ Slack ì „ì†¡ ì–µì œ (ì•½ì‹ í˜¸): {ticker} score={signal.score:.3f} < {strong_signal_threshold:.3f}")
                        else:
                            logger.warning(f"ğŸ” Slack ì „ì†¡ ê±´ë„ˆëœ€ - slack_botì´ None: {ticker}")
                        
                        signals_generated += 1
                    except Exception as e:
                        logger.error(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                        continue
                    # ìµœê·¼ ì‹ í˜¸ ê¸°ë¡ (+ ì„¸ì…˜/ìŠ¤í”„ë ˆë“œ/ë‹¬ëŸ¬ëŒ€ê¸ˆ)
                    _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators)
                    
                    tier_info = f" [Tier:{tier.value}]" if tier else ""
                    logger.info(f"ì‹œê·¸ë„ ìƒì„±: {ticker} {signal.signal_type.value} (ì ìˆ˜: {signal.score:.2f}){tier_info}")
                
            except Exception as e:
                logger.error(f"ì‹œê·¸ë„ ìƒì„± ì‹¤íŒ¨ ({ticker}): {e}")
                continue
        
        execution_time = time.time() - start_time
        
        # í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸ (Tier ì‹œìŠ¤í…œ)
        try:
            rate_limiter = get_rate_limiter()
            token_status = rate_limiter.get_token_status()
            api_usage = rate_limiter.get_total_api_usage()
            logger.info(f"ğŸ“Š í† í° ìƒíƒœ: A={token_status['tier_a']['current_tokens']}/{token_status['tier_a']['max_tokens']}, "
                       f"B={token_status['tier_b']['current_tokens']}/{token_status['tier_b']['max_tokens']}, "
                       f"ì˜ˆì•½={token_status['reserve']['current_tokens']}/{token_status['reserve']['max_tokens']} "
                       f"(ì‚¬ìš©ë¥ : {api_usage['usage_pct']:.1f}%)")
        except Exception as e:
            logger.warning(f"í† í° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # LLM ì‚¬ìš©ëŸ‰ ë¡œê·¸ (ê²Œì´íŒ… ì‹œìŠ¤í…œ)
        try:
            llm_stats = get_llm_usage_stats()
            logger.info(f"ğŸ¤– LLM ì‚¬ìš©ëŸ‰: {llm_stats['daily_used']}/{llm_stats['daily_limit']} "
                       f"(ë‚¨ì€ í˜¸ì¶œ: {llm_stats['remaining']}, ì‚¬ìš©ë¥ : {llm_stats['usage_pct']:.1f}%)")
        except Exception as e:
            logger.warning(f"LLM ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì‹œê·¸ë„ ìƒì„± ì™„ë£Œ: {signals_generated}ê°œ, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "signals_generated": signals_generated,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œê·¸ë„ ìƒì„± ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.update_quotes")
def update_quotes(self):
    """ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        quotes_ingestor = trading_components["quotes_ingestor"]
        redis_streams = trading_components["redis_streams"]
        
        if not quotes_ingestor or not redis_streams:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ëª¨ë“  ì¢…ëª© ì‹œì„¸ ì—…ë°ì´íŠ¸
        quotes_ingestor.update_all_tickers()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        market_data = quotes_ingestor.get_market_data_summary()
        # ì˜µì…˜: ì•¼í›„ ì¸ì œìŠ¤í„° ìš”ì•½ ë¡œê·¸ (ì‹¤ì‹œê°„ í‹± ì¶”ì ìš©)
        try:
            if os.getenv("QUOTE_LOG_VERBOSE", "false").lower() in ("1", "true", "yes", "on"):
                for _t, _d in (market_data or {}).items():
                    _ind = _d.get("indicators", {})
                    _px = float(_d.get("current_price", 0.0) or 0.0)
                    _dv = float(_ind.get("dollar_vol_5m", 0.0) or 0.0)
                    _sp = float(_ind.get("spread_bp", 0.0) or 0.0)
                    _ts = _d.get("last_update")
                    logger.info(f"[YQ] { _t } px={_px:.4f} dollar_vol_5m={_dv:.0f} spread_bp={_sp:.1f} ts={_ts}")
        except Exception:
            pass
        for ticker, data in market_data.items():
            if data.get("current_price"):
                quote_data = {
                    "ticker": ticker,
                    "price": data["current_price"],
                    "indicators": data.get("indicators", {}),
                    "timestamp": data.get("last_update", datetime.now()).isoformat()
                }
                redis_streams.publish_quote(ticker, "XNAS", quote_data)
        
        execution_time = time.time() - start_time
        logger.debug(f"ì‹œì„¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(market_data)}ê°œ ì¢…ëª©, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "tickers_updated": len(market_data),
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.scan_edgar")
def scan_edgar(self):
    """EDGAR ìŠ¤ìº” ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("EDGAR ìŠ¤ìº” ì‹œì‘")
        
        # EDGAR ìŠ¤ìºë„ˆ ì¤€ë¹„
        try:
            from app.io.edgar import EDGARScanner
        except Exception:
            EDGARScanner = None  # type: ignore
        edgar_scanner = trading_components.get("edgar_scanner")
        if edgar_scanner is None and EDGARScanner is not None:
            edgar_scanner = EDGARScanner()
            trading_components["edgar_scanner"] = edgar_scanner
        redis_streams = trading_components.get("redis_streams")
        redis_client = None
        try:
            # dedupeë¥¼ ìœ„í•œ raw redis í´ë¼ì´ì–¸íŠ¸ ì ‘ê·¼ (streams ë‚´ë¶€ í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©)
            if redis_streams:
                redis_client = redis_streams.redis_client
        except Exception:
            redis_client = None
        
        if not redis_streams:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # EDGAR ê³µì‹œ ìŠ¤ìº”
        filings = edgar_scanner.run_scan()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰ (ì¤‘ë³µ ë°©ì§€)
        dedupe_key = "edgar:dedupe:snippets"
        published = 0
        for filing in filings:
            snippet_text = filing.get("summary") or filing.get("snippet_text") or ""
            url = filing.get("url", "")
            base = (snippet_text or url).encode()
            snippet_hash = hashlib.md5(base).hexdigest()
            if redis_client:
                # ì¤‘ë³µì´ë©´ ìŠ¤í‚µ
                added = redis_client.sadd(dedupe_key, snippet_hash)
                if not added:
                    continue
            # í•´ì‹œë¥¼ í•¨ê»˜ ì €ì¥í•´ë‘ê¸°
            filing["snippet_hash"] = snippet_hash
            # StreamsëŠ” ë¬¸ìì—´ ê°’ì´ ì•ˆì „í•˜ë¯€ë¡œ dict/listëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            payload = {k: json.dumps(v) if isinstance(v, (dict, list)) else (v if v is not None else "") for k, v in filing.items()}
            redis_streams.publish_edgar(payload)
            published += 1
            
            # ì¤‘ìš” ê³µì‹œ LLM ì²˜ë¦¬
            llm_engine = trading_components.get("llm_engine")
            if filing.get("impact_score", 0) > 0.7 and llm_engine:
                llm_insight = llm_engine.analyze_edgar_filing(filing)
                if llm_insight:
                    insight_data = {
                        "ticker": filing["ticker"],
                        "sentiment": llm_insight.sentiment,
                        "trigger": llm_insight.trigger,
                        "horizon_minutes": llm_insight.horizon_minutes,
                        "summary": llm_insight.summary,
                        "timestamp": llm_insight.timestamp.isoformat()
                    }
                    redis_streams.publish_news(insight_data)
        
        execution_time = time.time() - start_time
        logger.debug(f"EDGAR ìŠ¤ìº” ì™„ë£Œ: {published}ê°œ ë°œí–‰, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "published": published,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"EDGAR ìŠ¤ìº” ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.check_risk")
def check_risk(self):
    """ë¦¬ìŠ¤í¬ ì²´í¬ ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("ë¦¬ìŠ¤í¬ ì²´í¬ ì‹œì‘")
        
        risk_engine = trading_components["risk_engine"]
        slack_bot = trading_components["slack_bot"]
        redis_streams = trading_components["redis_streams"]
        
        if not risk_engine:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
        risk_metrics = risk_engine.calculate_risk_metrics()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        if redis_streams:
            risk_data = {
                "daily_pnl": risk_metrics.daily_pnl,
                "daily_pnl_pct": risk_metrics.daily_pnl_pct,
                "var_95": risk_metrics.var_95,
                "max_drawdown": risk_metrics.max_drawdown,
                "position_count": risk_metrics.position_count,
                "total_exposure": risk_metrics.total_exposure,
                "status": risk_metrics.status.value,
                "timestamp": risk_metrics.timestamp.isoformat()
            }
            redis_streams.publish_risk_update(risk_data)
        
        # ê²½ê³ /ìœ„í—˜ ìƒíƒœì¼ ë•Œ Slack ì•Œë¦¼
        if risk_metrics.status.value in ["warning", "critical", "shutdown"] and slack_bot:
            risk_report = risk_engine.get_risk_report()
            slack_bot.send_risk_alert(risk_report)
        
        execution_time = time.time() - start_time
        logger.debug(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì™„ë£Œ: {risk_metrics.status.value}, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "risk_status": risk_metrics.status.value,
            "daily_pnl_pct": risk_metrics.daily_pnl_pct,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.daily_reset")
def daily_reset(self):
    """ì¼ì¼ ë¦¬ì…‹ ì‘ì—…"""
    try:
        logger.info("ì¼ì¼ ë¦¬ì…‹ ì‹œì‘")
        
        risk_engine = trading_components["risk_engine"]
        paper_ledger = trading_components["paper_ledger"]
        slack_bot = trading_components["slack_bot"]
        
        # ë¦¬ìŠ¤í¬ ì—”ì§„ ë¦¬ì…‹
        if risk_engine:
            risk_engine.reset_daily()
        
        # í˜ì´í¼ ë ˆì € ë¦¬ì…‹
        if paper_ledger:
            paper_ledger.reset_daily()
        
        # Slack ì•Œë¦¼
        if slack_bot:
            message = {
                "text": "ğŸ”„ ì¼ì¼ ë¦¬ì…‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "channel": "#trading-signals"
            }
            slack_bot.send_message(message)
        
        logger.info("ì¼ì¼ ë¦¬ì…‹ ì™„ë£Œ")
        
        return {
            "status": "success",
            "message": "ì¼ì¼ ë¦¬ì…‹ ì™„ë£Œ",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬ì…‹ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(name="app.jobs.scheduler.daily_report")
def daily_report(force=False, post=True):
    """ì¼ì¼ ë¦¬í¬íŠ¸ ì‘ì—…"""
    try:
        logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        paper_ledger = trading_components["paper_ledger"]
        risk_engine = trading_components["risk_engine"]
        llm_engine = trading_components["llm_engine"]
        slack_bot = trading_components["slack_bot"]
        
        if not paper_ledger:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ì¼ì¼ í†µê³„ ìˆ˜ì§‘
        daily_stats = paper_ledger.get_daily_stats()
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œ
        risk_metrics = None
        if risk_engine:
            risk_metrics = risk_engine.get_risk_report()
        
        # LLM ì‚¬ìš©ëŸ‰
        llm_usage = None
        if llm_engine:
            llm_usage = llm_engine.get_status()
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° êµ¬ì„±
        report_data = {
            "trades": daily_stats.get("trades", 0),
            "realized_pnl": daily_stats.get("realized_pnl", 0),
            "win_rate": 0.6,  # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
            "avg_rr": 1.4,    # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
            "risk_metrics": risk_metrics,
            "llm_usage": llm_usage
        }
        
        # Slack ë¦¬í¬íŠ¸ ì „ì†¡
        if slack_bot and post:
            slack_bot.send_daily_report(report_data)
        
        logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        
        return {
            "status": "success",
            "trades": report_data["trades"],
            "realized_pnl": report_data["realized_pnl"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬í¬íŠ¸ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def get_recent_edgar_filing(ticker: str) -> Optional[Dict]:
    """ìµœê·¼ EDGAR ê³µì‹œ ì¡°íšŒ (ìºì‹œëœ ë°ì´í„°ì—ì„œ)"""
    # ì‹¤ì œë¡œëŠ” ìºì‹œë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ None ë°˜í™˜
    return None

def _session_label() -> str:
    """RTH/EXT ê°„ë‹¨ íŒë³„: ET ì‹œê°„ìœ¼ë¡œ 09:30-16:00ì€ RTH, ê·¸ ì™¸ 04:00-20:00ì€ EXT, ë‚˜ë¨¸ì§€ëŠ” CLOSED"""
    from datetime import datetime, timedelta, time as dtime, timezone
    et_tz = timezone(timedelta(hours=-5))
    now_est = datetime.now(et_tz)
    # DST ê°„ì´ ì ìš©
    dst_start = now_est.replace(month=3, day=8 + (6 - now_est.replace(month=3, day=1).weekday()) % 7, hour=2)
    dst_end = now_est.replace(month=11, day=1 + (6 - now_est.replace(month=11, day=1).weekday()) % 7, hour=2)
    if dst_start <= now_est < dst_end:
        et_tz = timezone(timedelta(hours=-4))
        
    now = datetime.now(et_tz).time()
    session = None
    if dtime(9,30) <= now <= dtime(16,0):
        session = "RTH"
    elif dtime(4,0) <= now <= dtime(20,0):
        session = "EXT"
    else:
        session = "CLOSED"
    
    # ì„¸ì…˜ íŒë³„ ë¡œê·¸ (ë””ë²„ê·¸ ëª©ì )
    logger.debug(f"session={session} et_time={now} dst_active={dst_start <= now_est < dst_end}")
    return session

def _record_recent_signal(redis_url: Optional[str], signal, session_label: str, indicators: Dict, suppressed: Optional[str] = None) -> None:
    try:
        if not redis_url:
            return
        r = redis.from_url(redis_url)
        key = "signals:recent"
        payload = {
            "ticker": signal.ticker,
            "signal_type": signal.signal_type.value,
            "score": signal.score,
            "confidence": signal.confidence,
            "regime": signal.regime,
            "timestamp": signal.timestamp.isoformat(),
            "session": session_label,
            "spread_bp": float(indicators.get("spread_bp", 0.0)),
            "dollar_vol_5m": float(indicators.get("dollar_vol_5m", 0.0)),
        }
        if suppressed:
            payload["suppressed_reason"] = suppressed
        r.lpush(key, json.dumps(payload))
        r.ltrim(key, 0, 500)
    except Exception:
        pass

def initialize_components(components: Dict):
    """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    global trading_components
    trading_components.update(components)
    logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

    # Quotes ingestor ê¸°ë³¸ ì£¼ì…(ë”œë ˆì´ë“œ)
    try:
        from app.io.quotes_delayed import DelayedQuotesIngestor
        if trading_components.get("quotes_ingestor") is None:
            trading_components["quotes_ingestor"] = DelayedQuotesIngestor()
            logger.info("ë”œë ˆì´ë“œ Quotes ì¸ì œìŠ¤í„° ì´ˆê¸°í™”")
    except Exception as e:
        logger.warning(f"Quotes ì¸ì œìŠ¤í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


@celery_app.task(bind=True, name="app.jobs.scheduler.ingest_edgar_stream")
def ingest_edgar_stream(self):
    """Redis Streams(news.edgar) â†’ DB(edgar_events) ì ì¬. DB UNIQUE(snippet_hash)ë¡œ ìµœì¢… dedupe.
    ì›Œì»¤ ë¶€íŒ… í›„ readiness í†µê³¼ ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ëœë‹¤.
    """
    try:
        from app.io.streams import RedisStreams, StreamConsumer
        rs = trading_components.get("redis_streams")
        if rs is None:
            # envì—ì„œ ì—°ê²°
            import urllib.parse as _u
            redis_url = os.getenv("REDIS_URL", "redis://redis:6379/0")
            parsed = _u.urlparse(redis_url)
            host = parsed.hostname or "redis"
            port = int(parsed.port or 6379)
            db = int(parsed.path.lstrip("/") or 0)
            rs = RedisStreams(host=host, port=port, db=db)
            trading_components["redis_streams"] = rs
        consumer = trading_components.get("stream_consumer") or StreamConsumer(rs)
        trading_components["stream_consumer"] = consumer

        # DB ì—°ê²° í™•ë³´/ì¬ì‚¬ìš©
        conn = trading_components.get("db_connection")
        if conn is None or conn.closed:
            dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
            if not dsn:
                return {"status": "skipped", "reason": "missing_db_dsn", "timestamp": datetime.now().isoformat()}
            conn = psycopg2.connect(dsn)
            conn.autocommit = True
            trading_components["db_connection"] = conn

        messages = consumer.consume_edgar_events(count=20, block_ms=100)
        inserted = 0
        with conn.cursor() as cur:
            for msg in messages:
                d = msg.data
                # ë¬¸ìì—´ë¡œ ì˜¨ JSONì„ ì›ìƒë³µêµ¬ ì‹œë„
                def _norm(key):
                    val = d.get(key)
                    if val is None:
                        return None
                    try:
                        return json.loads(val)
                    except Exception:
                        return val

                ticker = _norm("ticker") or d.get("ticker")
                form = _norm("form") or d.get("form")
                item = _norm("item") or d.get("item")
                url = _norm("url") or d.get("url")
                snippet_text = _norm("snippet_text") or d.get("snippet_text")
                snippet_hash = _norm("snippet_hash") or d.get("snippet_hash")
                
                # formì´ Noneì´ë©´ snippet_textì—ì„œ ì¶”ì¶œ ì‹œë„
                if form is None and snippet_text:
                    import re
                    match = re.search(r'\b(4|8-K|10-K|10-Q|S-1|S-3|DEF 14A)\b', str(snippet_text))
                    if match:
                        form = match.group(1)

                cur.execute(
                    """
                    INSERT INTO edgar_events (ticker, form, item, url, snippet_hash, snippet_text)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    ON CONFLICT (snippet_hash) DO NOTHING
                    """,
                    (str(ticker) if ticker is not None else None,
                     str(form) if form is not None else None,
                     str(item) if item is not None else None,
                     str(url) if url is not None else None,
                     str(snippet_hash) if snippet_hash is not None else None,
                     str(snippet_text) if snippet_text is not None else None)
                )
                consumer.acknowledge("news.edgar", msg.message_id)
                inserted += 1

        return {"status": "success", "inserted": inserted, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"EDGAR ìŠ¤íŠ¸ë¦¼ ì ì¬ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e), "timestamp": datetime.now().isoformat()}

def get_task_status(task_id: str) -> Dict:
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    try:
        result = celery_app.AsyncResult(task_id)
        return {
            "task_id": task_id,
            "status": result.status,
            "result": result.result if result.ready() else None,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "task_id": task_id,
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(name="app.jobs.scheduler.refresh_universe")
def refresh_universe():
    """15ë¶„ë§ˆë‹¤ ìœ ë‹ˆë²„ìŠ¤ ë³‘í•©â†’ì¸ì œìŠ¤í„° ë°˜ì˜"""
    try:
        quotes_ingestor = trading_components.get("quotes_ingestor")
        rurl = os.getenv("REDIS_URL")
        if not quotes_ingestor or not rurl:
            return {"status": "skipped"}
        r = redis.from_url(rurl)
        external = r.smembers("universe:external") or []
        watch = r.smembers("universe:watchlist") or []
        core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
        ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
        wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
        merged = []
        seen = set()
        max_n = int(os.getenv("UNIVERSE_MAX", "60"))
        for arr in [core, ext, wch]:
            for s in arr:
                if s and s not in seen:
                    merged.append(s)
                    seen.add(s)
                if len(merged) >= max_n:
                    break
            if len(merged) >= max_n:
                break
        if hasattr(quotes_ingestor, "update_universe_tickers"):
            quotes_ingestor.update_universe_tickers(merged)
        return {"status": "ok", "universe_size": len(merged)}
    except Exception as e:
        logger.error(f"ìœ ë‹ˆë²„ìŠ¤ ê°±ì‹  ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}

@celery_app.task(name="app.jobs.scheduler.adaptive_cutoff")
def adaptive_cutoff():
    """ì „ì¼ ì²´ê²° ê±´ìˆ˜ ê¸°ë°˜ ì»·ì˜¤í”„ ì¡°ì •: cfg:signal_cutoff:{rth|ext} Â±0.02 with bounds"""
    try:
        if os.getenv("ADAPTIVE_CUTOFF_ENABLED", "true").lower() not in ("1","true","yes","on"):
            return {"status": "skipped", "reason": "disabled"}
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return {"status": "skipped", "reason": "no_redis"}
        r = redis.from_url(rurl)
        # ì²´ê²° ê±´ìˆ˜: ê°„ì´ ì§‘ê³„(orders_paper í…Œì´ë¸” ì—†ìœ¼ë©´ 0 ì²˜ë¦¬)
        fills = 0
        try:
            dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
            if dsn:
                import psycopg2
                from datetime import timedelta
                conn = psycopg2.connect(dsn)
                cur = conn.cursor()
                prev = (datetime.utcnow() - timedelta(days=1)).date()
                cur.execute("SELECT COUNT(*) FROM orders_paper WHERE DATE(ts)=%s", (prev,))
                fills = int(cur.fetchone()[0] or 0)
                cur.close()
                conn.close()
        except Exception:
            fills = 0
        # í˜„ì¬ê°’ ì½ê¸°
        def _getf(k, d):
            v = r.get(k)
            try:
                return float(v) if v is not None else d
            except Exception:
                return d
        rth = _getf("cfg:signal_cutoff:rth", settings.SIGNAL_CUTOFF_RTH)
        ext = _getf("cfg:signal_cutoff:ext", settings.SIGNAL_CUTOFF_EXT)
        # ì¡°ì • (í˜„ì‹¤ì  ê²½ê³„ê°’ìœ¼ë¡œ ìˆ˜ì •)
        rth_base, ext_base = settings.SIGNAL_CUTOFF_RTH, settings.SIGNAL_CUTOFF_EXT
        delta = -0.02 if fills == 0 else (0.02 if fills >= 4 else 0.0)
        rth_new = min(max(rth + delta, max(0.12, rth_base - 0.06)), rth_base + 0.12)
        ext_new = min(max(ext + delta, max(0.18, ext_base - 0.10)), ext_base + 0.10)
        r.set("cfg:signal_cutoff:rth", rth_new)
        r.set("cfg:signal_cutoff:ext", ext_new)
        return {"status": "ok", "fills": fills, "rth": rth_new, "ext": ext_new}
    except Exception as e:
        logger.error(f"ì ì‘í˜• ì»·ì˜¤í”„ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}


if __name__ == "__main__":
    # ê°œë°œìš© ì‹¤í–‰
    celery_app.start()
