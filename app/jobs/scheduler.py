"""
Celery beat ìŠ¤ì¼€ì¤„ëŸ¬
15-30ì´ˆ ì£¼ê¸°ë¡œ ì‹œê·¸ë„ ìƒì„± ë° ê±°ë˜ ì‹¤í–‰
"""
from datetime import datetime, timedelta, timezone
import hashlib
import json
import logging
import os
import time
from typing import Dict, List, Optional, Tuple, Union
import urllib.parse as _urlparse

import psycopg2
import redis

from celery import Celery
from celery.schedules import crontab
from celery.signals import beat_init, task_prerun, worker_process_init, worker_ready

# ë¡œê¹… ì„¤ì • (ë‹¤ë¥¸ importë³´ë‹¤ ë¨¼ì €)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# GPT-5 ë¦¬ìŠ¤í¬ ê´€ë¦¬ í†µí•©
try:
    from app.engine.risk_manager import get_risk_manager
    from app.adapters.trading_adapter import get_trading_adapter
    RISK_MANAGER_AVAILABLE = True
except ImportError:
    RISK_MANAGER_AVAILABLE = False
    logger.warning("âš ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì import ì‹¤íŒ¨ - ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘")

from app.config import settings, get_signal_cutoffs, sanitize_cutoffs_in_redis
from app.utils.rate_limiter import get_rate_limiter, TokenTier

def check_signal_risk_feasibility(signal, session_label):
    """
    ì‹ í˜¸ ë°œí–‰ ì „ ë¦¬ìŠ¤í¬ ì²´í¬ (GPT-5 ê¶Œì¥)
    ë™ì‹œìœ„í—˜ í•œë„ë¥¼ ì´ˆê³¼í•  ê°€ëŠ¥ì„±ì´ ìˆëŠ” ì‹ í˜¸ëŠ” ì‚¬ì „ í•„í„°ë§
    
    Returns:
        Tuple[bool, str]: (í—ˆìš© ì—¬ë¶€, ì‚¬ìœ )
    """
    if not RISK_MANAGER_AVAILABLE:
        return True, "ë¦¬ìŠ¤í¬ ê´€ë¦¬ì ë¹„í™œì„±í™”"
    
    try:
        # í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ í™•ì¸
        trading_adapter = get_trading_adapter()
        portfolio = trading_adapter.get_portfolio_summary()
        positions = trading_adapter.get_positions()
        
        # í˜„ì¬ ì´ ìœ„í—˜ ê³„ì‚°
        equity = portfolio.get('equity', 0)
        if equity <= 0:
            return False, "ê³„ì¢Œ ìì‚° í™•ì¸ ë¶ˆê°€"
        
        current_risk = 0
        for pos in positions:
            # ê° í¬ì§€ì…˜ ìœ„í—˜ (1.5% ì†ì ˆ ê°€ì •)
            stop_distance = pos.avg_price * 0.015
            pos_risk = abs(pos.quantity * stop_distance) / equity
            current_risk += pos_risk
        
        # ì‹ ê·œ ì‹ í˜¸ì˜ ì˜ˆìƒ ìœ„í—˜ (0.5% ê¸°ë³¸ê°’)
        risk_manager = get_risk_manager()
        expected_new_risk = risk_manager.config.risk_per_trade
        
        # ë™ì‹œìœ„í—˜ í•œë„ ì²´í¬ (2%)
        total_risk = current_risk + expected_new_risk
        max_risk = risk_manager.config.max_concurrent_risk
        
        if total_risk > max_risk:
            return False, f"ë™ì‹œìœ„í—˜ í•œë„ ì´ˆê³¼ ì˜ˆìƒ: {total_risk:.2%} > {max_risk:.2%}"
        
        # í¬ì§€ì…˜ ìˆ˜ ì²´í¬
        if len(positions) >= risk_manager.config.max_positions:
            return False, f"ìµœëŒ€ í¬ì§€ì…˜ ìˆ˜ ë„ë‹¬: {len(positions)}/{risk_manager.config.max_positions}"
        
        logger.info(f"âœ… {signal.ticker} ë¦¬ìŠ¤í¬ pre-check í†µê³¼: í˜„ì¬ {current_risk:.2%} + ì˜ˆìƒ {expected_new_risk:.2%} = {total_risk:.2%}")
        return True, f"ë¦¬ìŠ¤í¬ í—ˆìš©: {total_risk:.2%}/{max_risk:.2%}"
        
    except Exception as e:
        logger.error(f"âŒ ë¦¬ìŠ¤í¬ pre-check ì‹¤íŒ¨: {e}")
        # ì•ˆì „ì„ ìœ„í•´ ì²´í¬ ì‹¤íŒ¨ì‹œì—ë„ í—ˆìš© (ê¸°ì¡´ ë™ì‘ ìœ ì§€)
        return True, "ë¦¬ìŠ¤í¬ ì²´í¬ ì˜¤ë¥˜ë¡œ ê¸°ë³¸ í—ˆìš©"

# Celery ì•± ìƒì„±
celery_app = Celery(
    "trading_bot",
    broker=os.getenv("REDIS_URL", "redis://localhost:6379/0"),
    backend=os.getenv("REDIS_URL", "redis://localhost:6379/0")
)

# ì„¤ì •
celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Asia/Seoul",  # KST
    enable_utc=True,        # UTC ìœ ì§€ + íƒ€ì„ì¡´-aware ìŠ¤ì¼€ì¤„ OK
    task_track_started=True,
    task_time_limit=30 * 60,  # 30ë¶„
    task_soft_time_limit=25 * 60,  # 25ë¶„
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=1000,
    include=[
        "app.jobs.scheduler",
        "app.jobs.paper_trading_manager",
        "app.jobs.daily_briefing",
    ],
)

# ìŠ¤ì¼€ì¤„ ì„¤ì •
celery_app.conf.beat_schedule = {
    # 15ì´ˆë§ˆë‹¤ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (E2E)
    "pipeline-e2e": {
        "task": "app.jobs.scheduler.pipeline_e2e",
        "schedule": 15.0,  # 15ì´ˆ
    },
    # 15ì´ˆë§ˆë‹¤ ì‹œê·¸ë„ ìƒì„±
    "generate-signals": {
        "task": "app.jobs.scheduler.generate_signals",
        "schedule": 15.0,  # 15ì´ˆ
    },
    # 30ì´ˆë§ˆë‹¤ ì‹œì„¸ ì—…ë°ì´íŠ¸
    "update-quotes": {
        "task": "app.jobs.scheduler.update_quotes",
        "schedule": 30.0,  # 30ì´ˆ
    },
    # 1ë¶„ë§ˆë‹¤ EDGAR ìŠ¤ìº”
    "scan-edgar": {
        "task": "app.jobs.scheduler.scan_edgar",
        "schedule": 60.0,  # 1ë¶„
    },
    # 5ë¶„ë§ˆë‹¤ ë¦¬ìŠ¤í¬ ì²´í¬
    "check-risk": {
        "task": "app.jobs.scheduler.check_risk",
        "schedule": 300.0,  # 5ë¶„
    },
    # ë§¤ì¼ ìì •ì— ì¼ì¼ ë¦¬ì…‹
    "daily-reset": {
        "task": "app.jobs.scheduler.daily_reset",
        "schedule": crontab(hour=0, minute=0),  # ë§¤ì¼ 00:00
    },
    # ë§¤ì¼ 06:10 KSTì— ì¼ì¼ ë¦¬í¬íŠ¸ (KST = UTC+9, 06:10 KST = 21:10 UTC ì „ë‚ )
    "daily-report": {
        "task": "app.jobs.scheduler.daily_report",
        "schedule": crontab(hour=21, minute=10),  # ë§¤ì¼ 21:10 UTC = 06:10 KST
        "args": [False, True],  # force=False, post=True (ìŠ¬ë™ìœ¼ë¡œ ë³´ë‚´ê¸°)
    },
    # 5ì´ˆë§ˆë‹¤ EDGAR ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ â†’ DB ì ì¬ (dedupeëŠ” DB UNIQUEì™€ ON CONFLICTë¡œ ë³´ê°•)
    "ingest-edgar": {
        "task": "app.jobs.scheduler.ingest_edgar_stream",
        "schedule": 5.0,
    },
    # 15ë¶„ë§ˆë‹¤ ìœ ë‹ˆë²„ìŠ¤ ì¬ì ìš© (ê¶Œì¥ ë¶„ë¦¬)
    "refresh-universe": {
        "task": "app.jobs.scheduler.refresh_universe",
        "schedule": 900.0,
    },
    # ë§¤ì¼ 05:55 KST ì ì‘í˜• ì»·ì˜¤í”„ ê°±ì‹  (ë¦¬í¬íŠ¸ ì§ì „)
    "adaptive-cutoff": {
        "task": "app.jobs.scheduler.adaptive_cutoff",
        "schedule": crontab(hour=20, minute=55),  # 05:55 KST = 20:55 UTC ì „ë‚ 
    },
    
    # =============================================================================
    # Phase 1.5: ì¼ì¼ ë¸Œë¦¬í•‘ ì‹œìŠ¤í…œ (ë‹µë‹µí•¨ í•´ì†Œ!)
    # =============================================================================
    
    # ì•„ì¹¨ ë¸Œë¦¬í•‘ (09:00 KST = 00:00 UTC)
    "morning-briefing": {
        "task": "app.jobs.daily_briefing.send_scheduled_briefing",
        "schedule": crontab(hour=0, minute=0),  # 09:00 KST
        "args": ["morning"],
    },
    
    # ì ì‹¬ ë¸Œë¦¬í•‘ (12:30 KST = 03:30 UTC)  
    "midday-briefing": {
        "task": "app.jobs.daily_briefing.send_scheduled_briefing",
        "schedule": crontab(hour=3, minute=30),  # 12:30 KST
        "args": ["midday"],
    },
    
    # ì €ë… ë¸Œë¦¬í•‘ (18:00 KST = 09:00 UTC)
    "evening-briefing": {
        "task": "app.jobs.daily_briefing.send_scheduled_briefing",
        "schedule": crontab(hour=9, minute=0),  # 18:00 KST
        "args": ["evening"],
    },
    
    # ì¡°ìš©í•œ ì‹œì¥ ì²´í¬ (1ì‹œê°„ë§ˆë‹¤, 9-18ì‹œ KSTë§Œ)
    "quiet-market-check": {
        "task": "app.jobs.daily_briefing.check_and_send_quiet_message",
        "schedule": crontab(minute=0),  # ë§¤ ì •ì‹œë§ˆë‹¤
    },
    
    # =============================================================================
    # Phase 1.5: ìŠ¤ë§ˆíŠ¸ í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ
    # =============================================================================
    
    # ìŠ¤í†±ë¡œìŠ¤/ìµì ˆ ì£¼ë¬¸ ì²´í¬ (5ë¶„ë§ˆë‹¤)
    "check-stop-orders": {
        "task": "app.jobs.paper_trading_manager.check_stop_orders",
        "schedule": crontab(minute="*/5"),  # 5ë¶„ë§ˆë‹¤
    },
    
    # ì¼ì¼ ì„±ê³¼ ë¦¬í¬íŠ¸ (ì €ë… 19:00 KST = 10:00 UTC)
    "daily-paper-report": {
        "task": "app.jobs.paper_trading_manager.send_daily_report", 
        "schedule": crontab(hour=10, minute=0),  # 19:00 KST
    },
}

# ì „ì—­ ë³€ìˆ˜ (ì‹¤ì œë¡œëŠ” ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©)
trading_components = {
    "quotes_ingestor": None,
    "edgar_scanner": None,
    "regime_detector": None,
    "tech_score_engine": None,
    "llm_engine": None,
    "signal_mixer": None,
    "risk_engine": None,
    "paper_ledger": None,
    "redis_streams": None,
    "slack_bot": None,
    "stream_consumer": None,
    "db_connection": None,
}

def _parse_redis_url(url: str) -> tuple[str, int, int]:
    try:
        parsed = _urlparse.urlparse(url)
        host = parsed.hostname or "redis"
        port = int(parsed.port or 6379)
        db = int((parsed.path or "/0").lstrip("/") or 0)
        return host, port, db
    except Exception:
        return "redis", 6379, 0

def _autoinit_components_if_enabled() -> None:
    """Best-effort ì»´í¬ë„ŒíŠ¸ ìë™ ì´ˆê¸°í™” (ì›Œì»¤/ë¹„íŠ¸ í”„ë¡œì„¸ìŠ¤ ê¸°ë™ ì‹œ).
    í•„ìˆ˜ êµ¬ì„±ë§Œì´ë¼ë„ ì¤€ë¹„í•´ components_not_ready ìŠ¤í‚µì„ ì¤„ì¸ë‹¤.
    """
    if os.getenv("AUTO_INIT_COMPONENTS", "true").lower() not in ("1","true","yes","on"):  # opt-out
        return
    try:
        from app.io.quotes_delayed import DelayedQuotesIngestor
        from app.engine.regime import RegimeDetector
        from app.engine.techscore import TechScoreEngine
        from app.engine.mixer import SignalMixer
        from app.engine.risk import RiskEngine
        from app.adapters.paper_ledger import PaperLedger
        from app.io.streams import RedisStreams, StreamConsumer
        from app.engine.llm_insight import LLMInsightEngine
        from app.io.slack_bot import SlackBot
    except Exception as e:
        logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return

    components: Dict[str, object] = {}

    # Quotes ingestor
    try:
        components["quotes_ingestor"] = DelayedQuotesIngestor()
        # ì›Œë°ì—…ìœ¼ë¡œ ë¹ˆ ë²„í¼ ë°©ì§€
        components["quotes_ingestor"].warmup_backfill()  # type: ignore
        logger.info("ë”œë ˆì´ë“œ Quotes ì¸ì œìŠ¤í„° ì›Œë°ì—… ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"Quotes ì¸ì œìŠ¤í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Regime/Tech/Mixer
    try:
        components["regime_detector"] = RegimeDetector()
    except Exception as e:
        logger.warning(f"RegimeDetector ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        components["tech_score_engine"] = TechScoreEngine()
    except Exception as e:
        logger.warning(f"TechScoreEngine ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        thr = settings.MIXER_THRESHOLD
        components["signal_mixer"] = SignalMixer(buy_threshold=thr, sell_threshold=-thr)
    except Exception as e:
        logger.warning(f"SignalMixer ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Risk/Paper ledger
    try:
        init_cap = float(os.getenv("INITIAL_CAPITAL", "1000000"))
        components["risk_engine"] = RiskEngine(initial_capital=init_cap)
    except Exception as e:
        logger.warning(f"RiskEngine ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        components["paper_ledger"] = PaperLedger(initial_cash=float(os.getenv("INITIAL_CAPITAL", "1000000")))
    except Exception as e:
        logger.warning(f"PaperLedger ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Redis streams / consumer
    try:
        rurl = os.getenv("REDIS_URL", "redis://redis:6379/0")
        host, port, db = _parse_redis_url(rurl)
        rs = RedisStreams(host=host, port=port, db=db)
        components["redis_streams"] = rs
        components["stream_consumer"] = StreamConsumer(rs)
    except Exception as e:
        logger.warning(f"Redis Streams ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Slack bot (optional)
    try:
        token = os.getenv("SLACK_BOT_TOKEN")
        channel = os.getenv("SLACK_CHANNEL_ID") or os.getenv("SLACK_CHANNEL", "#trading-signals")
        logger.info(f"ğŸ” [DEBUG] SlackBot í™˜ê²½ë³€ìˆ˜: token={'***' if token else None}, channel_id={os.getenv('SLACK_CHANNEL_ID')}, channel_fallback={os.getenv('SLACK_CHANNEL')}")
        logger.info(f"ğŸ” [DEBUG] SlackBot ìµœì¢… ì±„ë„: {channel}")
        if token:
            components["slack_bot"] = SlackBot(token=token, channel=channel)
            logger.info(f"Slack ë´‡ ì¤€ë¹„: ì±„ë„ {channel}")
        else:
            logger.warning("Slack í† í° ì—†ìŒ - ìŠ¬ë™ ë¹„í™œì„±")
    except Exception as e:
        logger.warning(f"SlackBot ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # LLM (optional)
    try:
        llm = LLMInsightEngine()
        if components.get("slack_bot"):
            llm.set_slack_bot(components["slack_bot"])  # type: ignore
        components["llm_engine"] = llm
    except Exception as e:
        logger.warning(f"LLM ì—”ì§„ ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    if components:
        try:
            initialize_components(components)  # ê¸°ì¡´ í—¬í¼ë¡œ ì£¼ì…
        except Exception as e:
            logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì£¼ì… ì‹¤íŒ¨: {e}")

# Celery ì‹ í˜¸ì— ìë™ ì´ˆê¸°í™” ì—°ê²°
@worker_ready.connect
def _on_worker_ready(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

@beat_init.connect
def _on_beat_init(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

# ê° ì›Œì»¤ í”„ë¡œì„¸ìŠ¤(prefork)ì—ì„œ í•œ ë²ˆì”© ì´ˆê¸°í™”
@worker_process_init.connect
def _on_worker_process_init(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

# íƒœìŠ¤í¬ ì§ì „ì—ë„ í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì‹œë„
@task_prerun.connect
def _ensure_components_before_task(task=None, **kwargs):
    try:
        required_keys = [
            "quotes_ingestor",
            "regime_detector",
            "tech_score_engine",
            "signal_mixer",
        ]
        missing = [k for k in required_keys if not trading_components.get(k)]
        if missing:
            logger.warning(f"í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„(prerun): {missing} â†’ ìë™ ì´ˆê¸°í™” ì‹œë„")
            _autoinit_components_if_enabled()
    except Exception as e:
        logger.warning(f"prerun ìë™ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# =============================================================================
# Tier System Functions (Universe Expansion)
# =============================================================================

def get_ticker_tier(ticker: str) -> Optional[TokenTier]:
    """
    ì¢…ëª©ì´ ì†í•œ Tier ë°˜í™˜
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        Optional[TokenTier]: Tier íƒ€ì… (Noneì´ë©´ ë²¤ì¹˜)
    """
    ticker = ticker.upper().strip()
    
    tier_a_tickers = [t.strip().upper() for t in settings.TIER_A_TICKERS]
    tier_b_tickers = [t.strip().upper() for t in settings.TIER_B_TICKERS]
    
    if ticker in tier_a_tickers:
        return TokenTier.TIER_A
    elif ticker in tier_b_tickers:
        return TokenTier.TIER_B
    else:
        return None  # ë²¤ì¹˜ (ì´ë²¤íŠ¸ ê¸°ë°˜)

def should_process_ticker_now(ticker: str, current_time: Optional[Union[datetime, int]] = None) -> Tuple[bool, str]:
    """
    í˜„ì¬ ì‹œê°„ì— í•´ë‹¹ ì¢…ëª©ì„ ë¶„ì„í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        current_time: í˜„ì¬ ì‹œê°„ (Noneì´ë©´ datetime.now())
        
    Returns:
        Tuple[bool, str]: (ì²˜ë¦¬ ì—¬ë¶€, ì‚¬ìœ )
    """
    if current_time is None:
        current_time = datetime.now()
    
    tier = get_ticker_tier(ticker)
    
    # ë²¤ì¹˜ ì¢…ëª©ì€ ì´ë²¤íŠ¸ ê¸°ë°˜ë§Œ ì²˜ë¦¬ (í˜„ì¬ëŠ” ìŠ¤í‚µ)
    if tier is None:
        return False, "bench_event_only"
    
    # í˜„ì¬ ë¶„ì˜ ì´ˆ (timestampì—ì„œ datetime ê°ì²´ë¡œ ë³€í™˜)
    if isinstance(current_time, int):
        from datetime import datetime
        current_time = datetime.fromtimestamp(current_time)
    current_second = current_time.second
    
    if tier == TokenTier.TIER_A:
        # Tier A: 30ì´ˆë§ˆë‹¤ (0ì´ˆ, 30ì´ˆ)
        return current_second % 30 == 0, "tier_a_schedule"
    elif tier == TokenTier.TIER_B:
        # Tier B: 60ì´ˆë§ˆë‹¤ (0ì´ˆë§Œ)
        return current_second == 0, "tier_b_schedule"
    
    return False, "unknown_tier"

def can_consume_api_token_for_ticker(ticker: str) -> Tuple[bool, str]:
    """
    í•´ë‹¹ ì¢…ëª© ë¶„ì„ì„ ìœ„í•œ API í† í° ì†Œë¹„ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        Tuple[bool, str]: (ì†Œë¹„ ê°€ëŠ¥ ì—¬ë¶€, ì‚¬ìœ )
    """
    try:
        rate_limiter = get_rate_limiter()
        tier = get_ticker_tier(ticker)
        
        if tier is None:
            # ë²¤ì¹˜ ì¢…ëª©ì€ ì˜ˆì•½ í† í° ì‚¬ìš©
            tier = TokenTier.RESERVE
        
        can_consume = rate_limiter.can_consume_token(tier)
        if can_consume:
            return True, f"token_available_{tier.value}"
        else:
            return False, f"token_exhausted_{tier.value}"
            
    except Exception as e:
        logger.error(f"í† í° í™•ì¸ ì‹¤íŒ¨: {e}")
        return False, f"token_check_error: {e}"

def consume_api_token_for_ticker(ticker: str) -> Tuple[bool, str]:
    """
    í•´ë‹¹ ì¢…ëª© ë¶„ì„ì„ ìœ„í•œ API í† í° ì‹¤ì œ ì†Œë¹„
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        
    Returns:
        Tuple[bool, str]: (ì†Œë¹„ ì„±ê³µ ì—¬ë¶€, ì‚¬ìœ )
    """
    try:
        rate_limiter = get_rate_limiter()
        tier = get_ticker_tier(ticker)
        
        if tier is None:
            # ë²¤ì¹˜ ì¢…ëª©ì€ ì˜ˆì•½ í† í° ì‚¬ìš© (Fallbackë„ ì‹œë„)
            success, used_tier = rate_limiter.try_consume_with_fallback(
                TokenTier.RESERVE, 
                TokenTier.TIER_B  # Reserve ë¶€ì¡±ì‹œ Tier B ì‚¬ìš©
            )
            return success, f"consumed_{used_tier.value}_for_bench"
        else:
            # Tier A/BëŠ” í•´ë‹¹ í† í° ì‚¬ìš© (Fallbackë„ ì‹œë„)
            fallback_tier = TokenTier.RESERVE if tier == TokenTier.TIER_A else None
            success, used_tier = rate_limiter.try_consume_with_fallback(tier, fallback_tier)
            return success, f"consumed_{used_tier.value}"
            
    except Exception as e:
        logger.error(f"í† í° ì†Œë¹„ ì‹¤íŒ¨: {e}")
        return False, f"token_consume_error: {e}"

def get_universe_with_tiers() -> Dict[str, List[str]]:
    """
    Tierë³„ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
    Returns:
        Dict[str, List[str]]: Tierë³„ ì¢…ëª© ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ë™ì  ìœ ë‹ˆë²„ìŠ¤ ì¡°íšŒ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
        dynamic_universe = None
        try:
            rurl = os.getenv("REDIS_URL")
            if rurl:
                r = redis.from_url(rurl)
                external = r.smembers("universe:external") or []
                watch = r.smembers("universe:watchlist") or []
                core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
                ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
                wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
                merged = []
                seen = set()
                max_n = int(os.getenv("UNIVERSE_MAX", "100"))
                for arr in [core, ext, wch]:
                    for s in arr:
                        if s and s not in seen:
                            merged.append(s)
                            seen.add(s)
                        if len(merged) >= max_n:
                            break
                    if len(merged) >= max_n:
                        break
                dynamic_universe = merged
        except Exception:
            dynamic_universe = None
        
        # Fallback: ì„¤ì •ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        all_tickers = dynamic_universe or []
        if not all_tickers:
            all_tickers = (
                settings.TIER_A_TICKERS + 
                settings.TIER_B_TICKERS + 
                settings.BENCH_TICKERS
            )
        
        # Tierë³„ ë¶„ë¥˜
        tier_a = [t for t in all_tickers if get_ticker_tier(t) == TokenTier.TIER_A]
        tier_b = [t for t in all_tickers if get_ticker_tier(t) == TokenTier.TIER_B] 
        bench = [t for t in all_tickers if get_ticker_tier(t) is None]
        
        return {
            "tier_a": tier_a,
            "tier_b": tier_b,
            "bench": bench
        }
        
    except Exception as e:
        logger.error(f"ìœ ë‹ˆë²„ìŠ¤ Tier ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return {
            "tier_a": settings.TIER_A_TICKERS,
            "tier_b": settings.TIER_B_TICKERS,
            "bench": settings.BENCH_TICKERS
        }

def should_call_llm_for_event(ticker: str, event_type: str, signal_score: float = None, 
                              edgar_filing: Dict = None) -> Tuple[bool, str]:
    """
    LLM í˜¸ì¶œ ê²Œì´íŒ… ì‹œìŠ¤í…œ - ì—„ê²©í•œ ì´ë²¤íŠ¸ ê¸°ë°˜ íŠ¸ë¦¬ê±°ë§
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        event_type: ì´ë²¤íŠ¸ íƒ€ì… ('edgar', 'vol_spike')
        signal_score: ì‹ í˜¸ ì ìˆ˜ (vol_spikeìš©)
        edgar_filing: EDGAR ê³µì‹œ ì •ë³´
        
    Returns:
        Tuple[bool, str]: (í˜¸ì¶œ í—ˆìš© ì—¬ë¶€, ì‚¬ìœ )
    """
    try:
        # LLM ê²Œì´íŒ… ë¹„í™œì„±í™”ì‹œ ë¬´ì¡°ê±´ í—ˆìš©
        if not settings.LLM_GATING_ENABLED:
            return True, "gating_disabled"
        
        # 1. ì¼ì¼ í˜¸ì¶œ í•œë„ ì²´í¬
        rurl = os.getenv("REDIS_URL")
        if rurl:
            r = redis.from_url(rurl)
            
            # ET ê¸°ì¤€ ë‚ ì§œ í‚¤
            et_tz = timezone(timedelta(hours=-5))
            now_et = datetime.now(et_tz)
            if 3 <= now_et.month <= 11:  # DST ê°„ì´ ì ìš©
                et_tz = timezone(timedelta(hours=-4))
                now_et = datetime.now(et_tz)
            
            daily_key = f"llm_calls:{now_et:%Y%m%d}"
            current_calls = int(r.get(daily_key) or 0)
            
            if current_calls >= settings.LLM_DAILY_CALL_LIMIT:
                return False, f"daily_limit_exceeded ({current_calls}/{settings.LLM_DAILY_CALL_LIMIT})"
        
        # 2. ì´ë²¤íŠ¸ë³„ ì¡°ê±´ ê²€ì¦
        if event_type == "edgar":
            # EDGAR ì´ë²¤íŠ¸ëŠ” í•­ìƒ í—ˆìš© (ì¤‘ìš”ë„ ë†’ìŒ)
            cache_key = f"llm_cache:edgar:{ticker}:{edgar_filing.get('form_type', 'unknown')}"
            
        elif event_type == "vol_spike":
            # vol_spikeëŠ” ì‹ í˜¸ ì ìˆ˜ ì¡°ê±´ í•„ìš”
            if signal_score is None or abs(signal_score) < settings.LLM_MIN_SIGNAL_SCORE:
                return False, f"signal_score_too_low (|{signal_score}| < {settings.LLM_MIN_SIGNAL_SCORE})"
            
            cache_key = f"llm_cache:vol_spike:{ticker}"
            
        else:
            return False, f"unknown_event_type: {event_type}"
        
        # 3. ì¤‘ë³µ ë°©ì§€ ìºì‹œ ì²´í¬ (30ë¶„)
        if rurl:
            cached = r.get(cache_key)
            if cached:
                return False, f"cached_within_{settings.LLM_CACHE_DURATION_MIN}min"
        
        return True, f"allowed_{event_type}"
        
    except Exception as e:
        logger.error(f"LLM ê²Œì´íŒ… ì²´í¬ ì‹¤íŒ¨: {e}")
        # ì•ˆì „ì„ ìœ„í•´ ì—ëŸ¬ì‹œ ì°¨ë‹¨
        return False, f"gating_error: {e}"

def consume_llm_call_quota(ticker: str, event_type: str, edgar_filing: Dict = None) -> bool:
    """
    LLM í˜¸ì¶œ ì¿¼í„° ì‹¤ì œ ì†Œë¹„ ë° ìºì‹œ ë§ˆí‚¹
    
    Args:
        ticker: ì¢…ëª© ì½”ë“œ
        event_type: ì´ë²¤íŠ¸ íƒ€ì…
        edgar_filing: EDGAR ê³µì‹œ ì •ë³´
        
    Returns:
        bool: ì†Œë¹„ ì„±ê³µ ì—¬ë¶€
    """
    try:
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return True
        
        r = redis.from_url(rurl)
        
        # ì¼ì¼ ì¹´ìš´í„° ì¦ê°€
        et_tz = timezone(timedelta(hours=-5))
        now_et = datetime.now(et_tz)
        if 3 <= now_et.month <= 11:
            et_tz = timezone(timedelta(hours=-4))
            now_et = datetime.now(et_tz)
        
        daily_key = f"llm_calls:{now_et:%Y%m%d}"
        r.incr(daily_key)
        r.expire(daily_key, 86400)  # 24ì‹œê°„ TTL
        
        # ìºì‹œ ë§ˆí‚¹
        if event_type == "edgar":
            cache_key = f"llm_cache:edgar:{ticker}:{edgar_filing.get('form_type', 'unknown')}"
        else:
            cache_key = f"llm_cache:vol_spike:{ticker}"
        
        r.setex(cache_key, settings.LLM_CACHE_DURATION_MIN * 60, 1)
        
        return True
        
    except Exception as e:
        logger.error(f"LLM ì¿¼í„° ì†Œë¹„ ì‹¤íŒ¨: {e}")
        return False

def get_llm_usage_stats() -> Dict[str, int]:
    """
    LLM ì‚¬ìš©ëŸ‰ í†µê³„ ì¡°íšŒ
    
    Returns:
        Dict: ì‚¬ìš©ëŸ‰ í†µê³„
    """
    try:
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return {"daily_used": 0, "daily_limit": settings.LLM_DAILY_CALL_LIMIT}
        
        r = redis.from_url(rurl)
        
        et_tz = timezone(timedelta(hours=-5))
        now_et = datetime.now(et_tz)
        if 3 <= now_et.month <= 11:
            et_tz = timezone(timedelta(hours=-4))
            now_et = datetime.now(et_tz)
        
        daily_key = f"llm_calls:{now_et:%Y%m%d}"
        daily_used = int(r.get(daily_key) or 0)
        
        return {
            "daily_used": daily_used,
            "daily_limit": settings.LLM_DAILY_CALL_LIMIT,
            "remaining": max(0, settings.LLM_DAILY_CALL_LIMIT - daily_used),
            "usage_pct": (daily_used / settings.LLM_DAILY_CALL_LIMIT) * 100 if settings.LLM_DAILY_CALL_LIMIT > 0 else 0
        }
        
    except Exception as e:
        logger.error(f"LLM ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {"daily_used": 0, "daily_limit": settings.LLM_DAILY_CALL_LIMIT, "error": str(e)}

@celery_app.task(bind=True, name="app.jobs.scheduler.pipeline_e2e")
def pipeline_e2e(self):
    """E2E íŒŒì´í”„ë¼ì¸: EDGAR ì´ë²¤íŠ¸ â†’ LLM â†’ ë ˆì§ â†’ ë¯¹ì„œ â†’ DB â†’ Slack"""
    try:
        start_time = time.time()
        logger.info("E2E íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # ì»´í¬ë„ŒíŠ¸ í™•ì¸ (í•„ìˆ˜ ìµœì†Œ êµ¬ì„±ë§Œ ê°•ì œ, LLMì€ ì„ íƒ)
        if not all([
            trading_components["stream_consumer"],
            trading_components["regime_detector"],
            trading_components["signal_mixer"],
            trading_components["slack_bot"]
        ]):
            logger.warning("í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„(stream_consumer/regime_detector/signal_mixer/slack_bot)")
            return {"status": "skipped", "reason": "components_not_ready"}
        
        stream_consumer = trading_components["stream_consumer"]
        llm_engine = trading_components["llm_engine"]
        regime_detector = trading_components["regime_detector"]
        signal_mixer = trading_components["signal_mixer"]
        slack_bot = trading_components["slack_bot"]
        
        signals_processed = 0
        
        # 1. EDGAR ì´ë²¤íŠ¸ ì†Œë¹„
        edgar_events = stream_consumer.consume_edgar_events(count=5, block_ms=100)
        
        for event in edgar_events:
            try:
                ticker = event.data.get("ticker")
                if not ticker:
                    continue
                
                # 2. LLM ë¶„ì„ (EDGAR ì´ë²¤íŠ¸ì´ë¯€ë¡œ ì¡°ê±´ ì¶©ì¡±)
                llm_insight = None
                if llm_engine:
                    text = event.data.get("snippet_text", "")
                    url = event.data.get("url", "")
                    llm_insight = llm_engine.analyze_text(text, url, edgar_event=True)
                
                # 3. ì‹œì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê°„ë‹¨í•œ ëª¨ì˜ ë°ì´í„°)
                candles = get_mock_candles(ticker)
                get_mock_indicators(ticker)
                
                # 4. ë ˆì§ ê°ì§€
                regime_result = regime_detector.detect_regime(candles)
                
                # 5. ê¸°ìˆ ì  ì ìˆ˜ ê³„ì‚°
                tech_score = get_mock_tech_score(ticker)
                
                # 6. ì‹œê·¸ë„ ë¯¹ì‹±
                current_price = 150.0  # ëª¨ì˜ ê°€ê²©
                signal = signal_mixer.mix_signals(
                    ticker=ticker,
                    regime_result=regime_result,
                    tech_score=tech_score,
                    llm_insight=llm_insight,
                    edgar_filing=event.data,
                    current_price=current_price
                )
                
                if signal:
                    # ë©”íƒ€ì— ì„¸ì…˜/í’ˆì§ˆ ì§€í‘œ ì‹¬ê¸° â†’ Slack í—¤ë” ë¼ë²¨ìš©
                    if not signal.meta:
                        signal.meta = {}
                    session_label = _session_label()
                    signal.meta["session"] = session_label
                    # ì•ˆì „ ê°€ë“œ: ë¯¸ì •ì˜ ë³€ìˆ˜ ì²˜ë¦¬
                    signal.meta.setdefault("spread_bp", 0.0)
                    signal.meta.setdefault("dollar_vol_5m", 0.0)
                    # 7. DBì— ì €ì¥
                    if trading_components.get("db_connection"):
                        signal_mixer.save_signal_to_db(signal, trading_components["db_connection"])
                    
                    # 8. Slack ì•Œë¦¼
                    if slack_bot:
                        slack_message = format_slack_message(signal)
                        slack_bot.send_message(slack_message)
                    
                    # 9. ë©”ì‹œì§€ ACK
                    stream_consumer.acknowledge("news.edgar", event.message_id)
                    
                    signals_processed += 1
                    logger.info(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {ticker} {signal.signal_type.value}")
                
            except Exception as e:
                logger.error(f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        execution_time = time.time() - start_time
        logger.info(f"E2E íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {signals_processed}ê°œ, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "signals_processed": signals_processed,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"E2E íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def get_mock_candles(ticker: str) -> List:
    """ëª¨ì˜ ìº”ë“¤ ë°ì´í„°"""
    # ì‹¤ì œë¡œëŠ” quotes_ingestorì—ì„œ ê°€ì ¸ì˜´
    return []

def get_mock_indicators(ticker: str) -> Dict:
    """ëª¨ì˜ ê¸°ìˆ ì  ì§€í‘œ"""
    # ì‹¤ì œë¡œëŠ” quotes_ingestorì—ì„œ ê°€ì ¸ì˜´
    return {
        "adx": 25.0,
        "ema_20": 150.0,
        "ema_50": 148.0,
        "rsi": 65.0,
        "volume_spike": 0.3,
        "price_change_5m": 0.02,
        "realized_volatility": 0.03,
        "current_price": 150.0,
        "vwap": 149.5,
        "vwap_deviation": 0.003,
        "macd": 0.5,
        "macd_signal": 0.3,
        "bb_position": 0.6
    }

def get_mock_tech_score(ticker: str):
    """ëª¨ì˜ ê¸°ìˆ ì  ì ìˆ˜"""
    # ì‹¤ì œë¡œëŠ” tech_score_engineì—ì„œ ê³„ì‚°
    from app.engine.techscore import TechScoreResult
    return TechScoreResult(
        score=0.7,
        components={
            "ema": 0.8,
            "macd": 0.7,
            "rsi": 0.6,
            "vwap": 0.7,
        },
        timestamp=datetime.now()
    )

def format_slack_message(signal) -> Dict:
    """ìŠ¬ë™ ë©”ì‹œì§€ í¬ë§· (ê°€ê²©/ë²„íŠ¼/ìƒíƒœì •ë³´ í¬í•¨)"""
    import os
    import json
    
    # ê¸°ë³¸ ë©”ì‹œì§€ í…ìŠ¤íŠ¸
    regime_display = signal.regime.upper().replace("_", "")
    score_sign = "+" if signal.score >= 0 else ""
    action = "long" if signal.signal_type.value == "long" else "short"
    action_ko = "ë¡±" if action == "long" else "ìˆ"
    
    # ë©”ì¸ ë©”ì‹œì§€
    main_text = (
        f"{signal.ticker} | ë ˆì§ {regime_display}({signal.confidence:.2f}) | "
        f"ì ìˆ˜ {score_sign}{signal.score:.2f} {action_ko}"
    )
    
    # ë””í…Œì¼ ë¼ì¸
    detail_text = (
        f"ì œì•ˆ: ì§„ì… {signal.entry_price:.2f} / "
        f"ì†ì ˆ {signal.stop_loss:.2f} / ìµì ˆ {signal.take_profit:.2f}\n"
        f"ì´ìœ : {signal.trigger} (<= {signal.horizon_minutes}m)"
    )
    
    # ë²„íŠ¼ ìƒì„± ì—¬ë¶€ í™•ì¸ (ë°˜ìë™ ëª¨ë“œ)
    show_buttons = (
        os.getenv("SEMI_AUTO_BUTTONS", "0").lower() in ("1", "true", "yes", "on") or
        os.getenv("AUTO_MODE", "0").lower() in ("1", "true", "yes", "on")
    )
    
    # ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": f"*{main_text}*"}
        },
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": detail_text}
        }
    ]
    
    # ë²„íŠ¼ ì¶”ê°€ (ë°˜ìë™ ëª¨ë“œì¼ ë•Œ)
    if show_buttons:
        button_text = "ë§¤ìˆ˜" if action == "long" else "ë§¤ë„"
        order_payload = json.dumps({
            "ticker": signal.ticker,
            "side": "buy" if action == "long" else "sell",
            "entry": signal.entry_price,
            "sl": signal.stop_loss,
            "tp": signal.take_profit,
            "qty": int(os.getenv("DEFAULT_QTY", "1"))
        })
        
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": f"âœ… {button_text}", "emoji": True},
                    "style": "primary",
                    "value": order_payload,
                    "action_id": "approve_trade"
                },
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": "âŒ íŒ¨ìŠ¤", "emoji": True},
                    "style": "danger",
                    "value": f"reject_{signal.ticker}_{signal.signal_type.value}_{signal.timestamp.timestamp()}",
                    "action_id": "reject_trade"
                }
            ]
        })
    
    # ì²« ë²ˆì§¸ ì±„ë„ ìš°ì„ , ë‘ ë²ˆì§¸ëŠ” í´ë°± (channel_not_found ì˜¤ë¥˜ í•´ê²°)
    channel = os.getenv("SLACK_CHANNEL_ID") or "C099CQP8CJ3"
    
    return {
        "channel": channel,
        "text": main_text,
        "blocks": blocks
    }

def format_enhanced_slack_message(signal, llm_insight) -> Dict:
    """LLM ë¶„ì„ì´ í¬í•¨ëœ í–¥ìƒëœ ìŠ¬ë™ ë©”ì‹œì§€ í¬ë§· (Phase 1.5)"""
    import os
    import json
    
    # ê¸°ë³¸ ì •ë³´
    signal.regime.upper().replace("_", "")
    action_ko = "ë¡±" if signal.signal_type.value == "long" else "ìˆ"
    
    # ì‹ ë¢°ë„ ì´ëª¨ì§€
    confidence_emoji = {5: "ğŸ¯", 4: "ğŸ‘", 3: "ğŸ¤”", 2: "âš ï¸", 1: "ğŸ˜…"}
    confidence_level = min(5, max(1, round(signal.confidence * 5)))
    
    # LLM í–¥ìƒëœ ë©”ì¸ ë©”ì‹œì§€
    main_text = f"""
ğŸ’­ **{signal.ticker} ìƒˆë¡œìš´ ê¸°íšŒ ë°œê²¬!**

{confidence_emoji[confidence_level]} **AI íŒë‹¨**: {action_ko} ì¶”ì²œ ({signal.score:+.2f}ì )
ğŸ¯ **AI ë¶„ì„**: {llm_insight.summary}"""

    # ìƒì„¸ ì •ë³´ (ë” ì¹œê·¼í•˜ê²Œ)
    detail_text = f"""
ğŸ’¡ **íŠ¸ë ˆì´ë”© ì œì•ˆ**:
â€¢ ì§„ì…ê°€: ${signal.entry_price:.2f}
â€¢ ì†ì ˆì„ : ${signal.stop_loss:.2f} (ë¦¬ìŠ¤í¬ ê´€ë¦¬)
â€¢ ëª©í‘œê°€: ${signal.take_profit:.2f} (ìˆ˜ìµ ê¸°ëŒ€)

ğŸ§  **AIê°€ ë³¸ ì´ìœ **: {llm_insight.trigger}
â° **ì˜ˆìƒ ì§€ì†ì‹œê°„**: {signal.horizon_minutes}ë¶„

ì–´ë–»ê²Œ í•˜ì‹œê² ì–´ìš”?"""

    # ë¸”ë¡ êµ¬ì„±
    blocks = [
        {
            "type": "section", 
            "text": {"type": "mrkdwn", "text": main_text}
        },
        {
            "type": "section",
            "text": {"type": "mrkdwn", "text": detail_text}
        }
    ]
    
    # ë²„íŠ¼ ì¶”ê°€ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
    show_buttons = (
        os.getenv("SEMI_AUTO_BUTTONS", "0").lower() in ("1", "true", "yes", "on") or
        os.getenv("AUTO_MODE", "0").lower() in ("1", "true", "yes", "on")
    )
    
    if show_buttons:
        button_text = "ë§¤ìˆ˜" if signal.signal_type.value == "long" else "ë§¤ë„"
        order_payload = json.dumps({
            "ticker": signal.ticker,
            "action": signal.signal_type.value,
            "entry_price": signal.entry_price,
            "stop_loss": signal.stop_loss,
            "take_profit": signal.take_profit,
            "signal_score": signal.score,
            "llm_analysis": {
                "sentiment": llm_insight.sentiment,
                "trigger": llm_insight.trigger,
                "summary": llm_insight.summary
            }
        })
        
        blocks.append({
            "type": "actions",
            "elements": [
                {
                    "type": "button",
                    "text": {"type": "plain_text", "text": f"âœ… {button_text}"},
                    "style": "primary",
                    "value": order_payload,
                    "action_id": "execute_trade"
                },
                {
                    "type": "button", 
                    "text": {"type": "plain_text", "text": "âŒ ê±´ë„ˆë›°ê¸°"},
                    "value": "skip",
                    "action_id": "skip_trade"
                }
            ]
        })
    
    # ì±„ë„ ì„¤ì •
    channel = os.getenv("SLACK_CHANNEL_ID", "#trading-signals")
    
    return {
        "channel": channel,
        "text": f"ğŸ¤– AI ì¶”ì²œ: {signal.ticker} {action_ko} {signal.score:+.2f}ì ",
        "blocks": blocks
    }

@celery_app.task(bind=True, name="app.jobs.scheduler.generate_signals")
def generate_signals(self):
    """ì‹œê·¸ë„ ìƒì„± ì‘ì—…"""
    try:
        start_time = time.time()
        logger.info("ì‹œê·¸ë„ ìƒì„± ì‹œì‘")
        
        # í•„ìˆ˜ ìµœì†Œ ì»´í¬ë„ŒíŠ¸ í™•ì¸: ìŠ¤ìº˜í”„ ê²½ë¡œë§Œì´ë¼ë„ ëŒë¦´ ìˆ˜ ìˆê²Œ ìµœì†Œ depsë§Œ ê°•ì œ
        # 1) quotes_ingestor í•„ìˆ˜. ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ìƒì„± ì‹œë„
        if not trading_components.get("quotes_ingestor"):
            logger.warning("í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„: ['quotes_ingestor'] â†’ ë¡œì»¬ ìƒì„± ì‹œë„")
            try:
                from app.io.quotes_delayed import DelayedQuotesIngestor
                trading_components["quotes_ingestor"] = DelayedQuotesIngestor()
                try:
                    trading_components["quotes_ingestor"].warmup_backfill()  # type: ignore
                except Exception:
                    pass
            except Exception as e:
                logger.warning(f"quotes_ingestor ìƒì„± ì‹¤íŒ¨: {e}")
        if not trading_components.get("quotes_ingestor"):
            return {"status": "skipped", "reason": "quotes_ingestor_not_ready"}
        # 2) signal_mixer ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„± (ìŠ¤ìº˜í”„ ê²½ë¡œìš©)
        if not trading_components.get("signal_mixer"):
            try:
                from app.engine.mixer import SignalMixer
                thr = settings.MIXER_THRESHOLD
                trading_components["signal_mixer"] = SignalMixer(buy_threshold=thr, sell_threshold=-thr)
                logger.warning("signal_mixer ë¡œì»¬ ìƒì„±")
            except Exception as e:
                logger.warning(f"signal_mixer ìƒì„± ì‹¤íŒ¨: {e}")
        # 3) redis_streams ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ìƒì„± (ë°œí–‰ìš©)
        if not trading_components.get("redis_streams"):
            try:
                from app.io.streams import RedisStreams
                rurl = os.getenv("REDIS_URL", "redis://redis:6379/0")
                host, port, db = _parse_redis_url(rurl)
                trading_components["redis_streams"] = RedisStreams(host=host, port=port, db=db)
            except Exception as e:
                logger.warning(f"redis_streams ìƒì„± ì‹¤íŒ¨: {e}")
        
        quotes_ingestor = trading_components["quotes_ingestor"]
        trading_components["edgar_scanner"]
        regime_detector = trading_components["regime_detector"]
        tech_score_engine = trading_components["tech_score_engine"]
        llm_engine = trading_components["llm_engine"]
        signal_mixer = trading_components["signal_mixer"]
        redis_streams = trading_components["redis_streams"]
        slack_bot = trading_components.get("slack_bot")
        
        # ğŸ” DEBUG: Slack bot ìƒíƒœ í™•ì¸
        logger.info(f"ğŸ” [DEBUG] slack_bot ì¡´ì¬ ì—¬ë¶€: {slack_bot is not None}")
        if slack_bot:
            logger.info(f"ğŸ” [DEBUG] slack_bot íƒ€ì…: {type(slack_bot)}")
            logger.info(f"ğŸ” [DEBUG] slack_bot ì±„ë„: {getattr(slack_bot, 'default_channel', 'N/A')}")
        else:
            logger.warning(f"ğŸ” [DEBUG] slack_botì´ Noneì„! trading_components í‚¤: {list(trading_components.keys())}")
        
        signals_generated = 0
        
        # ê° ì¢…ëª©ë³„ë¡œ ì‹œê·¸ë„ ìƒì„±
        # ìœ ë‹ˆë²„ìŠ¤ ë™ì  ì ìš© (Redis union: core + external + watchlist)
        dynamic_universe = None
        try:
            rurl = os.getenv("REDIS_URL")
            if rurl:
                r = redis.from_url(rurl)
                external = r.smembers("universe:external") or []
                watch = r.smembers("universe:watchlist") or []
                core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
                ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
                wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
                merged = []
                seen = set()
                max_n = int(os.getenv("UNIVERSE_MAX", "100"))
                for arr in [core, ext, wch]:
                    for s in arr:
                        if s and s not in seen:
                            merged.append(s)
                            seen.add(s)
                        if len(merged) >= max_n:
                            break
                    if len(merged) >= max_n:
                        break
                dynamic_universe = merged
                # ì¸ì œìŠ¤í„°ì— ë°˜ì˜ ë° ì›Œë°ì—…
                try:
                    if hasattr(quotes_ingestor, "update_universe_tickers"):
                        quotes_ingestor.update_universe_tickers(dynamic_universe)
                except Exception:
                    pass
        except Exception:
            dynamic_universe = None

        # Tier ê¸°ë°˜ ì¢…ëª© ì²˜ë¦¬ (Universe Expansion)
        universe_tiers = get_universe_with_tiers()
        logger.info(f"ğŸ¯ Tier ìœ ë‹ˆë²„ìŠ¤: A={len(universe_tiers['tier_a'])}, B={len(universe_tiers['tier_b'])}, ë²¤ì¹˜={len(universe_tiers['bench'])}")
        
        # Tierë³„ ìŠ¤ì¼€ì¤„ë§ ì ìš©
        current_time = datetime.now()
        processing_tickers = []
        
        # Tier A ì¢…ëª© ì²´í¬ (30ì´ˆë§ˆë‹¤)
        for ticker in universe_tiers['tier_a']:
            should_process, reason = should_process_ticker_now(ticker, current_time)
            if should_process:
                processing_tickers.append((ticker, TokenTier.TIER_A, reason))
        
        # Tier B ì¢…ëª© ì²´í¬ (60ì´ˆë§ˆë‹¤) 
        for ticker in universe_tiers['tier_b']:
            should_process, reason = should_process_ticker_now(ticker, current_time)
            if should_process:
                processing_tickers.append((ticker, TokenTier.TIER_B, reason))
        
        # ë²¤ì¹˜ ì¢…ëª©ì€ í˜„ì¬ ì´ë²¤íŠ¸ ê¸°ë°˜ë§Œ (ì¶”í›„ í™•ì¥)
        
        logger.info(f"ğŸ¯ ì²˜ë¦¬ ëŒ€ìƒ: {len(processing_tickers)}ê°œ ì¢…ëª© {[f'{t}({tier.value})' for t, tier, _ in processing_tickers]}")
        
        # Fallback: Tier ì‹œìŠ¤í…œ ë¹„í™œì„±í™”ì‹œ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if not processing_tickers:
            logger.info("ğŸ¯ Tier ì²˜ë¦¬ ëŒ€ìƒ ì—†ìŒ, ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ Fallback")
            tickers_iter = dynamic_universe or list(quotes_ingestor.tickers)
            processing_tickers = [(ticker, None, "fallback") for ticker in tickers_iter]
        
        for ticker, tier, schedule_reason in processing_tickers:
            try:
                # API í† í° ì²´í¬ ë° ì†Œë¹„ (Tier ì‹œìŠ¤í…œ)
                if tier is not None:  # Tier ì‹œìŠ¤í…œ í™œì„±í™”ëœ ê²½ìš°
                    can_consume, token_reason = can_consume_api_token_for_ticker(ticker)
                    if not can_consume:
                        logger.info(f"ğŸš« í† í° ë¶€ì¡±ìœ¼ë¡œ ìŠ¤í‚µ: {ticker} ({tier.value}) - {token_reason}")
                        continue
                    
                    # í† í° ì‹¤ì œ ì†Œë¹„
                    consumed, consume_reason = consume_api_token_for_ticker(ticker)
                    if not consumed:
                        logger.warning(f"ğŸš« í† í° ì†Œë¹„ ì‹¤íŒ¨: {ticker} ({tier.value}) - {consume_reason}")
                        continue
                    
                    logger.debug(f"âœ… í† í° ì†Œë¹„: {ticker} ({tier.value}) - {consume_reason}")
                
                # 1. ì‹œì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                candles = quotes_ingestor.get_latest_candles(ticker, 50)
                if len(candles) < 20:
                    continue
                
                # 2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                indicators = quotes_ingestor.get_technical_indicators(ticker)
                if not indicators:
                    continue
                
                # 2.5 ìŠ¤ìº˜í”„ ëª¨ë“œ: ë§ˆì§€ë§‰ í•œ í‹±ì´ í¬ê²Œ íŠ€ë©´ ì¦‰ì‹œ ì‹ í˜¸ ìƒì„± (í…ŒìŠ¤íŠ¸/ì•Œë¦¼ìš©)
                try:
                    scalp_enabled = (os.getenv("SCALP_TICK_SPIKE", "false").lower() in ("1", "true", "yes", "on"))
                    if scalp_enabled and len(candles) >= 2:
                        # 30s/15s ë¶„í•  ì‹œ ë§ˆì§€ë§‰ ë‘ ë°”ê°€ ê°™ì€ 1ë¶„ì— ì†í•¨ â†’ ë¶„ë‹¹ ê°„ê²©ìœ¼ë¡œ ë¹„êµ
                        try:
                            bars_per_min = max(1, 60 // max(getattr(quotes_ingestor, "bar_sec", 60), 1))
                        except Exception:
                            bars_per_min = 1
                        last = candles[-1]
                        prev_idx = -1 - bars_per_min if len(candles) > bars_per_min else -2
                        prev = candles[prev_idx]
                        last_abs_ret = abs((last.c - prev.c) / max(prev.c, 1e-9))
                        spike_thr = float(os.getenv("SCALP_MIN_RET", "0.003"))  # ê¸°ë³¸ 0.3%
                        # ì•¼í›„ 1ë¶„ë´‰ ë¶„í•  ì‹œ ë§ˆì§€ë§‰ ë‘ ë°”ê°€ ë™ì¼ ê°’ì¸ ê²½ìš°ê°€ ë§ì•„ ê³ ì €í­ ê¸°ì¤€ë„ í—ˆìš©
                        last_range = (last.h - last.l) / max(last.c, 1e-9)
                        range_thr = float(os.getenv("SCALP_MIN_RANGE", "0.003"))  # ê¸°ë³¸ 0.3%
                        trig_reason = None
                        if last_abs_ret >= spike_thr:
                            trig_reason = f"ret>={spike_thr:.3%}"
                        elif last_range >= range_thr:
                            trig_reason = f"range>={range_thr:.3%}"
                        if trig_reason:
                            from app.engine.regime import RegimeType, RegimeResult
                            from app.engine.techscore import TechScoreResult
                            direction = 1.0 if (last.c - prev.c) >= 0 else -1.0
                            fake_regime = RegimeResult(
                                regime=RegimeType.VOL_SPIKE,
                                confidence=min(1.0, last_abs_ret * 20.0),
                                features={"last_abs_ret": last_abs_ret},
                                timestamp=datetime.now()
                            )
                            fake_tech = TechScoreResult(
                                score=direction,  # -1 ~ +1ë¡œ ì§ì ‘ ìŠ¤ì¼€ì¼
                                components={"ema": 0.8 if direction > 0 else 0.2,
                                            "macd": 0.8 if direction > 0 else 0.2,
                                            "rsi": 0.8 if direction > 0 else 0.2,
                                            "vwap": 0.8 if direction > 0 else 0.2},
                                timestamp=datetime.now()
                            )
                            quick_signal = signal_mixer.mix_signals(
                                ticker=ticker,
                                regime_result=fake_regime,
                                tech_score=fake_tech,
                                llm_insight=None,
                                edgar_filing=None,
                                current_price=last.c
                            )
                            if quick_signal:
                                quick_signal.trigger = "tick_spike"
                                quick_signal.summary = f"{trig_reason}; abs_ret={last_abs_ret:.3%}; range={last_range:.3%}"
                                # ì»·/ì„¸ì…˜ ì–µì œ ë™ì¼ ì ìš© (ë¡œì»¬ ê³„ì‚°)
                                sess_now = _session_label()
                                cutoff_rth, cutoff_ext = get_signal_cutoffs()
                                cut_r = cutoff_rth
                                cut_e = cutoff_ext
                                cut = cut_r if sess_now == "RTH" else cut_e
                                if abs(quick_signal.score) < cut:
                                    logger.info(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ ì‹ í˜¸ ì–µì œ: {ticker} score={quick_signal.score:.3f} < cut={cut:.3f}")
                                    _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="below_cutoff")
                                else:
                                    # GPT-5 ë¦¬ìŠ¤í¬ pre-check ì¶”ê°€
                                    risk_ok, risk_reason = check_signal_risk_feasibility(quick_signal, sess_now)
                                    if not risk_ok:
                                        logger.warning(f"ğŸ›¡ï¸ [RISK] ìŠ¤ìº˜í”„ ì‹ í˜¸ ë¦¬ìŠ¤í¬ ì°¨ë‹¨: {ticker} - {risk_reason}")
                                        _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed=f"risk_check: {risk_reason}")
                                    else:
                                        logger.info(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ ì‹ í˜¸ ë°œí–‰: {ticker} {quick_signal.signal_type.value} score={quick_signal.score:.3f} | ë¦¬ìŠ¤í¬: {risk_reason}")
                                        try:
                                            redis_streams.publish_signal({
                                            "ticker": quick_signal.ticker,
                                            "signal_type": quick_signal.signal_type.value,
                                            "score": quick_signal.score,
                                            "confidence": quick_signal.confidence,
                                            "regime": quick_signal.regime,
                                            "tech_score": quick_signal.tech_score,
                                            "sentiment_score": quick_signal.sentiment_score,
                                            "edgar_bonus": quick_signal.edgar_bonus,
                                            "trigger": quick_signal.trigger,
                                            "summary": quick_signal.summary,
                                            "entry_price": quick_signal.entry_price,
                                            "stop_loss": quick_signal.stop_loss,
                                            "take_profit": quick_signal.take_profit,
                                            "horizon_minutes": quick_signal.horizon_minutes,
                                            "timestamp": quick_signal.timestamp.isoformat()
                                        })
                                            logger.info(f"ğŸ”¥ [SCALP DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                                            signals_generated += 1
                                            _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators)
                                            logger.info(f"ìŠ¤ìº˜í”„ ì‹ í˜¸: {ticker} {quick_signal.signal_type.value} ({trig_reason}, abs_ret {last_abs_ret:.2%}, range {last_range:.2%})")
                                        except Exception as e:
                                            logger.error(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ Redis ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                except Exception:
                    pass

                # 2.6 ìŠ¤ìº˜í”„ ëª¨ë“œ(ëŒ€ì•ˆ): 3ë¶„ë´‰ 3ê°œ ì—°ì† ì–‘ë´‰ì´ë©´ ë¡± ì‹ í˜¸
                try:
                    if os.getenv("SCALP_3MIN3UP", "false").lower() in ("1", "true", "yes", "on"):
                        bar_sec = int(os.getenv("BAR_SEC", "30") or 30)
                        window = max(1, int(180 / max(bar_sec, 1)))  # 3ë¶„ ì°½ì˜ ë°” ê°œìˆ˜
                        need = window * 3
                        if len(candles) >= need:
                            w1 = candles[-window:]
                            w2 = candles[-2*window:-window]
                            w3 = candles[-3*window:-2*window]
                            def _is_green(ws):
                                try:
                                    return (ws[-1].c if ws else 0.0) > (ws[0].o if ws else 0.0)
                                except Exception:
                                    return False
                            if _is_green(w1) and _is_green(w2) and _is_green(w3):
                                from app.engine.regime import RegimeType, RegimeResult
                                from app.engine.techscore import TechScoreResult
                                fake_regime = RegimeResult(
                                    regime=RegimeType.TREND,
                                    confidence=0.8,
                                    features={"3min3up": True},
                                    timestamp=datetime.now()
                                )
                                fake_tech = TechScoreResult(
                                    score=1.0,
                                    components={"ema": 0.9, "macd": 0.9, "rsi": 0.8, "vwap": 0.8},
                                    timestamp=datetime.now()
                                )
                                last_px = candles[-1].c
                                quick_signal = signal_mixer.mix_signals(
                                    ticker=ticker,
                                    regime_result=fake_regime,
                                    tech_score=fake_tech,
                                    llm_insight=None,
                                    edgar_filing=None,
                                    current_price=last_px
                                )
                                if quick_signal:
                                    quick_signal.trigger = "3min_3up"
                                    quick_signal.summary = "3min green x3"
                                    sess_now = _session_label()
                                    cutoff_rth, cutoff_ext = get_signal_cutoffs()
                                    cut_r = cutoff_rth
                                    cut_e = cutoff_ext
                                    cut = cut_r if sess_now == "RTH" else cut_e
                                    if abs(quick_signal.score) < cut:
                                        logger.info(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ì–µì œ: {ticker} score={quick_signal.score:.3f} < cut={cut:.3f}")
                                        _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="below_cutoff")
                                    else:
                                        # ë¦¬ìŠ¤í¬ ì‚¬ì „ ì²´í¬ (GPT-5 ê¶Œì¥ì‚¬í•­)
                                        risk_ok, risk_reason = check_signal_risk_feasibility(quick_signal, sess_now)
                                        if not risk_ok:
                                            logger.warning(f"ğŸ›¡ï¸ {ticker} 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ë¦¬ìŠ¤í¬ ì°¨ë‹¨: {risk_reason}")
                                            _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="risk_limit")
                                        else:
                                            logger.info(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ë°œí–‰: {ticker} long score={quick_signal.score:.3f}")
                                            try:
                                                redis_streams.publish_signal({
                                                "ticker": quick_signal.ticker,
                                                "signal_type": quick_signal.signal_type.value,
                                                "score": quick_signal.score,
                                                "confidence": quick_signal.confidence,
                                                "regime": quick_signal.regime,
                                                "tech_score": quick_signal.tech_score,
                                                "sentiment_score": quick_signal.sentiment_score,
                                                "edgar_bonus": quick_signal.edgar_bonus,
                                                "trigger": quick_signal.trigger,
                                                "summary": quick_signal.summary,
                                                "entry_price": quick_signal.entry_price,
                                                "stop_loss": quick_signal.stop_loss,
                                                "take_profit": quick_signal.take_profit,
                                                "horizon_minutes": quick_signal.horizon_minutes,
                                                "timestamp": quick_signal.timestamp.isoformat()
                                            })
                                                logger.info(f"ğŸ”¥ [3MIN DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                                                signals_generated += 1
                                                _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators)
                                                logger.info(f"ìŠ¤ìº˜í”„ ì‹ í˜¸: {ticker} long (3min_3up)")
                                            except Exception as e:
                                                logger.error(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ Redis ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                                            continue
                except Exception:
                    pass

                # 3. ë ˆì§ ê°ì§€
                regime_result = regime_detector.detect_regime(candles)
                
                # 4. ê¸°ìˆ ì  ì ìˆ˜ ê³„ì‚°
                tech_score = tech_score_engine.calculate_tech_score(candles)
                
                # 5. EDGAR ê³µì‹œ í™•ì¸
                edgar_filing = None
                llm_insight = None
                
                # ìµœê·¼ EDGAR ê³µì‹œê°€ ìˆëŠ”ì§€ í™•ì¸
                recent_edgar = get_recent_edgar_filing(ticker)
                if recent_edgar:
                    edgar_filing = recent_edgar
                    # LLM ê²Œì´íŒ… ì ìš© (EDGAR ì´ë²¤íŠ¸)
                    should_call, call_reason = should_call_llm_for_event(
                        ticker, "edgar", edgar_filing=edgar_filing
                    )
                    if should_call:
                        # ì¿¼í„° ì†Œë¹„ ë° LLM ë¶„ì„
                        if consume_llm_call_quota(ticker, "edgar", edgar_filing):
                            llm_insight = llm_engine.analyze_edgar_filing(edgar_filing)
                            logger.info(f"ğŸ¤– LLM EDGAR ë¶„ì„: {ticker} - {call_reason}")
                        else:
                            logger.warning(f"ğŸ¤– LLM ì¿¼í„° ì†Œë¹„ ì‹¤íŒ¨: {ticker} (EDGAR)")
                    else:
                        logger.info(f"ğŸš« LLM EDGAR ì°¨ë‹¨: {ticker} - {call_reason}")
                
                # 6. ë ˆì§ì´ vol_spikeì¸ ê²½ìš° ì¶”ê°€ LLM ë¶„ì„ (ì‹ í˜¸ ì ìˆ˜ ì¡°ê±´ë¶€)
                if regime_result.regime.value == 'vol_spike' and llm_engine and not llm_insight:
                    # tech_scoreë¥¼ ì´ìš©í•´ ì‹ í˜¸ ì ìˆ˜ ì²´í¬ (vol_spike ê²Œì´íŒ…)
                    should_call, call_reason = should_call_llm_for_event(
                        ticker, "vol_spike", signal_score=tech_score.score
                    )
                    if should_call:
                        # ì¿¼í„° ì†Œë¹„ ë° LLM ë¶„ì„
                        if consume_llm_call_quota(ticker, "vol_spike"):
                            text = f"Volatility spike detected for {ticker} in {regime_result.regime.value} regime"
                            llm_insight = llm_engine.analyze_text(text, f"vol_spike_{ticker}", regime='vol_spike')
                            logger.info(f"ğŸ¤– LLM vol_spike ë¶„ì„: {ticker} - {call_reason}")
                        else:
                            logger.warning(f"ğŸ¤– LLM ì¿¼í„° ì†Œë¹„ ì‹¤íŒ¨: {ticker} (vol_spike)")
                    else:
                        logger.info(f"ğŸš« LLM vol_spike ì°¨ë‹¨: {ticker} - {call_reason}")
                
                # 6. ì„¸ì…˜ë³„ pre-filter (RTH: ì¼ì¼ìƒí•œ, EXT: ìœ ë™ì„±/ìŠ¤í”„ë ˆë“œ/ì¿¨ë‹¤ìš´/ì¼ì¼ìƒí•œ)
                ext_enabled = (os.getenv("EXTENDED_PRICE_SIGNALS", "false").lower() in ("1","true","yes","on"))
                session_label = _session_label()
                cutoff_rth, cutoff_ext = get_signal_cutoffs()
                dvol5m = float(indicators.get("dollar_vol_5m", 0.0))
                spread_bp = float(indicators.get("spread_bp", 0.0))
                suppress_reason = None
                
                # RTH ì¼ì¼ ìƒí•œ (5ê±´ ëª©í‘œ) - ì›ìì  ì „ì¹˜ ì²´í¬
                if session_label == "RTH":
                    try:
                        if rurl:
                            r = redis.from_url(rurl)
                            rth_daily_cap = int(os.getenv("RTH_DAILY_CAP", "5"))
                            # ET ê¸°ì¤€ ë‚ ì§œ í‚¤ (UTC-5, DST ê°„ì´ ì ìš©)
                            et_tz = timezone(timedelta(hours=-5))
                            now_et = datetime.now(et_tz)
                            # DST ê°„ì´ ì ìš© (3ì›”-11ì›”)
                            if 3 <= now_et.month <= 11:
                                et_tz = timezone(timedelta(hours=-4))
                                now_et = datetime.now(et_tz)
                            day_key = f"dailycap:{now_et:%Y%m%d}:RTH:{ticker}"
                            # ì›ìì  ì²´í¬-ì¦ê°€: INCR í›„ ê²°ê³¼ë¡œ íŒë‹¨
                            current_count = r.incr(day_key)
                            r.expire(day_key, 86400)  # ET EOD ë§Œë£Œ (24ì‹œê°„)
                            if current_count > rth_daily_cap:
                                # ìƒí•œ ì´ˆê³¼ ì‹œ ì¹´ìš´í„° ë¡¤ë°±í•˜ê³  ì–µì œ
                                r.decr(day_key)
                                suppress_reason = "rth_daily_cap"
                                logger.info(f"RTH ì¼ì¼ìƒí•œ ì´ˆê³¼: {ticker} ({current_count-1}/{rth_daily_cap})")
                    except Exception as e:
                        logger.warning(f"RTH ì¼ì¼ìƒí•œ ì²´í¬ ì‹¤íŒ¨: {e}")
                        pass
                elif session_label in ["EXT", "CLOSED"]:  # CLOSEDë„ EXT ë¡œì§ ì ìš©
                    # EXT ì„¸ì…˜ íŒë³„ ë° ì–µì œ ì´ìœ  ë¡œê·¸ ìˆ˜ì§‘
                    logger.info(f"EXT ì„¸ì…˜ ì²´í¬: {ticker} ext_enabled={ext_enabled} dvol5m={dvol5m:.0f} spread_bp={spread_bp:.1f}")
                    
                    if not ext_enabled:
                        suppress_reason = "ext_disabled"
                        logger.info(f"suppressed=ext_disabled ticker={ticker} session=EXT")
                    elif dvol5m < float(os.getenv("EXT_MIN_DOLLAR_VOL_5M", "50000")):
                        suppress_reason = "low_dvol"
                        logger.info(f"suppressed=low_dvol ticker={ticker} session=EXT dvol5m={dvol5m:.0f} min={os.getenv('EXT_MIN_DOLLAR_VOL_5M', '50000')}")
                    elif spread_bp > float(os.getenv("EXT_MAX_SPREAD_BP", "300")):
                        suppress_reason = "wide_spread"
                        logger.info(f"suppressed=wide_spread ticker={ticker} session=EXT spread_bp={spread_bp:.1f} max={os.getenv('EXT_MAX_SPREAD_BP', '300')}")
                    # ì¿¨ë‹¤ìš´/ì¼ì¼ ìƒí•œ ì²´í¬: Redis í‚¤ ì‚¬ìš© (ì›ìì  ì²˜ë¦¬)
                    try:
                        if rurl and not suppress_reason:  # ì´ë¯¸ ì–µì œ ì‚¬ìœ ê°€ ìˆìœ¼ë©´ ìŠ¤í‚µ
                            r = redis.from_url(rurl)
                            cool_min = int(os.getenv("EXT_COOLDOWN_MIN", "7"))
                            daily_cap = int(os.getenv("EXT_DAILY_CAP", "3"))
                            now_ts = int(time.time())
                            cd_key = f"cooldown:{ticker}"
                            
                            # ì¿¨ë‹¤ìš´ ì²´í¬
                            last_ts = int(r.get(cd_key) or 0)
                            if now_ts - last_ts < cool_min * 60:
                                suppress_reason = "cooldown"
                                logger.info(f"EXT ì¿¨ë‹¤ìš´: {ticker} ({now_ts - last_ts}s < {cool_min*60}s)")
                            else:
                                # ET ê¸°ì¤€ ë‚ ì§œ í‚¤
                                et_tz = timezone(timedelta(hours=-5))
                                now_et = datetime.now(et_tz)
                                if 3 <= now_et.month <= 11:
                                    et_tz = timezone(timedelta(hours=-4))
                                    now_et = datetime.now(et_tz)
                                day_key = f"dailycap:{now_et:%Y%m%d}:EXT:{ticker}"
                                
                                # ì›ìì  ì²´í¬-ì¦ê°€
                                current_count = r.incr(day_key)
                                r.expire(day_key, 86400)
                                if current_count > daily_cap:
                                    r.decr(day_key)  # ë¡¤ë°±
                                    suppress_reason = "ext_daily_cap"
                                    logger.info(f"EXT ì¼ì¼ìƒí•œ ì´ˆê³¼: {ticker} ({current_count-1}/{daily_cap})")
                                else:
                                    # í†µê³¼ ì‹œ ì¿¨ë‹¤ìš´ ë§ˆí‚¹
                                    r.setex(cd_key, cool_min*60, now_ts)
                    except Exception as e:
                        logger.warning(f"EXT ì¿¨ë‹¤ìš´/ìƒí•œ ì²´í¬ ì‹¤íŒ¨: {e}")
                        pass

                # VaR95 ê²½ëŸ‰ ê°€ë“œ: ìµœê·¼ ë¦¬í„´ ìƒ˜í”Œ ê¸°ë°˜(ì˜µì…˜)
                try:
                    from app.engine.risk import rolling_var95
                    # ìƒ˜í”Œì€ ë³„ë„ ê³³ì—ì„œ ì±„ì›Œì§„ë‹¤ê³  ê°€ì •; ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    rurl = os.getenv("REDIS_URL")
                    if rurl:
                        r = redis.from_url(rurl)
                        key = f"risk:rets:{ticker}:{regime_result.regime.value}"
                        samples = [float(x) for x in (r.lrange(key, 0, 9999) or [])]
                        if samples:
                            rolling_var95(samples)
                            # ê°„ì´ ê¸°ì¤€: ì˜ˆìƒ ì†ì‹¤R>VaRì´ë©´ ì–µì œ
                            # ì—¬ê¸°ì„œëŠ” ì‹ í˜¸ ìƒì„± í›„ ì»·ì˜¤í”„ ë‹¨ê³„ì—ì„œ suppress
                            pass
                except Exception:
                    pass

                # 7. ì‹œê·¸ë„ ë¯¹ì‹±
                current_price = candles[-1].c if candles else 0
                signal = signal_mixer.mix_signals(
                    ticker=ticker,
                    regime_result=regime_result,
                    tech_score=tech_score,
                    llm_insight=llm_insight,
                    edgar_filing=edgar_filing,
                    current_price=current_price
                )
                
                if signal:
                    # ì»·ì˜¤í”„ ì ìš© (ì„¸ì…˜ë³„)
                    cut = cutoff_rth if session_label == "RTH" else cutoff_ext
                    if abs(signal.score) < cut or suppress_reason:
                        # ì–µì œ ì‚¬ìœ  í†µì¼ í˜•ì‹ ë¡œê·¸
                        actual_reason = suppress_reason or "below_cutoff"
                        logger.info(f"suppressed={actual_reason} ticker={ticker} session={session_label} "
                                   f"score={signal.score:.3f} cut={cut:.3f} dvol5m={dvol5m:.0f} spread_bp={spread_bp:.1f}")
                        
                        # ì–µì œ ë©”íŠ¸ë¦­ ëˆ„ì 
                        try:
                            if rurl:
                                r = redis.from_url(rurl)
                                hkey = f"metrics:suppressed:{datetime.utcnow():%Y%m%d}"
                                r.hincrby(hkey, actual_reason, 1)
                        except Exception:
                            pass
                        # ìµœê·¼ ì‹ í˜¸ ë¦¬ìŠ¤íŠ¸ì— suppressedë¡œ ê¸°ë¡
                        _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed=suppress_reason or "below_cutoff")
                        continue

                    # 7. Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
                    signal_data = {
                        "ticker": signal.ticker,
                        "signal_type": signal.signal_type.value,
                        "score": signal.score,
                        "confidence": signal.confidence,
                        "regime": signal.regime,
                        "tech_score": signal.tech_score,
                        "sentiment_score": signal.sentiment_score,
                        "edgar_bonus": signal.edgar_bonus,
                        "trigger": signal.trigger,
                        "summary": signal.summary,
                        "entry_price": signal.entry_price,
                        "stop_loss": signal.stop_loss,
                        "take_profit": signal.take_profit,
                        "horizon_minutes": signal.horizon_minutes,
                        "timestamp": signal.timestamp.isoformat()
                    }
                    
                    logger.info(f"ğŸ”¥ [DEBUG] ì‹œê·¸ë„ ìƒì„±ë¨! ticker={ticker}, type={signal.signal_type.value}, score={signal.score:.3f}, cut={cut:.3f}")
                    
                    # GPT-5 ë¦¬ìŠ¤í¬ pre-check ì¶”ê°€
                    risk_ok, risk_reason = check_signal_risk_feasibility(signal, session_label)
                    if not risk_ok:
                        logger.warning(f"ğŸ›¡ï¸ [RISK] ì‹ í˜¸ ë¦¬ìŠ¤í¬ ì°¨ë‹¨: {ticker} - {risk_reason}")
                        _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed=f"risk_check: {risk_reason}")
                        continue  # ì´ ì‹ í˜¸ëŠ” ê±´ë„ˆë›°ê³  ë‹¤ìŒìœ¼ë¡œ
                    
                    logger.info(f"ğŸ”¥ [DEBUG] ë¦¬ìŠ¤í¬ ì²´í¬ í†µê³¼ - Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹œë„: {ticker} | {risk_reason}")
                    
                    try:
                        redis_streams.publish_signal(signal_data)
                        logger.info(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                        
                        # Slack ì „ì†¡: ê°•ì‹ í˜¸ë§Œ (ì›ë˜ ê¸°íš - ì†Œìˆ˜Â·êµµì§í•œ ì•Œë¦¼)
                        if slack_bot:
                            # ê°•ì‹ í˜¸ ê¸°ì¤€: abs(score) >= cut + 0.20 (ë” ê¹Œë‹¤ë¡­ê²Œ)
                            strong_signal_threshold = cut + 0.20
                            is_strong_signal = abs(signal.score) >= strong_signal_threshold
                            
                            if is_strong_signal:
                                logger.info(f"ğŸ“¢ ê°•ì‹ í˜¸ ê°ì§€: {ticker} score={signal.score:.3f} >= {strong_signal_threshold:.3f}")
                                
                                # Phase 1.5: ê°•ì‹ í˜¸ ì‹œ LLM ë¶„ì„ ì¶”ê°€!
                                enhanced_llm_insight = None
                                if llm_engine:
                                    try:
                                        # ê°•ì‹ í˜¸ë¥¼ ìœ„í•œ LLM ë¶„ì„ í”„ë¡¬í”„íŠ¸
                                        strong_signal_text = f"""
ê°•ì‹ í˜¸ ê°ì§€: {ticker}
ì ìˆ˜: {signal.score:.3f} ({signal.signal_type.value})
ë ˆì§: {signal.regime}
ê¸°ìˆ ì ìˆ˜: {signal.tech_score:.3f}
íŠ¸ë¦¬ê±°: {signal.trigger}

ì´ ê°•ì‹ í˜¸ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ê³¼ ì¹œê·¼í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”.
                                        """
                                        
                                        enhanced_llm_insight = llm_engine.analyze_text(
                                            text=strong_signal_text,
                                            source=f"strong_signal_{ticker}",
                                            edgar_event=False,
                                            regime=signal.regime,
                                            signal_strength=abs(signal.score)  # ê°•ì‹ í˜¸ strength ì „ë‹¬!
                                        )
                                        
                                        if enhanced_llm_insight:
                                            logger.info(f"ğŸ¤– ê°•ì‹ í˜¸ LLM ë¶„ì„ ì™„ë£Œ: {ticker}")
                                            logger.info(f"  - ê°ì„±: {enhanced_llm_insight.sentiment:.2f}")
                                            logger.info(f"  - íŠ¸ë¦¬ê±°: {enhanced_llm_insight.trigger}")
                                            logger.info(f"  - ìš”ì•½: {enhanced_llm_insight.summary}")
                                        
                                    except Exception as llm_e:
                                        logger.warning(f"ê°•ì‹ í˜¸ LLM ë¶„ì„ ì‹¤íŒ¨: {ticker} - {llm_e}")
                                
                                try:
                                    # ê¸°ì¡´ ë©”ì‹œì§€ë‚˜ LLM í–¥ìƒëœ ë©”ì‹œì§€ ì‚¬ìš©
                                    if enhanced_llm_insight:
                                        # LLM ë¶„ì„ì´ ìˆìœ¼ë©´ ë” ì¹œê·¼í•œ ë©”ì‹œì§€ë¡œ í¬ë§·
                                        # Phase 1.5: ì‹ í˜¸ ê²€ì¦ ì‹œìŠ¤í…œ ì ìš©!
                                        validated_signal = signal
                                        try:
                                            from app.jobs.signal_validation import SignalValidationEngine
                                            validation_engine = SignalValidationEngine()
                                            validation_result = validation_engine.validate_signal(signal)
                                            
                                            if validation_result:
                                                validated_signal = validation_engine.apply_validation_result(signal, validation_result)
                                                logger.info(f"ğŸ” ì‹ í˜¸ ê²€ì¦ ì™„ë£Œ: {ticker} - {'âœ…í†µê³¼' if validation_result.should_proceed else 'ğŸ›‘ê±°ë¶€'}")
                                                
                                                # ê²€ì¦ ê±°ë¶€ëœ ì‹ í˜¸ëŠ” ì „ì†¡í•˜ì§€ ì•ŠìŒ
                                                if not validation_result.should_proceed:
                                                    logger.info(f"suppressed=validation_rejected ticker={ticker} reason={validation_result.validation_reason}")
                                                    continue
                                        except Exception as val_e:
                                            logger.warning(f"ì‹ í˜¸ ê²€ì¦ ì‹¤íŒ¨: {ticker} - {val_e}")
                                        
                                        slack_message = format_enhanced_slack_message(validated_signal, enhanced_llm_insight)
                                    else:
                                        # ê¸°ì¡´ ë©”ì‹œì§€ ì‚¬ìš©
                                        slack_message = format_slack_message(signal)
                                    result = slack_bot.send_message(slack_message)
                                    if result:
                                        logger.info(f"âœ… Slack ì „ì†¡ ì„±ê³µ: {ticker} (ì¹´ìš´í„°ëŠ” ì´ë¯¸ ì „ì¹˜ ì²´í¬ì—ì„œ ì¦ê°€ë¨)")
                                        
                                        # Phase 1.5: í˜ì´í¼ íŠ¸ë ˆì´ë”© ìë™ ì‹¤í–‰!
                                        try:
                                            from app.jobs.paper_trading_manager import get_paper_trading_manager
                                            paper_manager = get_paper_trading_manager()
                                            
                                            execution_result = paper_manager.execute_signal(validated_signal)
                                            if execution_result:
                                                logger.info(f"ğŸ“Š í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹¤í–‰: {ticker}")
                                            else:
                                                logger.info(f"ğŸ“Š í˜ì´í¼ íŠ¸ë ˆì´ë”© ìŠ¤í‚µ: {ticker}")
                                        except Exception as paper_e:
                                            logger.warning(f"í˜ì´í¼ íŠ¸ë ˆì´ë”© ì‹¤í–‰ ì‹¤íŒ¨: {ticker} - {paper_e}")
                                    else:
                                        # Slack ì „ì†¡ ì‹¤íŒ¨ ì‹œ ì¹´ìš´í„° ë¡¤ë°± (ì „ì¹˜ ì²´í¬ì—ì„œ ì´ë¯¸ ì¦ê°€í–ˆìœ¼ë¯€ë¡œ)
                                        try:
                                            if rurl:
                                                r = redis.from_url(rurl)
                                                if session_label == "RTH":
                                                    et_tz = timezone(timedelta(hours=-5))
                                                    now_et = datetime.now(et_tz)
                                                    if 3 <= now_et.month <= 11:
                                                        et_tz = timezone(timedelta(hours=-4))
                                                        now_et = datetime.now(et_tz)
                                                    day_key = f"dailycap:{now_et:%Y%m%d}:RTH:{ticker}"
                                                    r.decr(day_key)
                                                elif session_label == "EXT":
                                                    et_tz = timezone(timedelta(hours=-5))
                                                    now_et = datetime.now(et_tz)
                                                    if 3 <= now_et.month <= 11:
                                                        et_tz = timezone(timedelta(hours=-4))
                                                        now_et = datetime.now(et_tz)
                                                    day_key = f"dailycap:{now_et:%Y%m%d}:EXT:{ticker}"
                                                    r.decr(day_key)
                                                logger.info(f"Slack ì „ì†¡ ì‹¤íŒ¨ë¡œ ì¹´ìš´í„° ë¡¤ë°±: {ticker}")
                                        except Exception as e:
                                            logger.warning(f"ì¹´ìš´í„° ë¡¤ë°± ì‹¤íŒ¨: {e}")
                                        logger.error(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {ticker}")
                                except Exception as e:
                                    # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ì¹´ìš´í„° ë¡¤ë°±
                                    try:
                                        if rurl:
                                            r = redis.from_url(rurl)
                                            if session_label == "RTH":
                                                et_tz = timezone(timedelta(hours=-5))
                                                now_et = datetime.now(et_tz)
                                                if 3 <= now_et.month <= 11:
                                                    et_tz = timezone(timedelta(hours=-4))
                                                    now_et = datetime.now(et_tz)
                                                day_key = f"dailycap:{now_et:%Y%m%d}:RTH:{ticker}"
                                                r.decr(day_key)
                                            elif session_label == "EXT":
                                                et_tz = timezone(timedelta(hours=-5))
                                                now_et = datetime.now(et_tz)
                                                if 3 <= now_et.month <= 11:
                                                    et_tz = timezone(timedelta(hours=-4))
                                                    now_et = datetime.now(et_tz)
                                                day_key = f"dailycap:{now_et:%Y%m%d}:EXT:{ticker}"
                                                r.decr(day_key)
                                            logger.info(f"Slack ì „ì†¡ ì˜ˆì™¸ë¡œ ì¹´ìš´í„° ë¡¤ë°±: {ticker}")
                                    except Exception as rollback_e:
                                        logger.warning(f"ì¹´ìš´í„° ë¡¤ë°± ì‹¤íŒ¨: {rollback_e}")
                                    logger.error(f"âŒ Slack ì „ì†¡ ì˜ˆì™¸: {ticker} - {e}")
                            else:
                                logger.info(f"ğŸ”‡ Slack ì „ì†¡ ì–µì œ (ì•½ì‹ í˜¸): {ticker} score={signal.score:.3f} < {strong_signal_threshold:.3f}")
                        else:
                            logger.warning(f"ğŸ” Slack ì „ì†¡ ê±´ë„ˆëœ€ - slack_botì´ None: {ticker}")
                        
                        signals_generated += 1
                    except Exception as e:
                        logger.error(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                        continue
                    # ìµœê·¼ ì‹ í˜¸ ê¸°ë¡ (+ ì„¸ì…˜/ìŠ¤í”„ë ˆë“œ/ë‹¬ëŸ¬ëŒ€ê¸ˆ)
                    _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators)
                    
                    tier_info = f" [Tier:{tier.value}]" if tier else ""
                    logger.info(f"ì‹œê·¸ë„ ìƒì„±: {ticker} {signal.signal_type.value} (ì ìˆ˜: {signal.score:.2f}){tier_info}")
                
            except Exception as e:
                logger.error(f"ì‹œê·¸ë„ ìƒì„± ì‹¤íŒ¨ ({ticker}): {e}")
                continue
        
        execution_time = time.time() - start_time
        
        # í† í° ì‚¬ìš©ëŸ‰ ë¡œê·¸ (Tier ì‹œìŠ¤í…œ)
        try:
            rate_limiter = get_rate_limiter()
            token_status = rate_limiter.get_token_status()
            api_usage = rate_limiter.get_total_api_usage()
            logger.info(f"ğŸ“Š í† í° ìƒíƒœ: A={token_status['tier_a']['current_tokens']}/{token_status['tier_a']['max_tokens']}, "
                       f"B={token_status['tier_b']['current_tokens']}/{token_status['tier_b']['max_tokens']}, "
                       f"ì˜ˆì•½={token_status['reserve']['current_tokens']}/{token_status['reserve']['max_tokens']} "
                       f"(ì‚¬ìš©ë¥ : {api_usage['usage_pct']:.1f}%)")
        except Exception as e:
            logger.warning(f"í† í° ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # LLM ì‚¬ìš©ëŸ‰ ë¡œê·¸ (ê²Œì´íŒ… ì‹œìŠ¤í…œ)
        try:
            llm_stats = get_llm_usage_stats()
            logger.info(f"ğŸ¤– LLM ì‚¬ìš©ëŸ‰: {llm_stats['daily_used']}/{llm_stats['daily_limit']} "
                       f"(ë‚¨ì€ í˜¸ì¶œ: {llm_stats['remaining']}, ì‚¬ìš©ë¥ : {llm_stats['usage_pct']:.1f}%)")
        except Exception as e:
            logger.warning(f"LLM ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì‹œê·¸ë„ ìƒì„± ì™„ë£Œ: {signals_generated}ê°œ, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "signals_generated": signals_generated,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œê·¸ë„ ìƒì„± ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.update_quotes")
def update_quotes(self):
    """ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        quotes_ingestor = trading_components["quotes_ingestor"]
        redis_streams = trading_components["redis_streams"]
        
        if not quotes_ingestor or not redis_streams:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ëª¨ë“  ì¢…ëª© ì‹œì„¸ ì—…ë°ì´íŠ¸
        quotes_ingestor.update_all_tickers()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        market_data = quotes_ingestor.get_market_data_summary()
        # ì˜µì…˜: ì•¼í›„ ì¸ì œìŠ¤í„° ìš”ì•½ ë¡œê·¸ (ì‹¤ì‹œê°„ í‹± ì¶”ì ìš©)
        try:
            if os.getenv("QUOTE_LOG_VERBOSE", "false").lower() in ("1", "true", "yes", "on"):
                for _t, _d in (market_data or {}).items():
                    _ind = _d.get("indicators", {})
                    _px = float(_d.get("current_price", 0.0) or 0.0)
                    _dv = float(_ind.get("dollar_vol_5m", 0.0) or 0.0)
                    _sp = float(_ind.get("spread_bp", 0.0) or 0.0)
                    _ts = _d.get("last_update")
                    logger.info(f"[YQ] { _t } px={_px:.4f} dollar_vol_5m={_dv:.0f} spread_bp={_sp:.1f} ts={_ts}")
        except Exception:
            pass
        for ticker, data in market_data.items():
            if data.get("current_price"):
                quote_data = {
                    "ticker": ticker,
                    "price": data["current_price"],
                    "indicators": data.get("indicators", {}),
                    "timestamp": data.get("last_update", datetime.now()).isoformat()
                }
                redis_streams.publish_quote(ticker, "XNAS", quote_data)
        
        execution_time = time.time() - start_time
        logger.debug(f"ì‹œì„¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(market_data)}ê°œ ì¢…ëª©, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "tickers_updated": len(market_data),
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.scan_edgar")
def scan_edgar(self):
    """EDGAR ìŠ¤ìº” ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("EDGAR ìŠ¤ìº” ì‹œì‘")
        
        # EDGAR ìŠ¤ìºë„ˆ ì¤€ë¹„
        try:
            from app.io.edgar import EDGARScanner
        except Exception:
            EDGARScanner = None  # type: ignore
        edgar_scanner = trading_components.get("edgar_scanner")
        if edgar_scanner is None and EDGARScanner is not None:
            edgar_scanner = EDGARScanner()
            trading_components["edgar_scanner"] = edgar_scanner
        redis_streams = trading_components.get("redis_streams")
        redis_client = None
        try:
            # dedupeë¥¼ ìœ„í•œ raw redis í´ë¼ì´ì–¸íŠ¸ ì ‘ê·¼ (streams ë‚´ë¶€ í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©)
            if redis_streams:
                redis_client = redis_streams.redis_client
        except Exception:
            redis_client = None
        
        if not redis_streams:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # EDGAR ê³µì‹œ ìŠ¤ìº”
        filings = edgar_scanner.run_scan()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰ (ì¤‘ë³µ ë°©ì§€)
        dedupe_key = "edgar:dedupe:snippets"
        published = 0
        for filing in filings:
            snippet_text = filing.get("summary") or filing.get("snippet_text") or ""
            url = filing.get("url", "")
            base = (snippet_text or url).encode()
            snippet_hash = hashlib.md5(base).hexdigest()
            if redis_client:
                # ì¤‘ë³µì´ë©´ ìŠ¤í‚µ
                added = redis_client.sadd(dedupe_key, snippet_hash)
                if not added:
                    continue
            # í•´ì‹œë¥¼ í•¨ê»˜ ì €ì¥í•´ë‘ê¸°
            filing["snippet_hash"] = snippet_hash
            # StreamsëŠ” ë¬¸ìì—´ ê°’ì´ ì•ˆì „í•˜ë¯€ë¡œ dict/listëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            payload = {k: json.dumps(v) if isinstance(v, (dict, list)) else (v if v is not None else "") for k, v in filing.items()}
            redis_streams.publish_edgar(payload)
            published += 1
            
            # ì¤‘ìš” ê³µì‹œ LLM ì²˜ë¦¬
            llm_engine = trading_components.get("llm_engine")
            if filing.get("impact_score", 0) > 0.7 and llm_engine:
                llm_insight = llm_engine.analyze_edgar_filing(filing)
                if llm_insight:
                    insight_data = {
                        "ticker": filing["ticker"],
                        "sentiment": llm_insight.sentiment,
                        "trigger": llm_insight.trigger,
                        "horizon_minutes": llm_insight.horizon_minutes,
                        "summary": llm_insight.summary,
                        "timestamp": llm_insight.timestamp.isoformat()
                    }
                    redis_streams.publish_news(insight_data)
        
        execution_time = time.time() - start_time
        logger.debug(f"EDGAR ìŠ¤ìº” ì™„ë£Œ: {published}ê°œ ë°œí–‰, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "published": published,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"EDGAR ìŠ¤ìº” ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.check_risk")
def check_risk(self):
    """ë¦¬ìŠ¤í¬ ì²´í¬ ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("ë¦¬ìŠ¤í¬ ì²´í¬ ì‹œì‘")
        
        risk_engine = trading_components["risk_engine"]
        slack_bot = trading_components["slack_bot"]
        redis_streams = trading_components["redis_streams"]
        
        if not risk_engine:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
        risk_metrics = risk_engine.calculate_risk_metrics()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        if redis_streams:
            risk_data = {
                "daily_pnl": risk_metrics.daily_pnl,
                "daily_pnl_pct": risk_metrics.daily_pnl_pct,
                "var_95": risk_metrics.var_95,
                "max_drawdown": risk_metrics.max_drawdown,
                "position_count": risk_metrics.position_count,
                "total_exposure": risk_metrics.total_exposure,
                "status": risk_metrics.status.value,
                "timestamp": risk_metrics.timestamp.isoformat()
            }
            redis_streams.publish_risk_update(risk_data)
        
        # ê²½ê³ /ìœ„í—˜ ìƒíƒœì¼ ë•Œ Slack ì•Œë¦¼
        if risk_metrics.status.value in ["warning", "critical", "shutdown"] and slack_bot:
            risk_report = risk_engine.get_risk_report()
            slack_bot.send_risk_alert(risk_report)
        
        execution_time = time.time() - start_time
        logger.debug(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì™„ë£Œ: {risk_metrics.status.value}, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "risk_status": risk_metrics.status.value,
            "daily_pnl_pct": risk_metrics.daily_pnl_pct,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.daily_reset")
def daily_reset(self):
    """ì¼ì¼ ë¦¬ì…‹ ì‘ì—…"""
    try:
        logger.info("ì¼ì¼ ë¦¬ì…‹ ì‹œì‘")
        
        risk_engine = trading_components["risk_engine"]
        paper_ledger = trading_components["paper_ledger"]
        slack_bot = trading_components["slack_bot"]
        
        # ë¦¬ìŠ¤í¬ ì—”ì§„ ë¦¬ì…‹
        if risk_engine:
            risk_engine.reset_daily()
        
        # í˜ì´í¼ ë ˆì € ë¦¬ì…‹
        if paper_ledger:
            paper_ledger.reset_daily()
        
        # Slack ì•Œë¦¼
        if slack_bot:
            message = {
                "text": "ğŸ”„ ì¼ì¼ ë¦¬ì…‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "channel": "#trading-signals"
            }
            slack_bot.send_message(message)
        
        logger.info("ì¼ì¼ ë¦¬ì…‹ ì™„ë£Œ")
        
        return {
            "status": "success",
            "message": "ì¼ì¼ ë¦¬ì…‹ ì™„ë£Œ",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬ì…‹ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(name="app.jobs.scheduler.daily_report")
def daily_report(force=False, post=True):
    """ì¼ì¼ ë¦¬í¬íŠ¸ ì‘ì—…"""
    try:
        logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        paper_ledger = trading_components["paper_ledger"]
        risk_engine = trading_components["risk_engine"]
        llm_engine = trading_components["llm_engine"]
        slack_bot = trading_components["slack_bot"]
        
        if not paper_ledger:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ì¼ì¼ í†µê³„ ìˆ˜ì§‘
        daily_stats = paper_ledger.get_daily_stats()
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œ
        risk_metrics = None
        if risk_engine:
            risk_metrics = risk_engine.get_risk_report()
        
        # LLM ì‚¬ìš©ëŸ‰
        llm_usage = None
        if llm_engine:
            llm_usage = llm_engine.get_status()
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° êµ¬ì„±
        report_data = {
            "trades": daily_stats.get("trades", 0),
            "realized_pnl": daily_stats.get("realized_pnl", 0),
            "win_rate": 0.6,  # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
            "avg_rr": 1.4,    # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
            "risk_metrics": risk_metrics,
            "llm_usage": llm_usage
        }
        
        # Slack ë¦¬í¬íŠ¸ ì „ì†¡
        if slack_bot and post:
            slack_bot.send_daily_report(report_data)
        
        logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        
        return {
            "status": "success",
            "trades": report_data["trades"],
            "realized_pnl": report_data["realized_pnl"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬í¬íŠ¸ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def get_recent_edgar_filing(ticker: str) -> Optional[Dict]:
    """ìµœê·¼ EDGAR ê³µì‹œ ì¡°íšŒ (ìºì‹œëœ ë°ì´í„°ì—ì„œ)"""
    # ì‹¤ì œë¡œëŠ” ìºì‹œë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ None ë°˜í™˜
    return None

def _session_label() -> str:
    """RTH/EXT ê°„ë‹¨ íŒë³„: ET ì‹œê°„ìœ¼ë¡œ 09:30-16:00ì€ RTH, ê·¸ ì™¸ 04:00-20:00ì€ EXT, ë‚˜ë¨¸ì§€ëŠ” CLOSED"""
    from datetime import datetime, timedelta, time as dtime, timezone
    et_tz = timezone(timedelta(hours=-5))
    now_est = datetime.now(et_tz)
    # DST ê°„ì´ ì ìš©
    dst_start = now_est.replace(month=3, day=8 + (6 - now_est.replace(month=3, day=1).weekday()) % 7, hour=2)
    dst_end = now_est.replace(month=11, day=1 + (6 - now_est.replace(month=11, day=1).weekday()) % 7, hour=2)
    if dst_start <= now_est < dst_end:
        et_tz = timezone(timedelta(hours=-4))
        
    now = datetime.now(et_tz).time()
    session = None
    if dtime(9,30) <= now <= dtime(16,0):
        session = "RTH"
    elif dtime(4,0) <= now <= dtime(20,0):
        session = "EXT"
    else:
        session = "CLOSED"
    
    # ì„¸ì…˜ íŒë³„ ë¡œê·¸ (ë””ë²„ê·¸ ëª©ì )
    logger.debug(f"session={session} et_time={now} dst_active={dst_start <= now_est < dst_end}")
    return session

def _record_recent_signal(redis_url: Optional[str], signal, session_label: str, indicators: Dict, suppressed: Optional[str] = None) -> None:
    try:
        if not redis_url:
            return
        r = redis.from_url(redis_url)
        key = "signals:recent"
        payload = {
            "ticker": signal.ticker,
            "signal_type": signal.signal_type.value,
            "score": signal.score,
            "confidence": signal.confidence,
            "regime": signal.regime,
            "timestamp": signal.timestamp.isoformat(),
            "session": session_label,
            "spread_bp": float(indicators.get("spread_bp", 0.0)),
            "dollar_vol_5m": float(indicators.get("dollar_vol_5m", 0.0)),
        }
        if suppressed:
            payload["suppressed_reason"] = suppressed
        r.lpush(key, json.dumps(payload))
        r.ltrim(key, 0, 500)
    except Exception:
        pass

def initialize_components(components: Dict):
    """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    global trading_components
    trading_components.update(components)
    logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

    # Quotes ingestor ê¸°ë³¸ ì£¼ì…(ë”œë ˆì´ë“œ)
    try:
        from app.io.quotes_delayed import DelayedQuotesIngestor
        if trading_components.get("quotes_ingestor") is None:
            trading_components["quotes_ingestor"] = DelayedQuotesIngestor()
            logger.info("ë”œë ˆì´ë“œ Quotes ì¸ì œìŠ¤í„° ì´ˆê¸°í™”")
    except Exception as e:
        logger.warning(f"Quotes ì¸ì œìŠ¤í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


@celery_app.task(bind=True, name="app.jobs.scheduler.ingest_edgar_stream")
def ingest_edgar_stream(self):
    """Redis Streams(news.edgar) â†’ DB(edgar_events) ì ì¬. DB UNIQUE(snippet_hash)ë¡œ ìµœì¢… dedupe.
    ì›Œì»¤ ë¶€íŒ… í›„ readiness í†µê³¼ ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ëœë‹¤.
    """
    try:
        from app.io.streams import RedisStreams, StreamConsumer
        rs = trading_components.get("redis_streams")
        if rs is None:
            # envì—ì„œ ì—°ê²°
            import urllib.parse as _u
            redis_url = os.getenv("REDIS_URL", "redis://redis:6379/0")
            parsed = _u.urlparse(redis_url)
            host = parsed.hostname or "redis"
            port = int(parsed.port or 6379)
            db = int(parsed.path.lstrip("/") or 0)
            rs = RedisStreams(host=host, port=port, db=db)
            trading_components["redis_streams"] = rs
        consumer = trading_components.get("stream_consumer") or StreamConsumer(rs)
        trading_components["stream_consumer"] = consumer

        # DB ì—°ê²° í™•ë³´/ì¬ì‚¬ìš©
        conn = trading_components.get("db_connection")
        if conn is None or conn.closed:
            dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
            if not dsn:
                return {"status": "skipped", "reason": "missing_db_dsn", "timestamp": datetime.now().isoformat()}
            conn = psycopg2.connect(dsn)
            conn.autocommit = True
            trading_components["db_connection"] = conn

        messages = consumer.consume_edgar_events(count=20, block_ms=100)
        inserted = 0
        with conn.cursor() as cur:
            for msg in messages:
                d = msg.data
                # ë¬¸ìì—´ë¡œ ì˜¨ JSONì„ ì›ìƒë³µêµ¬ ì‹œë„
                def _norm(key):
                    val = d.get(key)
                    if val is None:
                        return None
                    try:
                        return json.loads(val)
                    except Exception:
                        return val

                ticker = _norm("ticker") or d.get("ticker")
                form = _norm("form") or d.get("form")
                item = _norm("item") or d.get("item")
                url = _norm("url") or d.get("url")
                snippet_text = _norm("snippet_text") or d.get("snippet_text")
                snippet_hash = _norm("snippet_hash") or d.get("snippet_hash")
                
                # formì´ Noneì´ë©´ snippet_textì—ì„œ ì¶”ì¶œ ì‹œë„
                if form is None and snippet_text:
                    import re
                    match = re.search(r'\b(4|8-K|10-K|10-Q|S-1|S-3|DEF 14A)\b', str(snippet_text))
                    if match:
                        form = match.group(1)

                cur.execute(
                    """
                    INSERT INTO edgar_events (ticker, form, item, url, snippet_hash, snippet_text)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    ON CONFLICT (snippet_hash) DO NOTHING
                    """,
                    (str(ticker) if ticker is not None else None,
                     str(form) if form is not None else None,
                     str(item) if item is not None else None,
                     str(url) if url is not None else None,
                     str(snippet_hash) if snippet_hash is not None else None,
                     str(snippet_text) if snippet_text is not None else None)
                )
                consumer.acknowledge("news.edgar", msg.message_id)
                inserted += 1

        return {"status": "success", "inserted": inserted, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"EDGAR ìŠ¤íŠ¸ë¦¼ ì ì¬ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e), "timestamp": datetime.now().isoformat()}

def get_task_status(task_id: str) -> Dict:
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    try:
        result = celery_app.AsyncResult(task_id)
        return {
            "task_id": task_id,
            "status": result.status,
            "result": result.result if result.ready() else None,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "task_id": task_id,
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(name="app.jobs.scheduler.refresh_universe")
def refresh_universe():
    """15ë¶„ë§ˆë‹¤ ìœ ë‹ˆë²„ìŠ¤ ë³‘í•©â†’ì¸ì œìŠ¤í„° ë°˜ì˜"""
    try:
        quotes_ingestor = trading_components.get("quotes_ingestor")
        rurl = os.getenv("REDIS_URL")
        if not quotes_ingestor or not rurl:
            return {"status": "skipped"}
        r = redis.from_url(rurl)
        external = r.smembers("universe:external") or []
        watch = r.smembers("universe:watchlist") or []
        core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
        ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
        wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
        merged = []
        seen = set()
        max_n = int(os.getenv("UNIVERSE_MAX", "60"))
        for arr in [core, ext, wch]:
            for s in arr:
                if s and s not in seen:
                    merged.append(s)
                    seen.add(s)
                if len(merged) >= max_n:
                    break
            if len(merged) >= max_n:
                break
        if hasattr(quotes_ingestor, "update_universe_tickers"):
            quotes_ingestor.update_universe_tickers(merged)
        return {"status": "ok", "universe_size": len(merged)}
    except Exception as e:
        logger.error(f"ìœ ë‹ˆë²„ìŠ¤ ê°±ì‹  ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}

@celery_app.task(name="app.jobs.scheduler.adaptive_cutoff")
def adaptive_cutoff():
    """ì „ì¼ ì²´ê²° ê±´ìˆ˜ ê¸°ë°˜ ì»·ì˜¤í”„ ì¡°ì •: cfg:signal_cutoff:{rth|ext} Â±0.02 with bounds"""
    try:
        if os.getenv("ADAPTIVE_CUTOFF_ENABLED", "true").lower() not in ("1","true","yes","on"):
            return {"status": "skipped", "reason": "disabled"}
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return {"status": "skipped", "reason": "no_redis"}
        r = redis.from_url(rurl)
        # ì²´ê²° ê±´ìˆ˜: ê°„ì´ ì§‘ê³„(orders_paper í…Œì´ë¸” ì—†ìœ¼ë©´ 0 ì²˜ë¦¬)
        fills = 0
        try:
            dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
            if dsn:
                import psycopg2
                from datetime import timedelta
                conn = psycopg2.connect(dsn)
                cur = conn.cursor()
                prev = (datetime.utcnow() - timedelta(days=1)).date()
                cur.execute("SELECT COUNT(*) FROM orders_paper WHERE DATE(ts)=%s", (prev,))
                fills = int(cur.fetchone()[0] or 0)
                cur.close()
                conn.close()
        except Exception:
            fills = 0
        # í˜„ì¬ê°’ ì½ê¸°
        def _getf(k, d):
            v = r.get(k)
            try:
                return float(v) if v is not None else d
            except Exception:
                return d
        rth = _getf("cfg:signal_cutoff:rth", settings.SIGNAL_CUTOFF_RTH)
        ext = _getf("cfg:signal_cutoff:ext", settings.SIGNAL_CUTOFF_EXT)
        # ì¡°ì • (í˜„ì‹¤ì  ê²½ê³„ê°’ìœ¼ë¡œ ìˆ˜ì •)
        rth_base, ext_base = settings.SIGNAL_CUTOFF_RTH, settings.SIGNAL_CUTOFF_EXT
        delta = -0.02 if fills == 0 else (0.02 if fills >= 4 else 0.0)
        rth_new = min(max(rth + delta, max(0.12, rth_base - 0.06)), rth_base + 0.12)
        ext_new = min(max(ext + delta, max(0.18, ext_base - 0.10)), ext_base + 0.10)
        r.set("cfg:signal_cutoff:rth", rth_new)
        r.set("cfg:signal_cutoff:ext", ext_new)
        return {"status": "ok", "fills": fills, "rth": rth_new, "ext": ext_new}
    except Exception as e:
        logger.error(f"ì ì‘í˜• ì»·ì˜¤í”„ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}


if __name__ == "__main__":
    # ê°œë°œìš© ì‹¤í–‰
    celery_app.start()
