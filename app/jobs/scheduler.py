"""
Celery beat ìŠ¤ì¼€ì¤„ëŸ¬
15-30ì´ˆ ì£¼ê¸°ë¡œ ì‹œê·¸ë„ ìƒì„± ë° ê±°ë˜ ì‹¤í–‰
"""
from datetime import datetime, timedelta
import hashlib
import json
import logging
import os
import time
from typing import Dict, List, Optional
import urllib.parse as _urlparse

import psycopg2
import redis

from celery import Celery
from celery.schedules import crontab
from celery.signals import beat_init, task_prerun, worker_process_init, worker_ready

from app.config import settings, get_signal_cutoffs, sanitize_cutoffs_in_redis

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Celery ì•± ìƒì„±
celery_app = Celery(
    "trading_bot",
    broker=os.getenv("REDIS_URL", "redis://localhost:6379/0"),
    backend=os.getenv("REDIS_URL", "redis://localhost:6379/0")
)

# ì„¤ì •
celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Asia/Seoul",  # KST
    enable_utc=True,        # UTC ìœ ì§€ + íƒ€ì„ì¡´-aware ìŠ¤ì¼€ì¤„ OK
    task_track_started=True,
    task_time_limit=30 * 60,  # 30ë¶„
    task_soft_time_limit=25 * 60,  # 25ë¶„
    worker_prefetch_multiplier=1,
    worker_max_tasks_per_child=1000,
)

# ìŠ¤ì¼€ì¤„ ì„¤ì •
celery_app.conf.beat_schedule = {
    # 15ì´ˆë§ˆë‹¤ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (E2E)
    "pipeline-e2e": {
        "task": "app.jobs.scheduler.pipeline_e2e",
        "schedule": 15.0,  # 15ì´ˆ
    },
    # 15ì´ˆë§ˆë‹¤ ì‹œê·¸ë„ ìƒì„±
    "generate-signals": {
        "task": "app.jobs.scheduler.generate_signals",
        "schedule": 15.0,  # 15ì´ˆ
    },
    # 30ì´ˆë§ˆë‹¤ ì‹œì„¸ ì—…ë°ì´íŠ¸
    "update-quotes": {
        "task": "app.jobs.scheduler.update_quotes",
        "schedule": 30.0,  # 30ì´ˆ
    },
    # 1ë¶„ë§ˆë‹¤ EDGAR ìŠ¤ìº”
    "scan-edgar": {
        "task": "app.jobs.scheduler.scan_edgar",
        "schedule": 60.0,  # 1ë¶„
    },
    # 5ë¶„ë§ˆë‹¤ ë¦¬ìŠ¤í¬ ì²´í¬
    "check-risk": {
        "task": "app.jobs.scheduler.check_risk",
        "schedule": 300.0,  # 5ë¶„
    },
    # ë§¤ì¼ ìì •ì— ì¼ì¼ ë¦¬ì…‹
    "daily-reset": {
        "task": "app.jobs.scheduler.daily_reset",
        "schedule": crontab(hour=0, minute=0),  # ë§¤ì¼ 00:00
    },
    # ë§¤ì¼ 06:10 KSTì— ì¼ì¼ ë¦¬í¬íŠ¸ (KST = UTC+9, 06:10 KST = 21:10 UTC ì „ë‚ )
    "daily-report": {
        "task": "app.jobs.scheduler.daily_report",
        "schedule": crontab(hour=21, minute=10),  # ë§¤ì¼ 21:10 UTC = 06:10 KST
        "args": [False, True],  # force=False, post=True (ìŠ¬ë™ìœ¼ë¡œ ë³´ë‚´ê¸°)
    },
    # 5ì´ˆë§ˆë‹¤ EDGAR ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘ â†’ DB ì ì¬ (dedupeëŠ” DB UNIQUEì™€ ON CONFLICTë¡œ ë³´ê°•)
    "ingest-edgar": {
        "task": "app.jobs.scheduler.ingest_edgar_stream",
        "schedule": 5.0,
    },
    # 15ë¶„ë§ˆë‹¤ ìœ ë‹ˆë²„ìŠ¤ ì¬ì ìš© (ê¶Œì¥ ë¶„ë¦¬)
    "refresh-universe": {
        "task": "app.jobs.scheduler.refresh_universe",
        "schedule": 900.0,
    },
    # ë§¤ì¼ 05:55 KST ì ì‘í˜• ì»·ì˜¤í”„ ê°±ì‹  (ë¦¬í¬íŠ¸ ì§ì „)
    "adaptive-cutoff": {
        "task": "app.jobs.scheduler.adaptive_cutoff",
        "schedule": crontab(hour=20, minute=55),  # 05:55 KST = 20:55 UTC ì „ë‚ 
    },
}

# ì „ì—­ ë³€ìˆ˜ (ì‹¤ì œë¡œëŠ” ì˜ì¡´ì„± ì£¼ì… ì‚¬ìš©)
trading_components = {
    "quotes_ingestor": None,
    "edgar_scanner": None,
    "regime_detector": None,
    "tech_score_engine": None,
    "llm_engine": None,
    "signal_mixer": None,
    "risk_engine": None,
    "paper_ledger": None,
    "redis_streams": None,
    "slack_bot": None,
    "stream_consumer": None,
    "db_connection": None,
}

def _parse_redis_url(url: str) -> tuple[str, int, int]:
    try:
        parsed = _urlparse.urlparse(url)
        host = parsed.hostname or "redis"
        port = int(parsed.port or 6379)
        db = int((parsed.path or "/0").lstrip("/") or 0)
        return host, port, db
    except Exception:
        return "redis", 6379, 0

def _autoinit_components_if_enabled() -> None:
    """Best-effort ì»´í¬ë„ŒíŠ¸ ìë™ ì´ˆê¸°í™” (ì›Œì»¤/ë¹„íŠ¸ í”„ë¡œì„¸ìŠ¤ ê¸°ë™ ì‹œ).
    í•„ìˆ˜ êµ¬ì„±ë§Œì´ë¼ë„ ì¤€ë¹„í•´ components_not_ready ìŠ¤í‚µì„ ì¤„ì¸ë‹¤.
    """
    if os.getenv("AUTO_INIT_COMPONENTS", "true").lower() not in ("1","true","yes","on"):  # opt-out
        return
    try:
        from app.io.quotes_delayed import DelayedQuotesIngestor
        from app.engine.regime import RegimeDetector
        from app.engine.techscore import TechScoreEngine
        from app.engine.mixer import SignalMixer
        from app.engine.risk import RiskEngine
        from app.adapters.paper_ledger import PaperLedger
        from app.io.streams import RedisStreams, StreamConsumer
        from app.engine.llm_insight import LLMInsightEngine
        from app.io.slack_bot import SlackBot
    except Exception as e:
        logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
        return

    components: Dict[str, object] = {}

    # Quotes ingestor
    try:
        components["quotes_ingestor"] = DelayedQuotesIngestor()
        # ì›Œë°ì—…ìœ¼ë¡œ ë¹ˆ ë²„í¼ ë°©ì§€
        components["quotes_ingestor"].warmup_backfill()  # type: ignore
        logger.info("ë”œë ˆì´ë“œ Quotes ì¸ì œìŠ¤í„° ì›Œë°ì—… ì™„ë£Œ")
    except Exception as e:
        logger.warning(f"Quotes ì¸ì œìŠ¤í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Regime/Tech/Mixer
    try:
        components["regime_detector"] = RegimeDetector()
    except Exception as e:
        logger.warning(f"RegimeDetector ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        components["tech_score_engine"] = TechScoreEngine()
    except Exception as e:
        logger.warning(f"TechScoreEngine ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        thr = settings.MIXER_THRESHOLD
        components["signal_mixer"] = SignalMixer(buy_threshold=thr, sell_threshold=-thr)
    except Exception as e:
        logger.warning(f"SignalMixer ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Risk/Paper ledger
    try:
        init_cap = float(os.getenv("INITIAL_CAPITAL", "1000000"))
        components["risk_engine"] = RiskEngine(initial_capital=init_cap)
    except Exception as e:
        logger.warning(f"RiskEngine ì¤€ë¹„ ì‹¤íŒ¨: {e}")
    try:
        components["paper_ledger"] = PaperLedger(initial_cash=float(os.getenv("INITIAL_CAPITAL", "1000000")))
    except Exception as e:
        logger.warning(f"PaperLedger ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Redis streams / consumer
    try:
        rurl = os.getenv("REDIS_URL", "redis://redis:6379/0")
        host, port, db = _parse_redis_url(rurl)
        rs = RedisStreams(host=host, port=port, db=db)
        components["redis_streams"] = rs
        components["stream_consumer"] = StreamConsumer(rs)
    except Exception as e:
        logger.warning(f"Redis Streams ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # Slack bot (optional)
    try:
        token = os.getenv("SLACK_BOT_TOKEN")
        channel = os.getenv("SLACK_CHANNEL_ID") or os.getenv("SLACK_CHANNEL", "#trading-signals")
        logger.info(f"ğŸ” [DEBUG] SlackBot í™˜ê²½ë³€ìˆ˜: token={'***' if token else None}, channel_id={os.getenv('SLACK_CHANNEL_ID')}, channel_fallback={os.getenv('SLACK_CHANNEL')}")
        logger.info(f"ğŸ” [DEBUG] SlackBot ìµœì¢… ì±„ë„: {channel}")
        if token:
            components["slack_bot"] = SlackBot(token=token, channel=channel)
            logger.info(f"Slack ë´‡ ì¤€ë¹„: ì±„ë„ {channel}")
        else:
            logger.warning("Slack í† í° ì—†ìŒ - ìŠ¬ë™ ë¹„í™œì„±")
    except Exception as e:
        logger.warning(f"SlackBot ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    # LLM (optional)
    try:
        llm = LLMInsightEngine()
        if components.get("slack_bot"):
            llm.set_slack_bot(components["slack_bot"])  # type: ignore
        components["llm_engine"] = llm
    except Exception as e:
        logger.warning(f"LLM ì—”ì§„ ì¤€ë¹„ ì‹¤íŒ¨: {e}")

    if components:
        try:
            initialize_components(components)  # ê¸°ì¡´ í—¬í¼ë¡œ ì£¼ì…
        except Exception as e:
            logger.warning(f"ì»´í¬ë„ŒíŠ¸ ì£¼ì… ì‹¤íŒ¨: {e}")

# Celery ì‹ í˜¸ì— ìë™ ì´ˆê¸°í™” ì—°ê²°
@worker_ready.connect
def _on_worker_ready(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

@beat_init.connect
def _on_beat_init(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

# ê° ì›Œì»¤ í”„ë¡œì„¸ìŠ¤(prefork)ì—ì„œ í•œ ë²ˆì”© ì´ˆê¸°í™”
@worker_process_init.connect
def _on_worker_process_init(sender=None, **kwargs):
    _autoinit_components_if_enabled()
    # ì»·ì˜¤í”„ ì •í™” ë° ë¡œê¹…
    result = sanitize_cutoffs_in_redis()
    if result:
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={result['rth']:.3f}, EXT={result['ext']:.3f}")
    else:
        rth, ext = get_signal_cutoffs()
        logger.info(f"ì»·ì˜¤í”„ ë¡œë“œë¨: RTH={rth:.3f}, EXT={ext:.3f}")

# íƒœìŠ¤í¬ ì§ì „ì—ë„ í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ì‹œë„
@task_prerun.connect
def _ensure_components_before_task(task=None, **kwargs):
    try:
        required_keys = [
            "quotes_ingestor",
            "regime_detector",
            "tech_score_engine",
            "signal_mixer",
        ]
        missing = [k for k in required_keys if not trading_components.get(k)]
        if missing:
            logger.warning(f"í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„(prerun): {missing} â†’ ìë™ ì´ˆê¸°í™” ì‹œë„")
            _autoinit_components_if_enabled()
    except Exception as e:
        logger.warning(f"prerun ìë™ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

@celery_app.task(bind=True, name="app.jobs.scheduler.pipeline_e2e")
def pipeline_e2e(self):
    """E2E íŒŒì´í”„ë¼ì¸: EDGAR ì´ë²¤íŠ¸ â†’ LLM â†’ ë ˆì§ â†’ ë¯¹ì„œ â†’ DB â†’ Slack"""
    try:
        start_time = time.time()
        logger.info("E2E íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # ì»´í¬ë„ŒíŠ¸ í™•ì¸ (í•„ìˆ˜ ìµœì†Œ êµ¬ì„±ë§Œ ê°•ì œ, LLMì€ ì„ íƒ)
        if not all([
            trading_components["stream_consumer"],
            trading_components["regime_detector"],
            trading_components["signal_mixer"],
            trading_components["slack_bot"]
        ]):
            logger.warning("í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„(stream_consumer/regime_detector/signal_mixer/slack_bot)")
            return {"status": "skipped", "reason": "components_not_ready"}
        
        stream_consumer = trading_components["stream_consumer"]
        llm_engine = trading_components["llm_engine"]
        regime_detector = trading_components["regime_detector"]
        signal_mixer = trading_components["signal_mixer"]
        slack_bot = trading_components["slack_bot"]
        
        signals_processed = 0
        
        # 1. EDGAR ì´ë²¤íŠ¸ ì†Œë¹„
        edgar_events = stream_consumer.consume_edgar_events(count=5, block_ms=100)
        
        for event in edgar_events:
            try:
                ticker = event.data.get("ticker")
                if not ticker:
                    continue
                
                # 2. LLM ë¶„ì„ (EDGAR ì´ë²¤íŠ¸ì´ë¯€ë¡œ ì¡°ê±´ ì¶©ì¡±)
                llm_insight = None
                if llm_engine:
                    text = event.data.get("snippet_text", "")
                    url = event.data.get("url", "")
                    llm_insight = llm_engine.analyze_text(text, url, edgar_event=True)
                
                # 3. ì‹œì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê°„ë‹¨í•œ ëª¨ì˜ ë°ì´í„°)
                candles = get_mock_candles(ticker)
                indicators = get_mock_indicators(ticker)
                
                # 4. ë ˆì§ ê°ì§€
                regime_result = regime_detector.detect_regime(candles)
                
                # 5. ê¸°ìˆ ì  ì ìˆ˜ ê³„ì‚°
                tech_score = get_mock_tech_score(ticker)
                
                # 6. ì‹œê·¸ë„ ë¯¹ì‹±
                current_price = 150.0  # ëª¨ì˜ ê°€ê²©
                signal = signal_mixer.mix_signals(
                    ticker=ticker,
                    regime_result=regime_result,
                    tech_score=tech_score,
                    llm_insight=llm_insight,
                    edgar_filing=event.data,
                    current_price=current_price
                )
                
                if signal:
                    # ë©”íƒ€ì— ì„¸ì…˜/í’ˆì§ˆ ì§€í‘œ ì‹¬ê¸° â†’ Slack í—¤ë” ë¼ë²¨ìš©
                    if not signal.meta:
                        signal.meta = {}
                    session_label = _session_label()
                    signal.meta["session"] = session_label
                    # ì•ˆì „ ê°€ë“œ: ë¯¸ì •ì˜ ë³€ìˆ˜ ì²˜ë¦¬
                    signal.meta.setdefault("spread_bp", 0.0)
                    signal.meta.setdefault("dollar_vol_5m", 0.0)
                    # 7. DBì— ì €ì¥
                    if trading_components.get("db_connection"):
                        signal_mixer.save_signal_to_db(signal, trading_components["db_connection"])
                    
                    # 8. Slack ì•Œë¦¼
                    if slack_bot:
                        slack_message = format_slack_message(signal)
                        slack_bot.send_message(slack_message)
                    
                    # 9. ë©”ì‹œì§€ ACK
                    stream_consumer.acknowledge("news.edgar", event.message_id)
                    
                    signals_processed += 1
                    logger.info(f"íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {ticker} {signal.signal_type.value}")
                
            except Exception as e:
                logger.error(f"ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        execution_time = time.time() - start_time
        logger.info(f"E2E íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {signals_processed}ê°œ, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "signals_processed": signals_processed,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"E2E íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def get_mock_candles(ticker: str) -> List:
    """ëª¨ì˜ ìº”ë“¤ ë°ì´í„°"""
    # ì‹¤ì œë¡œëŠ” quotes_ingestorì—ì„œ ê°€ì ¸ì˜´
    return []

def get_mock_indicators(ticker: str) -> Dict:
    """ëª¨ì˜ ê¸°ìˆ ì  ì§€í‘œ"""
    # ì‹¤ì œë¡œëŠ” quotes_ingestorì—ì„œ ê°€ì ¸ì˜´
    return {
        "adx": 25.0,
        "ema_20": 150.0,
        "ema_50": 148.0,
        "rsi": 65.0,
        "volume_spike": 0.3,
        "price_change_5m": 0.02,
        "realized_volatility": 0.03,
        "current_price": 150.0,
        "vwap": 149.5,
        "vwap_deviation": 0.003,
        "macd": 0.5,
        "macd_signal": 0.3,
        "bb_position": 0.6
    }

def get_mock_tech_score(ticker: str):
    """ëª¨ì˜ ê¸°ìˆ ì  ì ìˆ˜"""
    # ì‹¤ì œë¡œëŠ” tech_score_engineì—ì„œ ê³„ì‚°
    from app.engine.techscore import TechScoreResult
    return TechScoreResult(
        score=0.7,
        components={
            "ema": 0.8,
            "macd": 0.7,
            "rsi": 0.6,
            "vwap": 0.7,
        },
        timestamp=datetime.now()
    )

def format_slack_message(signal) -> Dict:
    """Slack ë©”ì‹œì§€ í¬ë§·"""
    return {
        "channel": "C099CQP8CJ3",  # ğŸ”§ ëª…ì‹œì ìœ¼ë¡œ ì±„ë„ ID ì§€ì • (channel_not_found ì˜¤ë¥˜ í•´ê²°)
        "text": (
            f"{signal.ticker} | ë ˆì§ {signal.regime.upper()}({signal.confidence:.2f}) | "
            f"ì ìˆ˜ {signal.score:+.2f} {'ë¡±' if signal.signal_type.value == 'long' else 'ìˆ'}"
        )
    }

@celery_app.task(bind=True, name="app.jobs.scheduler.generate_signals")
def generate_signals(self):
    """ì‹œê·¸ë„ ìƒì„± ì‘ì—…"""
    try:
        start_time = time.time()
        logger.info("ì‹œê·¸ë„ ìƒì„± ì‹œì‘")
        
        # í•„ìˆ˜ ìµœì†Œ ì»´í¬ë„ŒíŠ¸ í™•ì¸: ìŠ¤ìº˜í”„ ê²½ë¡œë§Œì´ë¼ë„ ëŒë¦´ ìˆ˜ ìˆê²Œ ìµœì†Œ depsë§Œ ê°•ì œ
        # 1) quotes_ingestor í•„ìˆ˜. ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ìƒì„± ì‹œë„
        if not trading_components.get("quotes_ingestor"):
            logger.warning("í•„ìˆ˜ ì»´í¬ë„ŒíŠ¸ ë¯¸ì¤€ë¹„: ['quotes_ingestor'] â†’ ë¡œì»¬ ìƒì„± ì‹œë„")
            try:
                from app.io.quotes_delayed import DelayedQuotesIngestor
                trading_components["quotes_ingestor"] = DelayedQuotesIngestor()
                try:
                    trading_components["quotes_ingestor"].warmup_backfill()  # type: ignore
                except Exception:
                    pass
            except Exception as e:
                logger.warning(f"quotes_ingestor ìƒì„± ì‹¤íŒ¨: {e}")
        if not trading_components.get("quotes_ingestor"):
            return {"status": "skipped", "reason": "quotes_ingestor_not_ready"}
        # 2) signal_mixer ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„± (ìŠ¤ìº˜í”„ ê²½ë¡œìš©)
        if not trading_components.get("signal_mixer"):
            try:
                from app.engine.mixer import SignalMixer
                thr = settings.MIXER_THRESHOLD
                trading_components["signal_mixer"] = SignalMixer(buy_threshold=thr, sell_threshold=-thr)
                logger.warning("signal_mixer ë¡œì»¬ ìƒì„±")
            except Exception as e:
                logger.warning(f"signal_mixer ìƒì„± ì‹¤íŒ¨: {e}")
        # 3) redis_streams ì—†ìœ¼ë©´ í˜„ ìë¦¬ì—ì„œ ìƒì„± (ë°œí–‰ìš©)
        if not trading_components.get("redis_streams"):
            try:
                from app.io.streams import RedisStreams
                rurl = os.getenv("REDIS_URL", "redis://redis:6379/0")
                host, port, db = _parse_redis_url(rurl)
                trading_components["redis_streams"] = RedisStreams(host=host, port=port, db=db)
            except Exception as e:
                logger.warning(f"redis_streams ìƒì„± ì‹¤íŒ¨: {e}")
        
        quotes_ingestor = trading_components["quotes_ingestor"]
        edgar_scanner = trading_components["edgar_scanner"]
        regime_detector = trading_components["regime_detector"]
        tech_score_engine = trading_components["tech_score_engine"]
        llm_engine = trading_components["llm_engine"]
        signal_mixer = trading_components["signal_mixer"]
        redis_streams = trading_components["redis_streams"]
        slack_bot = trading_components.get("slack_bot")
        
        # ğŸ” DEBUG: Slack bot ìƒíƒœ í™•ì¸
        logger.info(f"ğŸ” [DEBUG] slack_bot ì¡´ì¬ ì—¬ë¶€: {slack_bot is not None}")
        if slack_bot:
            logger.info(f"ğŸ” [DEBUG] slack_bot íƒ€ì…: {type(slack_bot)}")
            logger.info(f"ğŸ” [DEBUG] slack_bot ì±„ë„: {getattr(slack_bot, 'default_channel', 'N/A')}")
        else:
            logger.warning(f"ğŸ” [DEBUG] slack_botì´ Noneì„! trading_components í‚¤: {list(trading_components.keys())}")
        
        signals_generated = 0
        
        # ê° ì¢…ëª©ë³„ë¡œ ì‹œê·¸ë„ ìƒì„±
        # ìœ ë‹ˆë²„ìŠ¤ ë™ì  ì ìš© (Redis union: core + external + watchlist)
        dynamic_universe = None
        try:
            rurl = os.getenv("REDIS_URL")
            if rurl:
                r = redis.from_url(rurl)
                external = r.smembers("universe:external") or []
                watch = r.smembers("universe:watchlist") or []
                core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
                ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
                wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
                merged = []
                seen = set()
                max_n = int(os.getenv("UNIVERSE_MAX", "100"))
                for arr in [core, ext, wch]:
                    for s in arr:
                        if s and s not in seen:
                            merged.append(s)
                            seen.add(s)
                        if len(merged) >= max_n:
                            break
                    if len(merged) >= max_n:
                        break
                dynamic_universe = merged
                # ì¸ì œìŠ¤í„°ì— ë°˜ì˜ ë° ì›Œë°ì—…
                try:
                    if hasattr(quotes_ingestor, "update_universe_tickers"):
                        quotes_ingestor.update_universe_tickers(dynamic_universe)
                except Exception:
                    pass
        except Exception:
            dynamic_universe = None

        tickers_iter = dynamic_universe or list(quotes_ingestor.tickers)
        for ticker in tickers_iter:
            try:
                # 1. ì‹œì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                candles = quotes_ingestor.get_latest_candles(ticker, 50)
                if len(candles) < 20:
                    continue
                
                # 2. ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
                indicators = quotes_ingestor.get_technical_indicators(ticker)
                if not indicators:
                    continue
                
                # 2.5 ìŠ¤ìº˜í”„ ëª¨ë“œ: ë§ˆì§€ë§‰ í•œ í‹±ì´ í¬ê²Œ íŠ€ë©´ ì¦‰ì‹œ ì‹ í˜¸ ìƒì„± (í…ŒìŠ¤íŠ¸/ì•Œë¦¼ìš©)
                try:
                    scalp_enabled = (os.getenv("SCALP_TICK_SPIKE", "false").lower() in ("1", "true", "yes", "on"))
                    if scalp_enabled and len(candles) >= 2:
                        # 30s/15s ë¶„í•  ì‹œ ë§ˆì§€ë§‰ ë‘ ë°”ê°€ ê°™ì€ 1ë¶„ì— ì†í•¨ â†’ ë¶„ë‹¹ ê°„ê²©ìœ¼ë¡œ ë¹„êµ
                        try:
                            bars_per_min = max(1, 60 // max(getattr(quotes_ingestor, "bar_sec", 60), 1))
                        except Exception:
                            bars_per_min = 1
                        last = candles[-1]
                        prev_idx = -1 - bars_per_min if len(candles) > bars_per_min else -2
                        prev = candles[prev_idx]
                        last_abs_ret = abs((last.c - prev.c) / max(prev.c, 1e-9))
                        spike_thr = float(os.getenv("SCALP_MIN_RET", "0.003"))  # ê¸°ë³¸ 0.3%
                        # ì•¼í›„ 1ë¶„ë´‰ ë¶„í•  ì‹œ ë§ˆì§€ë§‰ ë‘ ë°”ê°€ ë™ì¼ ê°’ì¸ ê²½ìš°ê°€ ë§ì•„ ê³ ì €í­ ê¸°ì¤€ë„ í—ˆìš©
                        last_range = (last.h - last.l) / max(last.c, 1e-9)
                        range_thr = float(os.getenv("SCALP_MIN_RANGE", "0.003"))  # ê¸°ë³¸ 0.3%
                        trig_reason = None
                        if last_abs_ret >= spike_thr:
                            trig_reason = f"ret>={spike_thr:.3%}"
                        elif last_range >= range_thr:
                            trig_reason = f"range>={range_thr:.3%}"
                        if trig_reason:
                            from app.engine.regime import RegimeType, RegimeResult
                            from app.engine.techscore import TechScoreResult
                            direction = 1.0 if (last.c - prev.c) >= 0 else -1.0
                            fake_regime = RegimeResult(
                                regime=RegimeType.VOL_SPIKE,
                                confidence=min(1.0, last_abs_ret * 20.0),
                                features={"last_abs_ret": last_abs_ret},
                                timestamp=datetime.now()
                            )
                            fake_tech = TechScoreResult(
                                score=direction,  # -1 ~ +1ë¡œ ì§ì ‘ ìŠ¤ì¼€ì¼
                                components={"ema": 0.8 if direction > 0 else 0.2,
                                            "macd": 0.8 if direction > 0 else 0.2,
                                            "rsi": 0.8 if direction > 0 else 0.2,
                                            "vwap": 0.8 if direction > 0 else 0.2},
                                timestamp=datetime.now()
                            )
                            quick_signal = signal_mixer.mix_signals(
                                ticker=ticker,
                                regime_result=fake_regime,
                                tech_score=fake_tech,
                                llm_insight=None,
                                edgar_filing=None,
                                current_price=last.c
                            )
                            if quick_signal:
                                quick_signal.trigger = "tick_spike"
                                quick_signal.summary = f"{trig_reason}; abs_ret={last_abs_ret:.3%}; range={last_range:.3%}"
                                # ì»·/ì„¸ì…˜ ì–µì œ ë™ì¼ ì ìš© (ë¡œì»¬ ê³„ì‚°)
                                sess_now = _session_label()
                                cutoff_rth, cutoff_ext = get_signal_cutoffs()
                                cut_r = cutoff_rth
                                cut_e = cutoff_ext
                                cut = cut_r if sess_now == "RTH" else cut_e
                                if abs(quick_signal.score) < cut:
                                    logger.info(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ ì‹ í˜¸ ì–µì œ: {ticker} score={quick_signal.score:.3f} < cut={cut:.3f}")
                                    _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="below_cutoff")
                                else:
                                    logger.info(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ ì‹ í˜¸ ë°œí–‰: {ticker} {quick_signal.signal_type.value} score={quick_signal.score:.3f}")
                                    try:
                                        redis_streams.publish_signal({
                                            "ticker": quick_signal.ticker,
                                            "signal_type": quick_signal.signal_type.value,
                                            "score": quick_signal.score,
                                            "confidence": quick_signal.confidence,
                                            "regime": quick_signal.regime,
                                            "tech_score": quick_signal.tech_score,
                                            "sentiment_score": quick_signal.sentiment_score,
                                            "edgar_bonus": quick_signal.edgar_bonus,
                                            "trigger": quick_signal.trigger,
                                            "summary": quick_signal.summary,
                                            "entry_price": quick_signal.entry_price,
                                            "stop_loss": quick_signal.stop_loss,
                                            "take_profit": quick_signal.take_profit,
                                            "horizon_minutes": quick_signal.horizon_minutes,
                                            "timestamp": quick_signal.timestamp.isoformat()
                                        })
                                        logger.info(f"ğŸ”¥ [SCALP DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                                        signals_generated += 1
                                        _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators)
                                        logger.info(f"ìŠ¤ìº˜í”„ ì‹ í˜¸: {ticker} {quick_signal.signal_type.value} ({trig_reason}, abs_ret {last_abs_ret:.2%}, range {last_range:.2%})")
                                    except Exception as e:
                                        logger.error(f"ğŸ”¥ [SCALP DEBUG] ìŠ¤ìº˜í”„ Redis ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                                    # ìŠ¤ìº˜í”„ ëª¨ë“œì—ì„  í•œ í‹±ë§Œ ì¡ìœ¼ë©´ ì¶©ë¶„ â€” ë‹¤ìŒ ì¢…ëª©ìœ¼ë¡œ
                                    continue
                except Exception:
                    pass

                # 2.6 ìŠ¤ìº˜í”„ ëª¨ë“œ(ëŒ€ì•ˆ): 3ë¶„ë´‰ 3ê°œ ì—°ì† ì–‘ë´‰ì´ë©´ ë¡± ì‹ í˜¸
                try:
                    if os.getenv("SCALP_3MIN3UP", "false").lower() in ("1", "true", "yes", "on"):
                        bar_sec = int(os.getenv("BAR_SEC", "30") or 30)
                        window = max(1, int(180 / max(bar_sec, 1)))  # 3ë¶„ ì°½ì˜ ë°” ê°œìˆ˜
                        need = window * 3
                        if len(candles) >= need:
                            w1 = candles[-window:]
                            w2 = candles[-2*window:-window]
                            w3 = candles[-3*window:-2*window]
                            def _is_green(ws):
                                try:
                                    return (ws[-1].c if ws else 0.0) > (ws[0].o if ws else 0.0)
                                except Exception:
                                    return False
                            if _is_green(w1) and _is_green(w2) and _is_green(w3):
                                from app.engine.regime import RegimeType, RegimeResult
                                from app.engine.techscore import TechScoreResult
                                fake_regime = RegimeResult(
                                    regime=RegimeType.TREND,
                                    confidence=0.8,
                                    features={"3min3up": True},
                                    timestamp=datetime.now()
                                )
                                fake_tech = TechScoreResult(
                                    score=1.0,
                                    components={"ema": 0.9, "macd": 0.9, "rsi": 0.8, "vwap": 0.8},
                                    timestamp=datetime.now()
                                )
                                last_px = candles[-1].c
                                quick_signal = signal_mixer.mix_signals(
                                    ticker=ticker,
                                    regime_result=fake_regime,
                                    tech_score=fake_tech,
                                    llm_insight=None,
                                    edgar_filing=None,
                                    current_price=last_px
                                )
                                if quick_signal:
                                    quick_signal.trigger = "3min_3up"
                                    quick_signal.summary = "3min green x3"
                                    sess_now = _session_label()
                                    cutoff_rth, cutoff_ext = get_signal_cutoffs()
                                    cut_r = cutoff_rth
                                    cut_e = cutoff_ext
                                    cut = cut_r if sess_now == "RTH" else cut_e
                                    if abs(quick_signal.score) < cut:
                                        logger.info(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ì–µì œ: {ticker} score={quick_signal.score:.3f} < cut={cut:.3f}")
                                        _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators, suppressed="below_cutoff")
                                    else:
                                        logger.info(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ ì‹ í˜¸ ë°œí–‰: {ticker} long score={quick_signal.score:.3f}")
                                        try:
                                            redis_streams.publish_signal({
                                                "ticker": quick_signal.ticker,
                                                "signal_type": quick_signal.signal_type.value,
                                                "score": quick_signal.score,
                                                "confidence": quick_signal.confidence,
                                                "regime": quick_signal.regime,
                                                "tech_score": quick_signal.tech_score,
                                                "sentiment_score": quick_signal.sentiment_score,
                                                "edgar_bonus": quick_signal.edgar_bonus,
                                                "trigger": quick_signal.trigger,
                                                "summary": quick_signal.summary,
                                                "entry_price": quick_signal.entry_price,
                                                "stop_loss": quick_signal.stop_loss,
                                                "take_profit": quick_signal.take_profit,
                                                "horizon_minutes": quick_signal.horizon_minutes,
                                                "timestamp": quick_signal.timestamp.isoformat()
                                            })
                                            logger.info(f"ğŸ”¥ [3MIN DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                                            signals_generated += 1
                                            _record_recent_signal(redis_url=rurl, signal=quick_signal, session_label=sess_now, indicators=indicators)
                                            logger.info(f"ìŠ¤ìº˜í”„ ì‹ í˜¸: {ticker} long (3min_3up)")
                                        except Exception as e:
                                            logger.error(f"ğŸ”¥ [3MIN DEBUG] 3ë¶„3ìƒìŠ¹ Redis ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                                        continue
                except Exception:
                    pass

                # 3. ë ˆì§ ê°ì§€
                regime_result = regime_detector.detect_regime(candles)
                
                # 4. ê¸°ìˆ ì  ì ìˆ˜ ê³„ì‚°
                tech_score = tech_score_engine.calculate_tech_score(candles)
                
                # 5. EDGAR ê³µì‹œ í™•ì¸
                edgar_filing = None
                llm_insight = None
                
                # ìµœê·¼ EDGAR ê³µì‹œê°€ ìˆëŠ”ì§€ í™•ì¸
                recent_edgar = get_recent_edgar_filing(ticker)
                if recent_edgar:
                    edgar_filing = recent_edgar
                    # LLM ë¶„ì„ (EDGAR ì´ë²¤íŠ¸ì´ë¯€ë¡œ ì¡°ê±´ ì¶©ì¡±)
                    llm_insight = llm_engine.analyze_edgar_filing(edgar_filing)
                
                # 6. ë ˆì§ì´ vol_spikeì¸ ê²½ìš° ì¶”ê°€ LLM ë¶„ì„
                if regime_result.regime.value == 'vol_spike' and llm_engine and not llm_insight:
                    # vol_spike ë ˆì§ì—ì„œ LLM ë¶„ì„ (ì¡°ê±´ ì¶©ì¡±)
                    text = f"Volatility spike detected for {ticker} in {regime_result.regime.value} regime"
                    llm_insight = llm_engine.analyze_text(text, f"vol_spike_{ticker}", regime='vol_spike')
                
                # 6. ì„¸ì…˜ë³„ pre-filter (RTH: ì¼ì¼ìƒí•œ, EXT: ìœ ë™ì„±/ìŠ¤í”„ë ˆë“œ/ì¿¨ë‹¤ìš´/ì¼ì¼ìƒí•œ)
                ext_enabled = (os.getenv("EXTENDED_PRICE_SIGNALS", "false").lower() in ("1","true","yes","on"))
                session_label = _session_label()
                cutoff_rth, cutoff_ext = get_signal_cutoffs()
                dvol5m = float(indicators.get("dollar_vol_5m", 0.0))
                spread_bp = float(indicators.get("spread_bp", 0.0))
                suppress_reason = None
                
                # RTH ì¼ì¼ ìƒí•œ (5ê±´ ëª©í‘œ)
                if session_label == "RTH":
                    try:
                        if rurl:
                            r = redis.from_url(rurl)
                            rth_daily_cap = int(os.getenv("RTH_DAILY_CAP", "5"))
                            day_key = f"dailycap:{datetime.utcnow():%Y%m%d}:RTH:{ticker}"
                            used = int(r.get(day_key) or 0)
                            if used >= rth_daily_cap:
                                suppress_reason = "rth_daily_cap"
                    except Exception:
                        pass
                elif session_label == "EXT":
                    if not ext_enabled:
                        suppress_reason = "ext_disabled"
                    if dvol5m < float(os.getenv("EXT_MIN_DOLLAR_VOL_5M", "50000")):
                        suppress_reason = suppress_reason or "low_dvol"
                    if spread_bp > float(os.getenv("EXT_MAX_SPREAD_BP", "300")):
                        suppress_reason = suppress_reason or "wide_spread"
                    # ì¿¨ë‹¤ìš´/ì¼ì¼ ìƒí•œ ì²´í¬: Redis í‚¤ ì‚¬ìš©
                    try:
                        if rurl:
                            r = redis.from_url(rurl)
                            cool_min = int(os.getenv("EXT_COOLDOWN_MIN", "7"))
                            daily_cap = 3
                            now_ts = int(time.time())
                            cd_key = f"cooldown:{ticker}"
                            last_ts = int(r.get(cd_key) or 0)
                            if now_ts - last_ts < cool_min * 60:
                                suppress_reason = suppress_reason or "cooldown"
                            day_key = f"dailycap:{datetime.utcnow():%Y%m%d}:{ticker}"
                            used = int(r.get(day_key) or 0)
                            if used >= daily_cap:
                                suppress_reason = suppress_reason or "daily_cap"
                            if not suppress_reason:
                                # í†µê³¼ ì‹œ ë‹¤ìŒ ì¹´ìš´íŒ…ì„ ìœ„í•´ ì„ì‹œ ë§ˆí‚¹(ì‹¤ì œ Slack ì „ì†¡ ì‹œ ìµœì¢… ì¦ê°€ ê¶Œì¥)
                                r.setex(cd_key, cool_min*60, now_ts)
                    except Exception:
                        pass

                # VaR95 ê²½ëŸ‰ ê°€ë“œ: ìµœê·¼ ë¦¬í„´ ìƒ˜í”Œ ê¸°ë°˜(ì˜µì…˜)
                try:
                    from app.engine.risk import rolling_var95
                    # ìƒ˜í”Œì€ ë³„ë„ ê³³ì—ì„œ ì±„ì›Œì§„ë‹¤ê³  ê°€ì •; ì—†ìœ¼ë©´ ìŠ¤í‚µ
                    rurl = os.getenv("REDIS_URL")
                    var_guard = False
                    if rurl:
                        r = redis.from_url(rurl)
                        key = f"risk:rets:{ticker}:{regime_result.regime.value}"
                        samples = [float(x) for x in (r.lrange(key, 0, 9999) or [])]
                        if samples:
                            var95 = rolling_var95(samples)
                            # ê°„ì´ ê¸°ì¤€: ì˜ˆìƒ ì†ì‹¤R>VaRì´ë©´ ì–µì œ
                            # ì—¬ê¸°ì„œëŠ” ì‹ í˜¸ ìƒì„± í›„ ì»·ì˜¤í”„ ë‹¨ê³„ì—ì„œ suppress
                            pass
                except Exception:
                    pass

                # 7. ì‹œê·¸ë„ ë¯¹ì‹±
                current_price = candles[-1].c if candles else 0
                signal = signal_mixer.mix_signals(
                    ticker=ticker,
                    regime_result=regime_result,
                    tech_score=tech_score,
                    llm_insight=llm_insight,
                    edgar_filing=edgar_filing,
                    current_price=current_price
                )
                
                if signal:
                    # ì»·ì˜¤í”„ ì ìš© (ì„¸ì…˜ë³„)
                    cut = cutoff_rth if session_label == "RTH" else cutoff_ext
                    if abs(signal.score) < cut or suppress_reason:
                        # ì–µì œ ì‚¬ìœ  ìƒì„¸ ë¡œê·¸
                        logger.info(f"ì–µì œ: reason={suppress_reason or 'below_cutoff'} "
                                   f"score={signal.score:.3f} cut={cut:.3f} dvol5m={dvol5m:.0f} spread_bp={spread_bp:.1f}")
                        
                        # ì–µì œ ë©”íŠ¸ë¦­ ëˆ„ì 
                        try:
                            if rurl:
                                r = redis.from_url(rurl)
                                hkey = f"metrics:suppressed:{datetime.utcnow():%Y%m%d}"
                                r.hincrby(hkey, suppress_reason or "below_cutoff", 1)
                        except Exception:
                            pass
                        # ìµœê·¼ ì‹ í˜¸ ë¦¬ìŠ¤íŠ¸ì— suppressedë¡œ ê¸°ë¡
                        _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators, suppressed=suppress_reason or "below_cutoff")
                        continue

                    # 7. Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
                    signal_data = {
                        "ticker": signal.ticker,
                        "signal_type": signal.signal_type.value,
                        "score": signal.score,
                        "confidence": signal.confidence,
                        "regime": signal.regime,
                        "tech_score": signal.tech_score,
                        "sentiment_score": signal.sentiment_score,
                        "edgar_bonus": signal.edgar_bonus,
                        "trigger": signal.trigger,
                        "summary": signal.summary,
                        "entry_price": signal.entry_price,
                        "stop_loss": signal.stop_loss,
                        "take_profit": signal.take_profit,
                        "horizon_minutes": signal.horizon_minutes,
                        "timestamp": signal.timestamp.isoformat()
                    }
                    
                    logger.info(f"ğŸ”¥ [DEBUG] ì‹œê·¸ë„ ìƒì„±ë¨! ticker={ticker}, type={signal.signal_type.value}, score={signal.score:.3f}, cut={cut:.3f}")
                    logger.info(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹œë„ ì¤‘...")
                    
                    try:
                        redis_streams.publish_signal(signal_data)
                        logger.info(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì„±ê³µ: {ticker}")
                        
                        # Slack ì „ì†¡: ê°•ì‹ í˜¸ë§Œ (ì›ë˜ ê¸°íš - ì†Œìˆ˜Â·êµµì§í•œ ì•Œë¦¼)
                        if slack_bot:
                            # ê°•ì‹ í˜¸ ê¸°ì¤€: abs(score) >= cut + 0.20 (ë” ê¹Œë‹¤ë¡­ê²Œ)
                            strong_signal_threshold = cut + 0.20
                            is_strong_signal = abs(signal.score) >= strong_signal_threshold
                            
                            if is_strong_signal:
                                logger.info(f"ğŸ“¢ Slack ì „ì†¡ (ê°•ì‹ í˜¸): {ticker} score={signal.score:.3f} >= {strong_signal_threshold:.3f}")
                                try:
                                    slack_message = format_slack_message(signal)
                                    result = slack_bot.send_message(slack_message)
                                    if result:
                                        logger.info(f"âœ… Slack ì „ì†¡ ì„±ê³µ: {ticker}")
                                        # ì¼ì¼ ìƒí•œ ì¹´ìš´í„° ì¦ê°€
                                        try:
                                            if rurl:
                                                r = redis.from_url(rurl)
                                                if session_label == "RTH":
                                                    day_key = f"dailycap:{datetime.utcnow():%Y%m%d}:RTH:{ticker}"
                                                    r.incr(day_key)
                                                    r.expire(day_key, 86400)  # 24ì‹œê°„ ë§Œë£Œ
                                                elif session_label == "EXT":
                                                    day_key = f"dailycap:{datetime.utcnow():%Y%m%d}:EXT:{ticker}"
                                                    r.incr(day_key)
                                                    r.expire(day_key, 86400)  # 24ì‹œê°„ ë§Œë£Œ
                                        except Exception as e:
                                            logger.warning(f"ì¼ì¼ ìƒí•œ ì¹´ìš´í„° ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                                    else:
                                        logger.error(f"âŒ Slack ì „ì†¡ ì‹¤íŒ¨: {ticker}")
                                except Exception as e:
                                    logger.error(f"âŒ Slack ì „ì†¡ ì˜ˆì™¸: {ticker} - {e}")
                            else:
                                logger.info(f"ğŸ”‡ Slack ì „ì†¡ ì–µì œ (ì•½ì‹ í˜¸): {ticker} score={signal.score:.3f} < {strong_signal_threshold:.3f}")
                        else:
                            logger.warning(f"ğŸ” Slack ì „ì†¡ ê±´ë„ˆëœ€ - slack_botì´ None: {ticker}")
                        
                        signals_generated += 1
                    except Exception as e:
                        logger.error(f"ğŸ”¥ [DEBUG] Redis ìŠ¤íŠ¸ë¦¼ ë°œí–‰ ì‹¤íŒ¨: {ticker} - {e}")
                        continue
                    # ìµœê·¼ ì‹ í˜¸ ê¸°ë¡ (+ ì„¸ì…˜/ìŠ¤í”„ë ˆë“œ/ë‹¬ëŸ¬ëŒ€ê¸ˆ)
                    _record_recent_signal(redis_url=rurl, signal=signal, session_label=session_label, indicators=indicators)
                    
                    logger.info(f"ì‹œê·¸ë„ ìƒì„±: {ticker} {signal.signal_type.value} (ì ìˆ˜: {signal.score:.2f})")
                
            except Exception as e:
                logger.error(f"ì‹œê·¸ë„ ìƒì„± ì‹¤íŒ¨ ({ticker}): {e}")
                continue
        
        execution_time = time.time() - start_time
        logger.info(f"ì‹œê·¸ë„ ìƒì„± ì™„ë£Œ: {signals_generated}ê°œ, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "signals_generated": signals_generated,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œê·¸ë„ ìƒì„± ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.update_quotes")
def update_quotes(self):
    """ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‹œì‘")
        
        quotes_ingestor = trading_components["quotes_ingestor"]
        redis_streams = trading_components["redis_streams"]
        
        if not quotes_ingestor or not redis_streams:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ëª¨ë“  ì¢…ëª© ì‹œì„¸ ì—…ë°ì´íŠ¸
        quotes_ingestor.update_all_tickers()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        market_data = quotes_ingestor.get_market_data_summary()
        # ì˜µì…˜: ì•¼í›„ ì¸ì œìŠ¤í„° ìš”ì•½ ë¡œê·¸ (ì‹¤ì‹œê°„ í‹± ì¶”ì ìš©)
        try:
            if os.getenv("QUOTE_LOG_VERBOSE", "false").lower() in ("1", "true", "yes", "on"):
                for _t, _d in (market_data or {}).items():
                    _ind = _d.get("indicators", {}) if isinstance(_d, dict) else {}
                    _px = float(_d.get("current_price", 0.0) or 0.0)
                    _dv = float(_ind.get("dollar_vol_5m", 0.0) or 0.0)
                    _sp = float(_ind.get("spread_bp", 0.0) or 0.0)
                    _ts = _d.get("last_update")
                    logger.info(f"[YQ] { _t } px={_px:.4f} dollar_vol_5m={_dv:.0f} spread_bp={_sp:.1f} ts={_ts}")
        except Exception:
            pass
        for ticker, data in market_data.items():
            if data.get("current_price"):
                quote_data = {
                    "ticker": ticker,
                    "price": data["current_price"],
                    "indicators": data.get("indicators", {}),
                    "timestamp": data.get("last_update", datetime.now()).isoformat()
                }
                redis_streams.publish_quote(ticker, "XNAS", quote_data)
        
        execution_time = time.time() - start_time
        logger.debug(f"ì‹œì„¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(market_data)}ê°œ ì¢…ëª©, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "tickers_updated": len(market_data),
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì‹œì„¸ ì—…ë°ì´íŠ¸ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.scan_edgar")
def scan_edgar(self):
    """EDGAR ìŠ¤ìº” ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("EDGAR ìŠ¤ìº” ì‹œì‘")
        
        # EDGAR ìŠ¤ìºë„ˆ ì¤€ë¹„
        try:
            from app.io.edgar import EDGARScanner
        except Exception:
            EDGARScanner = None  # type: ignore
        edgar_scanner = trading_components.get("edgar_scanner")
        if edgar_scanner is None and EDGARScanner is not None:
            edgar_scanner = EDGARScanner()
            trading_components["edgar_scanner"] = edgar_scanner
        redis_streams = trading_components.get("redis_streams")
        redis_client = None
        try:
            # dedupeë¥¼ ìœ„í•œ raw redis í´ë¼ì´ì–¸íŠ¸ ì ‘ê·¼ (streams ë‚´ë¶€ í´ë¼ì´ì–¸íŠ¸ ì¬ì‚¬ìš©)
            if redis_streams:
                redis_client = redis_streams.redis_client
        except Exception:
            redis_client = None
        
        if not redis_streams:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # EDGAR ê³µì‹œ ìŠ¤ìº”
        filings = edgar_scanner.run_scan()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰ (ì¤‘ë³µ ë°©ì§€)
        dedupe_key = "edgar:dedupe:snippets"
        published = 0
        for filing in filings:
            snippet_text = filing.get("summary") or filing.get("snippet_text") or ""
            url = filing.get("url", "")
            base = (snippet_text or url).encode()
            snippet_hash = hashlib.md5(base).hexdigest()
            if redis_client:
                # ì¤‘ë³µì´ë©´ ìŠ¤í‚µ
                added = redis_client.sadd(dedupe_key, snippet_hash)
                if not added:
                    continue
            # í•´ì‹œë¥¼ í•¨ê»˜ ì €ì¥í•´ë‘ê¸°
            filing["snippet_hash"] = snippet_hash
            # StreamsëŠ” ë¬¸ìì—´ ê°’ì´ ì•ˆì „í•˜ë¯€ë¡œ dict/listëŠ” JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            payload = {k: json.dumps(v) if isinstance(v, (dict, list)) else (v if v is not None else "") for k, v in filing.items()}
            redis_streams.publish_edgar(payload)
            published += 1
            
            # ì¤‘ìš” ê³µì‹œ LLM ì²˜ë¦¬
            if filing.get("impact_score", 0) > 0.7 and llm_engine:
                llm_insight = llm_engine.analyze_edgar_filing(filing)
                if llm_insight:
                    insight_data = {
                        "ticker": filing["ticker"],
                        "sentiment": llm_insight.sentiment,
                        "trigger": llm_insight.trigger,
                        "horizon_minutes": llm_insight.horizon_minutes,
                        "summary": llm_insight.summary,
                        "timestamp": llm_insight.timestamp.isoformat()
                    }
                    redis_streams.publish_news(insight_data)
        
        execution_time = time.time() - start_time
        logger.debug(f"EDGAR ìŠ¤ìº” ì™„ë£Œ: {published}ê°œ ë°œí–‰, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "published": published,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"EDGAR ìŠ¤ìº” ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.check_risk")
def check_risk(self):
    """ë¦¬ìŠ¤í¬ ì²´í¬ ì‘ì—…"""
    try:
        start_time = time.time()
        logger.debug("ë¦¬ìŠ¤í¬ ì²´í¬ ì‹œì‘")
        
        risk_engine = trading_components["risk_engine"]
        slack_bot = trading_components["slack_bot"]
        redis_streams = trading_components["redis_streams"]
        
        if not risk_engine:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œ ê³„ì‚°
        risk_metrics = risk_engine.calculate_risk_metrics()
        
        # Redis ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        if redis_streams:
            risk_data = {
                "daily_pnl": risk_metrics.daily_pnl,
                "daily_pnl_pct": risk_metrics.daily_pnl_pct,
                "var_95": risk_metrics.var_95,
                "max_drawdown": risk_metrics.max_drawdown,
                "position_count": risk_metrics.position_count,
                "total_exposure": risk_metrics.total_exposure,
                "status": risk_metrics.status.value,
                "timestamp": risk_metrics.timestamp.isoformat()
            }
            redis_streams.publish_risk_update(risk_data)
        
        # ê²½ê³ /ìœ„í—˜ ìƒíƒœì¼ ë•Œ Slack ì•Œë¦¼
        if risk_metrics.status.value in ["warning", "critical", "shutdown"] and slack_bot:
            risk_report = risk_engine.get_risk_report()
            slack_bot.send_risk_alert(risk_report)
        
        execution_time = time.time() - start_time
        logger.debug(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì™„ë£Œ: {risk_metrics.status.value}, {execution_time:.2f}ì´ˆ")
        
        return {
            "status": "success",
            "risk_status": risk_metrics.status.value,
            "daily_pnl_pct": risk_metrics.daily_pnl_pct,
            "execution_time": execution_time,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(bind=True, name="app.jobs.scheduler.daily_reset")
def daily_reset(self):
    """ì¼ì¼ ë¦¬ì…‹ ì‘ì—…"""
    try:
        logger.info("ì¼ì¼ ë¦¬ì…‹ ì‹œì‘")
        
        risk_engine = trading_components["risk_engine"]
        paper_ledger = trading_components["paper_ledger"]
        slack_bot = trading_components["slack_bot"]
        
        # ë¦¬ìŠ¤í¬ ì—”ì§„ ë¦¬ì…‹
        if risk_engine:
            risk_engine.reset_daily()
        
        # í˜ì´í¼ ë ˆì € ë¦¬ì…‹
        if paper_ledger:
            paper_ledger.reset_daily()
        
        # Slack ì•Œë¦¼
        if slack_bot:
            message = {
                "text": "ğŸ”„ ì¼ì¼ ë¦¬ì…‹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
                "channel": "#trading-signals"
            }
            slack_bot.send_message(message)
        
        logger.info("ì¼ì¼ ë¦¬ì…‹ ì™„ë£Œ")
        
        return {
            "status": "success",
            "message": "ì¼ì¼ ë¦¬ì…‹ ì™„ë£Œ",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬ì…‹ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(name="app.jobs.scheduler.daily_report")
def daily_report(force=False, post=True):
    """ì¼ì¼ ë¦¬í¬íŠ¸ ì‘ì—…"""
    try:
        logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘")
        
        paper_ledger = trading_components["paper_ledger"]
        risk_engine = trading_components["risk_engine"]
        llm_engine = trading_components["llm_engine"]
        slack_bot = trading_components["slack_bot"]
        
        if not paper_ledger:
            return {"status": "skipped", "reason": "components_not_ready"}
        
        # ì¼ì¼ í†µê³„ ìˆ˜ì§‘
        daily_stats = paper_ledger.get_daily_stats()
        
        # ë¦¬ìŠ¤í¬ ì§€í‘œ
        risk_metrics = None
        if risk_engine:
            risk_metrics = risk_engine.get_risk_report()
        
        # LLM ì‚¬ìš©ëŸ‰
        llm_usage = None
        if llm_engine:
            llm_usage = llm_engine.get_status()
        
        # ë¦¬í¬íŠ¸ ë°ì´í„° êµ¬ì„±
        report_data = {
            "trades": daily_stats.get("trades", 0),
            "realized_pnl": daily_stats.get("realized_pnl", 0),
            "win_rate": 0.6,  # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
            "avg_rr": 1.4,    # ì‹¤ì œë¡œëŠ” ê³„ì‚° í•„ìš”
            "risk_metrics": risk_metrics,
            "llm_usage": llm_usage
        }
        
        # Slack ë¦¬í¬íŠ¸ ì „ì†¡
        if slack_bot and post:
            slack_bot.send_daily_report(report_data)
        
        logger.info("ì¼ì¼ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        
        return {
            "status": "success",
            "trades": report_data["trades"],
            "realized_pnl": report_data["realized_pnl"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì¼ì¼ ë¦¬í¬íŠ¸ ì‘ì—… ì‹¤íŒ¨: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

def get_recent_edgar_filing(ticker: str) -> Optional[Dict]:
    """ìµœê·¼ EDGAR ê³µì‹œ ì¡°íšŒ (ìºì‹œëœ ë°ì´í„°ì—ì„œ)"""
    # ì‹¤ì œë¡œëŠ” ìºì‹œë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ None ë°˜í™˜
    return None

def _session_label() -> str:
    """RTH/EXT ê°„ë‹¨ íŒë³„: ET ì‹œê°„ìœ¼ë¡œ 09:30-16:00ì€ RTH, ê·¸ ì™¸ 04:00-20:00ì€ EXT, ë‚˜ë¨¸ì§€ëŠ” CLOSED"""
    from datetime import datetime, timedelta, time as dtime, timezone
    et_tz = timezone(timedelta(hours=-5))
    now_est = datetime.now(et_tz)
    # DST ê°„ì´ ì ìš©
    dst_start = now_est.replace(month=3, day=8 + (6 - now_est.replace(month=3, day=1).weekday()) % 7, hour=2)
    dst_end = now_est.replace(month=11, day=1 + (6 - now_est.replace(month=11, day=1).weekday()) % 7, hour=2)
    if dst_start <= now_est < dst_end:
        et_tz = timezone(timedelta(hours=-4))
    now = datetime.now(et_tz).time()
    if dtime(9,30) <= now <= dtime(16,0):
        return "RTH"
    if dtime(4,0) <= now <= dtime(20,0):
        return "EXT"
    return "CLOSED"

def _record_recent_signal(redis_url: Optional[str], signal, session_label: str, indicators: Dict, suppressed: Optional[str] = None) -> None:
    try:
        if not redis_url:
            return
        r = redis.from_url(redis_url)
        key = "signals:recent"
        payload = {
            "ticker": signal.ticker,
            "signal_type": signal.signal_type.value,
            "score": signal.score,
            "confidence": signal.confidence,
            "regime": signal.regime,
            "timestamp": signal.timestamp.isoformat(),
            "session": session_label,
            "spread_bp": float(indicators.get("spread_bp", 0.0)),
            "dollar_vol_5m": float(indicators.get("dollar_vol_5m", 0.0)),
        }
        if suppressed:
            payload["suppressed_reason"] = suppressed
        r.lpush(key, json.dumps(payload))
        r.ltrim(key, 0, 500)
    except Exception:
        pass

def initialize_components(components: Dict):
    """ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    global trading_components
    trading_components.update(components)
    logger.info("ìŠ¤ì¼€ì¤„ëŸ¬ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")

    # Quotes ingestor ê¸°ë³¸ ì£¼ì…(ë”œë ˆì´ë“œ)
    try:
        from app.io.quotes_delayed import DelayedQuotesIngestor
        if trading_components.get("quotes_ingestor") is None:
            trading_components["quotes_ingestor"] = DelayedQuotesIngestor()
            logger.info("ë”œë ˆì´ë“œ Quotes ì¸ì œìŠ¤í„° ì´ˆê¸°í™”")
    except Exception as e:
        logger.warning(f"Quotes ì¸ì œìŠ¤í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


@celery_app.task(bind=True, name="app.jobs.scheduler.ingest_edgar_stream")
def ingest_edgar_stream(self):
    """Redis Streams(news.edgar) â†’ DB(edgar_events) ì ì¬. DB UNIQUE(snippet_hash)ë¡œ ìµœì¢… dedupe.
    ì›Œì»¤ ë¶€íŒ… í›„ readiness í†µê³¼ ì‹œ ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰ëœë‹¤.
    """
    try:
        from app.io.streams import RedisStreams, StreamConsumer
        rs = trading_components.get("redis_streams")
        if rs is None:
            # envì—ì„œ ì—°ê²°
            import urllib.parse as _u
            redis_url = os.getenv("REDIS_URL", "redis://redis:6379/0")
            parsed = _u.urlparse(redis_url)
            host = parsed.hostname or "redis"
            port = int(parsed.port or 6379)
            db = int(parsed.path.lstrip("/") or 0)
            rs = RedisStreams(host=host, port=port, db=db)
            trading_components["redis_streams"] = rs
        consumer = trading_components.get("stream_consumer") or StreamConsumer(rs)
        trading_components["stream_consumer"] = consumer

        # DB ì—°ê²° í™•ë³´/ì¬ì‚¬ìš©
        conn = trading_components.get("db_connection")
        if conn is None or conn.closed:
            dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
            if not dsn:
                return {"status": "skipped", "reason": "missing_db_dsn", "timestamp": datetime.now().isoformat()}
            conn = psycopg2.connect(dsn)
            conn.autocommit = True
            trading_components["db_connection"] = conn

        messages = consumer.consume_edgar_events(count=20, block_ms=100)
        inserted = 0
        with conn.cursor() as cur:
            for msg in messages:
                d = msg.data
                # ë¬¸ìì—´ë¡œ ì˜¨ JSONì„ ì›ìƒë³µêµ¬ ì‹œë„
                def _norm(key):
                    val = d.get(key)
                    if val is None:
                        return None
                    try:
                        return json.loads(val)
                    except Exception:
                        return val

                ticker = _norm("ticker") or d.get("ticker")
                form = _norm("form") or d.get("form")
                item = _norm("item") or d.get("item")
                url = _norm("url") or d.get("url")
                snippet_text = _norm("snippet_text") or d.get("snippet_text")
                snippet_hash = _norm("snippet_hash") or d.get("snippet_hash")
                
                # formì´ Noneì´ë©´ snippet_textì—ì„œ ì¶”ì¶œ ì‹œë„
                if form is None and snippet_text:
                    import re
                    match = re.search(r'\b(4|8-K|10-K|10-Q|S-1|S-3|DEF 14A)\b', str(snippet_text))
                    if match:
                        form = match.group(1)

                cur.execute(
                    """
                    INSERT INTO edgar_events (ticker, form, item, url, snippet_hash, snippet_text)
                    VALUES (%s, %s, %s, %s, %s, %s)
                    ON CONFLICT (snippet_hash) DO NOTHING
                    """,
                    (str(ticker) if ticker is not None else None,
                     str(form) if form is not None else None,
                     str(item) if item is not None else None,
                     str(url) if url is not None else None,
                     str(snippet_hash) if snippet_hash is not None else None,
                     str(snippet_text) if snippet_text is not None else None)
                )
                consumer.acknowledge("news.edgar", msg.message_id)
                inserted += 1

        return {"status": "success", "inserted": inserted, "timestamp": datetime.now().isoformat()}
    except Exception as e:
        logger.error(f"EDGAR ìŠ¤íŠ¸ë¦¼ ì ì¬ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e), "timestamp": datetime.now().isoformat()}

def get_task_status(task_id: str) -> Dict:
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    try:
        result = celery_app.AsyncResult(task_id)
        return {
            "task_id": task_id,
            "status": result.status,
            "result": result.result if result.ready() else None,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {
            "task_id": task_id,
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

@celery_app.task(name="app.jobs.scheduler.refresh_universe")
def refresh_universe():
    """15ë¶„ë§ˆë‹¤ ìœ ë‹ˆë²„ìŠ¤ ë³‘í•©â†’ì¸ì œìŠ¤í„° ë°˜ì˜"""
    try:
        quotes_ingestor = trading_components.get("quotes_ingestor")
        rurl = os.getenv("REDIS_URL")
        if not quotes_ingestor or not rurl:
            return {"status": "skipped"}
        r = redis.from_url(rurl)
        external = r.smembers("universe:external") or []
        watch = r.smembers("universe:watchlist") or []
        core = [t.strip().upper() for t in (os.getenv("TICKERS", "").split(",")) if t.strip()]
        ext = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in external]
        wch = [x.decode() if isinstance(x, (bytes, bytearray)) else x for x in watch]
        merged = []
        seen = set()
        max_n = int(os.getenv("UNIVERSE_MAX", "60"))
        for arr in [core, ext, wch]:
            for s in arr:
                if s and s not in seen:
                    merged.append(s)
                    seen.add(s)
                if len(merged) >= max_n:
                    break
            if len(merged) >= max_n:
                break
        if hasattr(quotes_ingestor, "update_universe_tickers"):
            quotes_ingestor.update_universe_tickers(merged)
        return {"status": "ok", "universe_size": len(merged)}
    except Exception as e:
        logger.error(f"ìœ ë‹ˆë²„ìŠ¤ ê°±ì‹  ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}

@celery_app.task(name="app.jobs.scheduler.adaptive_cutoff")
def adaptive_cutoff():
    """ì „ì¼ ì²´ê²° ê±´ìˆ˜ ê¸°ë°˜ ì»·ì˜¤í”„ ì¡°ì •: cfg:signal_cutoff:{rth|ext} Â±0.02 with bounds"""
    try:
        if os.getenv("ADAPTIVE_CUTOFF_ENABLED", "true").lower() not in ("1","true","yes","on"):
            return {"status": "skipped", "reason": "disabled"}
        rurl = os.getenv("REDIS_URL")
        if not rurl:
            return {"status": "skipped", "reason": "no_redis"}
        r = redis.from_url(rurl)
        # ì²´ê²° ê±´ìˆ˜: ê°„ì´ ì§‘ê³„(orders_paper í…Œì´ë¸” ì—†ìœ¼ë©´ 0 ì²˜ë¦¬)
        fills = 0
        try:
            dsn = os.getenv("POSTGRES_URL") or os.getenv("DATABASE_URL")
            if dsn:
                import psycopg2
                from datetime import date, timedelta
                conn = psycopg2.connect(dsn)
                cur = conn.cursor()
                prev = (datetime.utcnow() - timedelta(days=1)).date()
                cur.execute("SELECT COUNT(*) FROM orders_paper WHERE DATE(ts)=%s", (prev,))
                fills = int(cur.fetchone()[0] or 0)
                cur.close(); conn.close()
        except Exception:
            fills = 0
        # í˜„ì¬ê°’ ì½ê¸°
        def _getf(k, d):
            v = r.get(k)
            try:
                return float(v) if v is not None else d
            except Exception:
                return d
        rth = _getf("cfg:signal_cutoff:rth", settings.SIGNAL_CUTOFF_RTH)
        ext = _getf("cfg:signal_cutoff:ext", settings.SIGNAL_CUTOFF_EXT)
        # ì¡°ì • (í˜„ì‹¤ì  ê²½ê³„ê°’ìœ¼ë¡œ ìˆ˜ì •)
        rth_base, ext_base = settings.SIGNAL_CUTOFF_RTH, settings.SIGNAL_CUTOFF_EXT
        delta = -0.02 if fills == 0 else (0.02 if fills >= 4 else 0.0)
        rth_new = min(max(rth + delta, max(0.12, rth_base - 0.06)), rth_base + 0.12)
        ext_new = min(max(ext + delta, max(0.18, ext_base - 0.10)), ext_base + 0.10)
        r.set("cfg:signal_cutoff:rth", rth_new)
        r.set("cfg:signal_cutoff:ext", ext_new)
        return {"status": "ok", "fills": fills, "rth": rth_new, "ext": ext_new}
    except Exception as e:
        logger.error(f"ì ì‘í˜• ì»·ì˜¤í”„ ì‹¤íŒ¨: {e}")
        return {"status": "error", "error": str(e)}


if __name__ == "__main__":
    # ê°œë°œìš© ì‹¤í–‰
    celery_app.start()
